### 引入实时API

开发者现在可以在他们的应用中构建快速的语音到语音体验

今天，我们推出了实时API的公测版，允许所有付费开发者在他们的应用中构建低延迟的多模态体验。与ChatGPT的高级语音模式相似，实时API支持自然的语音到语音对话，并使用API中已经支持的六种预设声音。

我们还在“聊天补全API”中引入了音频输入和输出，以支持那些不需要实时API的低延迟优势的用例。通过这一更新，开发者可以将任何文本或音频输入传递给GPT-4o，让模型以文本、音频或两者同时的方式进行响应。

从语言学习应用和教育软件到客户支持体验，开发者已经在利用语音体验与用户建立联系。现在，有了实时API，并且不久后“聊天补全API”也支持音频输入输出，开发者不再需要组合多个模型来提供这些体验。相反，只需通过单个API调用就可以构建自然的对话体验。

### 工作原理

之前，要实现类似的语音助手体验，开发者需要先使用自动语音识别模型（如Whisper）来转录音频，将文本传递给文本模型进行推理或判断，然后通过文本到语音（TTS）模型播放模型的输出。这样的方法往往会导致情感、重点和口音的丢失，并且会带来明显的延迟。使用“聊天补全API”，开发者可以通过单个API调用处理整个流程，尽管速度仍比人类对话稍慢。实时API通过直接流式传输音频输入和输出来改善这一点，使对话体验更加自然。它还可以像ChatGPT的高级语音模式一样自动处理打断。

在后台，实时API允许你创建一个持久的WebSocket连接，以与GPT-4o交换消息。API支持函数调用，使得语音助手可以通过触发操作或获取新上下文来响应用户请求。例如，语音助手可以代表用户下订单或检索相关的客户信息，以个性化其响应。

### 支持客户服务代理、语言学习助手等

作为我们迭代部署策略的一部分，我们已经与一些合作伙伴一起测试了实时API，以便在构建过程中收集反馈。几个有前景的早期用例包括：

* **Healthify**，一款营养和健身指导应用，利用实时API使其AI教练Ria与用户进行自然的对话，在需要个性化支持时，甚至可以引入真人营养师。

* **Speak**，一款语言学习应用，使用实时API来支持其角色扮演功能，鼓励用户在新语言中练习对话。

### 可用性与定价

实时API今天开始向所有付费开发者推出公测版。实时API中的音频功能由新模型GPT-4o的预览版本“gpt-4o-realtime-preview”提供支持。

聊天补全API中的音频功能将在未来几周内发布，新模型“gpt-4o-audio-preview”将支持这一功能。通过gpt-4o-audio-preview，开发者可以将文本或音频输入传递给GPT-4o，并接收文本、音频或两者兼有的响应。

实时API使用文本和音频两种类型的令牌。文本输入令牌的价格为每百万令牌$$5，输出令牌为每百万$$20。音频输入定价为每百万令牌$$100，音频输出则为每百万令牌$$200。这相当于每分钟音频输入约$$0.06，每分钟音频输出约$$0.24。聊天补全API中的音频功能将采用相同的定价。

### 安全性与隐私

实时API使用多层安全保护措施，以降低API滥用的风险，包括对标记的模型输入和输出的自动监控和人工审查。实时API基于GPT-4o的相同版本构建，该版本同样支持ChatGPT的高级语音模式，并且我们通过自动和人工评估进行了仔细审查，其中包括使用《GPT-4o系统卡》中的准备框架进行评估。实时API还利用了我们为高级语音模式构建的音频安全基础设施，测试显示该基础设施有助于降低潜在的危害。

我们的使用政策禁止将服务输出用于垃圾邮件、误导或其他有害用途，并且我们会主动监控潜在的滥用情况。我们的政策还要求开发者向用户明确说明他们正在与AI交互，除非从上下文中已显而易见。

在发布前，我们通过外部红队网络测试了实时API，发现该API没有带来未涵盖的高风险漏洞。和所有API服务一样，实时API也符合我们的企业隐私承诺。在未经明确许可的情况下，我们不会将用于该服务的输入或输出数据用于训练我们的模型。

### 入门指南

开发者可以在未来几天内通过Playground或使用我们的文档和参考客户端开始使用实时API。

我们还与LiveKit和Agora合作，创建了包含回声消除、重连和声音隔离等音频组件的客户端库，并与Twilio集成，将实时API与Twilio的语音API结合，从而使开发者能够通过语音通话无缝地构建、部署和连接AI虚拟代理与客户互动。

### 未来展望

在推进全面可用性方面，我们正在积极收集反馈，以改进实时API。我们计划引入的一些功能包括：

* **更多模态支持**：实时API最初支持语音，我们计划逐步添加视觉、视频等更多模态支持。

* **提高速率限制**：目前，API对5级开发者的限制是约100个并发会话，1-4级的限制较低。我们将逐步提高这些限制，以支持更大规模的部署。

* **官方SDK支持**：我们将把实时API集成到OpenAI的Python和Node.js SDK中。

* **提示缓存**：我们将支持提示缓存功能，以便以前的对话轮次可以以折扣价重新处理。

* **扩展模型支持**：未来，实时API还将支持GPT-4o mini版本。

我们期待看到开发者如何利用这些新功能，为用户在教育、翻译、客户服务、无障碍等各种应用场景中创造引人入胜的音频体验。



🍻现开设了**大模型学习交流群**，扫描下👇码，来遇见更多志同道合的小伙伴\~

海量硬核独家技&#x672F;**`干货内容`**+无门&#x69DB;**`技术交流`**\~

![](images/f339b04b7b20233dd1509c7fb36d5c0.png)

上图**扫码**👆即刻入群！

📍 社群**技术交流**氛围浓厚，不定期开&#x8BBE;**`硬核干货&前沿技术公开课`**&#x5662;\~
