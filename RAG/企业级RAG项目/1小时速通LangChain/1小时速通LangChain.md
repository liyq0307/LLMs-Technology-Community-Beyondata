## LangChainå¦‚ä½•æ¥å…¥åœ¨çº¿å¤§æ¨¡å‹å¹¶æ„å»ºé“¾è·¯

â€ƒâ€ƒLangChainå½’å±äºLangChain AIå…¬å¸ï¼ŒLangChainä½œä¸ºå…¶ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒé¡¹ç›®ï¼Œå¼€æºå‘å¸ƒåœ¨Gitubä¸Šï¼šhttps://github.com/langchain-ai/langchain

â€ƒâ€ƒä»LangChainçš„GitHubç‰ˆæœ¬è¿­ä»£å†å²ä¸Šçœ‹ï¼Œä»2023å¹´1æœˆ16æ—¥èµ·å·²ç»ç»å†äº†320ä¸ªå¤§å°ç‰ˆæœ¬çš„è¿­ä»£ï¼Œå¹¶ä¸”ä»ç„¶ä»¥é«˜é¢‘ç‡çš„æ›´æ–°åœ¨åŠ é€Ÿé¡¹ç›®çš„åŠŸèƒ½ä¸Šçº¿ï¼Œä»æ•´ä½“ä¸Šçœ‹ï¼Œå…¶å…³æ³¨åº¦å’Œç¤¾åŒºæ´»è·ƒåº¦æ˜¯éå¸¸é«˜çš„ã€‚LangChainç»™è‡ªèº«çš„å®šä½æ˜¯ï¼šç”¨äºå¼€å‘ç”±å¤§è¯­è¨€æ¨¡å‹æ”¯æŒçš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚å®ƒçš„åšæ³•æ˜¯ï¼šé€šè¿‡æä¾›æ ‡å‡†åŒ–ä¸”ä¸°å¯Œçš„æ¨¡å—æŠ½è±¡ï¼Œæ„å»ºå¤§è¯­è¨€æ¨¡å‹çš„è¾“å…¥è¾“å…¥è§„èŒƒï¼Œåˆ©ç”¨å…¶æ ¸å¿ƒæ¦‚å¿µ`chains`ï¼Œçµæ´»åœ°è¿æ¥æ•´ä¸ªåº”ç”¨å¼€å‘æµç¨‹ã€‚è€Œé’ˆå¯¹æ¯ä¸ªåŠŸèƒ½æ¨¡å—ï¼Œéƒ½æºäºå¯¹å¤§æ¨¡å‹é¢†åŸŸçš„æ·±å…¥ç†è§£å’Œå®è·µç»éªŒï¼Œå¼€å‘è€…æä¾›å‡ºæ¥çš„æ ‡å‡†åŒ–æµç¨‹å’Œè§£å†³æ–¹æ¡ˆçš„æŠ½è±¡ï¼Œå†é€šè¿‡çµæ´»çš„æ¨¡å—åŒ–ç»„åˆï¼Œæ‰æœ‰äº†ç›®å‰è¿™æ ·ä¸€æ¬¾åœ¨å¤§æ¨¡å‹åº”ç”¨å¼€å‘é¢†åŸŸå†…è¢«æ™®éé«˜åº¦è®¤å¯çš„é€šç”¨æ¡†æ¶ã€‚

![](images/dbee404f-8d65-4f13-89bd-324f5a5b02fb.png)

* **ä¸ºä»€ä¹ˆéœ€è¦è¿™æ ·åšï¼Ÿ**

â€ƒâ€ƒé¦–å…ˆï¼Œæˆ‘ä»¬éœ€è€ƒè™‘å½“å‰å¤§æ¨¡å‹çš„å‘å±•æ€åŠ¿ã€‚å°½ç®¡OpenAIçš„GPTç³»åˆ—æ¨¡å‹ä½œä¸ºå¤§æ¨¡å‹é¢†åŸŸçš„`é¢†å†›äººç‰©`ï¼Œåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šäº†å½±å“äº†å¤§æ¨¡å‹çš„ä½¿ç”¨è§„èŒƒå’ŒåŸºäºå¤§æ¨¡å‹è¿›è¡Œåº”ç”¨å¼€å‘çš„èŒƒå¼ï¼Œä½†å¹¶ä¸æ„å‘³ç€æ‰€æœ‰å¤§æ¨¡å‹é—´çš„ä½¿ç”¨æ–¹å¼å®Œå…¨ç›¸åŒã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ç†Ÿæ‚‰çš„OpenAI GPTæ¨¡å‹APIè°ƒç”¨æ–¹å¼å¯¹äºBaichuan2æ¨¡å‹å°±ä¸é€‚ç”¨ã€‚å› æ­¤ï¼Œå¯¹äºæ¯ä¸ªæ–°æ¨¡å‹éƒ½è¦èŠ±è´¹å¤§é‡æ—¶é—´å­¦ä¹ å…¶ç‰¹å®šè§„èŒƒå†è¿›è¡Œåº”ç”¨æ¢ç´¢ï¼Œè¿™ç§å·¥ä½œæ•ˆç‡æ˜¾ç„¶æ˜¯ååˆ†ä½ä¸‹çš„ã€‚

â€ƒâ€ƒå…¶æ¬¡ï¼Œå¿…é¡»è°ˆè®ºçš„æ˜¯å¤§æ¨¡å‹ç›®å‰é¢ä¸´çš„å±€é™ï¼Œå¦‚çŸ¥è¯†æ›´æ–°çš„æ»åæ€§ã€å¤–éƒ¨APIè°ƒç”¨èƒ½åŠ›ã€ç§æœ‰æ•°æ®è¿æ¥æ–¹å¼ä»¥åŠè¾“å‡ºç»“æœçš„ä¸ç¨³å®šæ€§ç­‰é—®é¢˜ã€‚åœ¨åº”ç”¨å¼€å‘ä¸­ï¼Œå¦‚ä½•æ‰¾åˆ°è¿™äº›é—®é¢˜çš„æœ‰æ•ˆè§£å†³ç­–ç•¥ï¼Ÿ

![](images/9accd5d1-3511-4230-af86-6440349fee20.png)

â€ƒâ€ƒä¸Šè¿°æåˆ°çš„æ¯ä¸ªé™åˆ¶éƒ½ç´§å¯†å…³è”äºå¤§æ¨¡å‹æœ¬èº«çš„ç‰¹æ€§ã€‚å°½ç®¡ç†è®ºä¸Šå¯ä»¥é€šè¿‡é‡æ–°è®­ç»ƒã€å¾®è°ƒæ¥å¢å¼ºæ¨¡å‹çš„åŸç”Ÿèƒ½åŠ›ï¼Œè¿™ç§æ–¹æ³•ç¡®å®æœ‰æ•ˆï¼Œä½†å®é™…ä¸Šï¼Œå¤§å¤šæ•°å¼€å‘è€…å¹¶ä¸å…·å¤‡è¿›è¡Œè¿™æ ·æ“ä½œæ‰€éœ€çš„æŠ€æœ¯èµ„æºã€æ—¶é—´å’Œè´¢åŠ›ï¼Œé€‰æ‹©è¿™æ¡è·¯å¾„ä¸€å®šä¼šå¯¼è‡´æ–¹å‘è¶Šæ¥è¶Šåç¦»ç›®æ ‡ã€‚æ¯”å¦‚å…³äºå¤§æ¨¡å‹çš„Agentsã€å‡½æ•°è°ƒç”¨ç­‰åŠŸèƒ½ï¼Œæ¯ä¸€æ­¥éƒ½éœ€å¤§é‡çš„ç ”å‘æŠ•å…¥ï¼Œè€Œä¸”æœ€ç»ˆå®ç°åçš„åº”ç”¨æ•ˆæœï¼Œä¹Ÿå–å†³äºç ”å‘äººå‘˜çš„ä¸ªäººæŠ€æœ¯èƒ½åŠ›ã€‚åœ¨è¿™ç§èƒŒæ™¯ä¸‹ï¼Œæ—¢ç„¶å¤§å®¶éƒ½æœ‰ä¸åŒçš„æƒ³æ³•å’Œè§£å†³æ–¹æ¡ˆï¼Œé‚£LangChainå°±æ¥é›†ä¸­åšè¿™ä»¶äº‹ï¼Œæä¾›ä¸€ä¸ªç»Ÿä¸€çš„å¹³å°å’Œæ˜ç¡®çš„å®šä¹‰ï¼Œæ¥å®ç°åº”ç”¨æ¡†æ¶çš„å¿«é€Ÿæ­å»ºï¼Œè¿™å°±æ˜¯LangChainä¸€ç›´æƒ³è¦åšåˆ°ï¼Œä¸”æ­£åœ¨åšçš„äº‹æƒ…ã€‚

* **LangChainçš„åšæ³•**

â€ƒâ€ƒä»æœ¬è´¨ä¸Šåˆ†æï¼ŒLangChainè¿˜æ˜¯ä¾ç„¶é‡‡ç”¨ä»å¤§æ¨¡å‹è‡ªèº«å‡ºå‘çš„ç­–ç•¥ï¼Œé€šè¿‡å¼€å‘äººå‘˜åœ¨å®è·µè¿‡ç¨‹ä¸­å¯¹å¤§æ¨¡å‹èƒ½åŠ›çš„æ·±å…¥ç†è§£åŠå…¶åœ¨ä¸åŒåœºæ™¯ä¸‹çš„æ¶Œç°æ½œåŠ›ï¼Œä½¿ç”¨æ¨¡å—åŒ–çš„æ–¹å¼è¿›è¡Œé«˜çº§æŠ½è±¡ï¼Œè®¾è®¡å‡ºç»Ÿä¸€æ¥å£ä»¥é€‚é…å„ç§å¤§æ¨¡å‹ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼ŒLangChainæŠ½è±¡å‡ºæœ€é‡è¦çš„æ ¸å¿ƒæ¨¡å—å¦‚ä¸‹ï¼š

1. Model I/O ï¼šæ ‡å‡†åŒ–å„ä¸ªå¤§æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºï¼ŒåŒ…å«è¾“å…¥æ¨¡ç‰ˆï¼Œæ¨¡å‹æœ¬èº«å’Œæ ¼å¼åŒ–è¾“å‡ºï¼›

2. Retrieval ï¼šæ£€ç´¢å¤–éƒ¨æ•°æ®ï¼Œç„¶ååœ¨æ‰§è¡Œç”Ÿæˆæ­¥éª¤æ—¶å°†å…¶ä¼ é€’åˆ° LLMï¼ŒåŒ…æ‹¬æ–‡æ¡£åŠ è½½ã€åˆ‡å‰²ã€Embeddingç­‰ï¼›

3. Chains ï¼šé“¾æ¡ï¼ŒLangChainæ¡†æ¶ä¸­æœ€é‡è¦çš„æ¨¡å—ï¼Œé“¾æ¥å¤šä¸ªæ¨¡å—ååŒæ„å»ºåº”ç”¨ï¼Œæ˜¯å®é™…è¿ä½œå¾ˆå¤šåŠŸèƒ½çš„é«˜çº§æŠ½è±¡ï¼›

4. Memory ï¼š è®°å¿†æ¨¡å—ï¼Œä»¥å„ç§æ–¹å¼æ„å»ºå†å²ä¿¡æ¯ï¼Œç»´æŠ¤æœ‰å…³å®ä½“åŠå…¶å…³ç³»çš„ä¿¡æ¯ï¼›

5. Agents ï¼š ç›®å‰æœ€çƒ­é—¨çš„Agentså¼€å‘å®è·µï¼Œæœªæ¥èƒ½å¤ŸçœŸæ­£å®ç°é€šç”¨äººå·¥æ™ºèƒ½çš„è½åœ°æ–¹æ¡ˆï¼›

6. Callbacks ï¼šå›è°ƒç³»ç»Ÿï¼Œå…è®¸è¿æ¥åˆ° LLM åº”ç”¨ç¨‹åºçš„å„ä¸ªé˜¶æ®µã€‚ç”¨äºæ—¥å¿—è®°å½•ã€ç›‘æ§ã€æµä¼ è¾“å’Œå…¶ä»–ä»»åŠ¡ï¼›

![](images/ba3b32df-6f9f-4935-b5d8-c50aba47af88.png)

â€ƒâ€ƒä»ä¸Šå›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼ŒLangChainæ¡†æ¶æ¶µç›–äº†æ¨¡å‹è¾“å…¥è¾“å‡ºçš„æ ‡å‡†åŒ–ã€å¤–éƒ¨å·¥å…·æ¥å…¥çš„è§„èŒƒã€ä¸Šä¸‹æ–‡è®°å¿†åŠŸèƒ½ï¼Œä»¥åŠå¯¹æ•°æ®åº“ã€SQLã€CSVç­‰å¤šç§æ•°æ®æºçš„è¿æ¥æ ‡å‡†ã€‚é€šè¿‡æ ¸å¿ƒçš„"Chain"é«˜çº§æŠ½è±¡ï¼Œå®šä¹‰äº†ä¸åŒå½¢å¼ä¸‹æ ‡å‡†çš„é“¾æ¥æ–¹æ³•ï¼Œè¿™å°±èƒ½å¤Ÿå…è®¸å¼€å‘è€…æ ¹æ®å®é™…çš„åº”ç”¨éœ€æ±‚å’Œæ•°æ®æµå‘å¿«é€Ÿæ„å»ºå‡ºä¸€å¥—å®Œæ•´çš„åº”ç”¨ç¨‹åºã€‚è¿™ä¸ªè¿‡ç¨‹ç±»ä¼¼äºæ­å»ºç§¯æœ¨ï¼Œå¯ä»¥çµæ´»é€‚åº”ä¸åŒçš„ä»»åŠ¡éœ€æ±‚ã€‚

![](images/0c3f62d6-bd59-43f7-b02e-3707c63bc232.png)

â€ƒâ€ƒä¹Ÿæ­£å› ä¸ºå¦‚æ­¤ï¼ŒLangChainä¸­æ¶‰åŠçš„æ¦‚å¿µå’Œæ¨¡å—åŒ–æ˜¯éå¸¸å¤šçš„ï¼Œæ¯ä¸ªæ¨¡å—éƒ½æœ‰å…¶ç‹¬ç‰¹çš„ä½¿ç”¨åœºæ™¯å’Œä½¿ç”¨æ–¹æ³•ï¼Œé‚£ä¹ˆå¦‚ä½•å»æ­è¿™ä¸ªâ€œç§¯æœ¨â€ï¼Œå°±éœ€è¦æˆ‘ä»¬å¯¹å…¶æ¯ä¸ªæ ¸å¿ƒæ¨¡å—éƒ½è¦æœ‰ä¸€ä¸ªæ¯”è¾ƒæ¸…æ¥šçš„è®¤çŸ¥ã€‚æ‰€ä»¥æˆ‘ä»¬è¯¾ç¨‹çš„å®‰æ’è¿˜æ˜¯é€ä¸ªæ‹†è§£LangChainçš„åŠŸèƒ½æ¨¡å—ï¼Œæ¯ä¸€éƒ¨åˆ†éƒ½å°½å¯èƒ½çš„ç»™å¤§å®¶åšè¯¦ç»†çš„ä»‹ç»å’Œå®æ“ï¼Œå¹¶åœ¨æ¥ä¸‹æ¥çš„é¡¹ç›®éƒ¨åˆ†ï¼Œè¿›è¡Œæ•´ä½“çš„ä¸€ä¸ªä¸²è”ï¼Œå±Šæ—¶å¤§å®¶å°†èƒ½å¤Ÿæ¸…æ™°çš„æ˜ç¡®å¦‚ä½•æ ¹æ®è‡ªå·±çš„å®é™…ä¸šåŠ¡æƒ…å†µï¼Œé€‰æ‹©åˆé€‚çš„æ„é€ æ¨¡å—å’Œæ„é€ æ–¹æ³•ã€‚

â€ƒâ€ƒåœ¨æ•´ä½“ä¸Šç†è§£äº†LangChainä¹‹åï¼Œæˆ‘ä»¬é¦–å…ˆä»Model I/Oæ¨¡å—è¿›è¡Œæ·±å…¥çš„æ¢è®¨å’Œå®è·µã€‚

# 1. LangChainæ ¸å¿ƒæ¨¡å—ï¼šModel I/O

â€ƒâ€ƒLangChainçš„Model I/Oæ¨¡å—æä¾›äº†æ ‡å‡†çš„ã€å¯æ‰©å±•çš„æ¥å£å®ç°ä¸å¤§è¯­è¨€æ¨¡å‹çš„å¤–éƒ¨é›†æˆã€‚æ‰€è°“çš„Model I/Oï¼ŒåŒ…æ‹¬æ¨¡å‹è¾“å…¥ï¼ˆPromptsï¼‰ã€æ¨¡å‹è¾“å‡ºï¼ˆOutPutsï¼‰å’Œæ¨¡å‹æœ¬èº«ï¼ˆModelsï¼‰ï¼Œç®€å•ç†è§£å°±æ˜¯é€šè¿‡è¯¥æ¨¡å—ï¼Œæˆ‘ä»¬å¯ä»¥å¿«é€Ÿä¸æŸä¸ªå¤§æ¨¡å‹è¿›è¡Œå¯¹è¯äº¤äº’ï¼Œæ•´ä¸ªå†…éƒ¨é€»è¾‘å°±ç›¸å½“äºæˆ‘ä»¬æœ€ç†Ÿæ‚‰çš„è¿™ä¸ªè¿‡ç¨‹ï¼šè¾“å…¥Promptï¼Œå¾—åˆ°å¤§æ¨¡å‹é’ˆå¯¹è¯¥Promptçš„æ¨ç†ç»“æœã€‚å¦‚ä¸‹ç¤ºä¾‹ä¸ºOpenAIçš„ GPT ç³»åˆ—æ¨¡å‹çš„API è°ƒç”¨è§„èŒƒï¼š

```python
response = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "user", "content": "è¯·é—®ï¼Œä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"}
  ]
)
```

â€ƒâ€ƒè€Œæˆ‘ä»¬å‰é¢æåˆ°äº†ï¼ŒLangChainé¡¹ç›®çš„å®šä½ä¸ºä¸€ä¸ªåº”ç”¨å¼€å‘æ¡†æ¶ï¼Œæ‰€ä»¥å¦‚æœä»…ä»…é›†æˆåˆ°è¿™æ ·çš„å¯¹è¯äº¤äº’ç¨‹åº¦ï¼Œé‚£ç›¸è¾ƒäºç›´æ¥ä½¿ç”¨OpenAIçš„APIè°ƒç”¨åˆæœ‰ä½•å¼‚å‘¢ï¼Ÿæ‰€ä»¥åœ¨è¿™ä¸ªæ¨¡å—ä¸­ï¼ŒLangChainåŒæ ·æŠ½è±¡å‡ºä¸€ä¸ª`chain`ï¼Œç”¨äºè¿›ä¸€æ­¥ç®€åŒ–å’Œå¢å¼ºäº¤äº’æµç¨‹ã€‚åœ¨LangChainçš„Model I/Oæ¨¡å—è®¾è®¡ä¸­ï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒéƒ¨åˆ†ï¼š Prompt Templateï¼ˆå¯¹åº”ä¸‹å›¾ä¸­çš„Formatéƒ¨åˆ†ï¼‰ï¼Œ Modelï¼ˆå¯¹åº”ä¸‹å›¾ä¸­çš„Predictéƒ¨åˆ†ï¼‰ å’ŒOutput Parserï¼ˆå¯¹åº”ä¸‹å›¾ä¸­çš„Parseéƒ¨åˆ†ï¼‰ã€‚

* **Formatï¼šå³æŒ‡ä»£Prompts Templateï¼Œé€šè¿‡æ¨¡æ¿åŒ–æ¥ç®¡ç†å¤§æ¨¡å‹çš„è¾“å…¥ï¼›**

* **Predictï¼šå³æŒ‡ä»£Modelsï¼Œä½¿ç”¨é€šç”¨æ¥å£è°ƒç”¨ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹ï¼›**

* **Parseï¼šå³æŒ‡ä»£Outputéƒ¨åˆ†ï¼Œç”¨æ¥ä»æ¨¡å‹çš„æ¨ç†ä¸­æå–ä¿¡æ¯ï¼Œå¹¶æŒ‰ç…§é¢„å…ˆè®¾å®šå¥½çš„æ¨¡ç‰ˆæ¥è§„èŒƒåŒ–è¾“å‡ºã€‚**

â€ƒâ€ƒæ•´ä¸ªModel I/Oå·¥ä½œæµå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![](images/bb04b6a7-7e99-4717-8a1f-7c443ef36245.png)

* **Format**

â€ƒâ€ƒå¯¹äºPrompt Templateç¬¬ä¸€éƒ¨åˆ†ï¼Œä¼ ç»Ÿä¸Šæˆ‘ä»¬åˆ›å»ºæç¤ºè¯æ˜¯é€šè¿‡æ‰‹å·¥ç¼–å†™æ¥å®ç°çš„ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ä¼šåˆ©ç”¨å„ç§æç¤ºå·¥ç¨‹æŠ€å·§ï¼Œå¦‚Few-Shotã€é“¾å¼æ¨ç†ï¼ˆCoTï¼‰ç­‰æ–¹æ³•ï¼Œä»¥æé«˜å¤§æ¨¡å‹çš„æ¨ç†æ€§èƒ½ã€‚ç„¶è€Œï¼Œ\*\*åœ¨åº”ç”¨å¼€å‘ä¸­ï¼Œä¸€ä¸ªå…³é”®çš„è€ƒé‡æ˜¯æç¤ºè¯ä¸èƒ½æ˜¯ä¸€æˆä¸å˜çš„ã€‚\*\*å…¶åŸå› åœ¨äºï¼Œåº”ç”¨å¼€å‘éœ€è¦é€‚åº”å¤šå˜çš„ç”¨æˆ·éœ€æ±‚å’Œåœºæ™¯ã€‚å›ºå®šçš„æç¤ºè¯é™åˆ¶äº†æ¨¡å‹çš„çµæ´»æ€§å’Œé€‚ç”¨èŒƒå›´ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æ­£åœ¨å¼€å‘ä¸€ä¸ªå¤©æ°”æŸ¥è¯¢åº”ç”¨ï¼Œç”¨æˆ·å¯èƒ½ä¼šä»¥å¤šç§æ–¹å¼æå‡ºæŸ¥è¯¢ï¼Œå¦‚â€œä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿâ€æˆ–â€œæ˜å¤©çº½çº¦çš„æ¸©åº¦æ˜¯å¤šå°‘åº¦ï¼Ÿâ€ã€‚å¦‚æœæç¤ºè¯æ˜¯å›ºå®šçš„ï¼Œå®ƒå¯èƒ½åªèƒ½å¤„ç†ä¸€ç§ç‰¹å®šç±»å‹çš„æŸ¥è¯¢ï¼Œè€Œæ— æ³•é€‚åº”è¿™ç§å¤šæ ·æ€§çš„éœ€æ±‚ã€‚

â€ƒâ€ƒè€ŒPrompt Templateï¼Œå°±åƒReActä¸€æ ·ï¼Œå°†APIçš„ä½¿ç”¨ã€é—®é¢˜è§£ç­”è¿‡ç¨‹ç­‰å¤æ‚é€»è¾‘å°è£…æˆäº†ä¸€å¥—ç»“æ„åŒ–çš„æ ¼å¼ã€‚æˆ‘ä»¬åªéœ€å‡†å¤‡å…·ä½“çš„å¤–éƒ¨å‡½æ•°ä¿¡æ¯å’Œç”¨æˆ·æŸ¥è¯¢ï¼Œå³å¯ç”Ÿæˆå®šåˆ¶åŒ–çš„æç¤ºè¯ï¼Œå¼•å¯¼æ¨¡å‹æŒ‰ç…§æ—¢å®šé€»è¾‘è¿›è¡Œæ€è€ƒå’Œå›ç­”ï¼Œä»è€Œå®ç°å¤–éƒ¨å‡½æ•°çš„è°ƒç”¨è¿‡ç¨‹ï¼Œå³ï¼š

```json
# å°†ä¸€ä¸ªæ’ä»¶çš„å…³é”®ä¿¡æ¯æ‹¼æ¥æˆä¸€æ®µæ–‡æœ¬çš„æ¨¡ç‰ˆã€‚
TOOL_DESC = """{name_for_model}: Call this tool to interact with the {name_for_human} API. What is the {name_for_human} API useful for? {description_for_model} Parameters: {parameters}"""

# ReAct prompting çš„ instruction æ¨¡ç‰ˆï¼Œå°†åŒ…å«æ’ä»¶çš„è¯¦ç»†ä¿¡æ¯ã€‚
PROMPT_REACT = """Answer the following questions as best you can. You have access to the following APIs:

{tool_descs}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can be repeated zero or more times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {query}"""
```

â€ƒâ€ƒå› æ­¤ï¼Œå¼•å…¥Prompt Templateå¯ä»¥æ”¯æŒå˜é‡å’ŒåŠ¨æ€å†…å®¹çš„æ’å…¥ï¼Œä½¿å¾—åŒä¸€ä¸ªåº”ç”¨å¯ä»¥æ ¹æ®ä¸åŒçš„è¾“å…¥åŠ¨æ€è°ƒæ•´æç¤ºè¯ï¼Œä»è€Œæ›´å¥½åœ°å“åº”ç”¨æˆ·çš„å…·ä½“éœ€æ±‚ã€‚LangChainé€šè¿‡è¿™ç§æ–¹å¼æ¥æé«˜åº”ç”¨çš„é€šç”¨æ€§å’Œç”¨æˆ·ä½“éªŒã€‚

* **Predict**

â€ƒâ€ƒåœ¨Predictéƒ¨åˆ†ï¼Œå®è´¨ä¸Šæ˜¯å¤„ç†æ¨¡å‹ä»æ¥æ”¶è¾“å…¥åˆ°æ‰§è¡Œæ¨ç†çš„æ•´ä¸ªè¿‡ç¨‹ã€‚è€ƒè™‘åˆ°å­˜åœ¨ä¸¤ç§ä¸»è¦ç±»å‹çš„å¤§æ¨¡å‹â€”â€”Baseç±»æ¨¡å‹å’ŒChatç±»æ¨¡å‹ï¼ŒLangChainåœ¨å…¶Model I/Oæ¨¡å—ä¸­å¯¹è¿™ä¸¤ç§æ¨¡å‹éƒ½è¿›è¡Œäº†æŠ½è±¡ï¼Œåˆ†åˆ«å½’ç±»ä¸ºLLMsï¼ˆLarge Language Modelsï¼‰å’ŒChat Modelsã€‚æˆ‘ä»¬è¿˜æ˜¯ä»¥OpenAI çš„ Completion å’Œ Chatcompletionsæ–¹æ³•ä¸ºä¾‹ï¼š

```python

# Baseç±»æ¨¡å‹
client.completions.create(
  model="gpt-3.5-turbo-instruct",
  prompt="Say this is a test",
)


# èŠå¤©æ¨¡å‹
client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„AIæ™ºèƒ½å°åŠ©æ‰‹"},
    {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
  ]
)
```

â€ƒâ€ƒLLMsæ˜¯ç®€åŒ–çš„å¤§è¯­è¨€æ¨¡å‹æŠ½è±¡ï¼Œå³åŸºäºç»™å®šçš„Promptæä¾›å†…å®¹ç”Ÿæˆçš„åŠŸèƒ½ã€‚è€ŒChat Modelsåˆ™ä¸“æ³¨äºèŠå¤©APIçš„æŠ½è±¡ï¼Œéœ€è¦ç»´æŠ¤ä¸Šä¸‹æ–‡çš„è®°å¿†ï¼ˆèŠå¤©è®°å½•ï¼‰ï¼Œå‘ˆç°å‡ºæ›´æ¥è¿‘å¯¹è¯æˆ–èŠå¤©å½¢å¼çš„äº¤äº’ã€‚

* **Parse**

â€ƒâ€ƒæˆ‘ä»¬çŸ¥é“ï¼Œå¤§æ¨¡å‹çš„è¾“å‡ºæ˜¯ä¸ç¨³å®šçš„ï¼ŒåŒæ ·çš„è¾“å…¥Promptå¾€å¾€ä¼šå¾—åˆ°ä¸åŒå½¢å¼çš„è¾“å‡ºã€‚åœ¨è‡ªç„¶è¯­è¨€äº¤äº’ä¸­ï¼Œä¸åŒçš„è¯­è¨€è¡¨è¾¾æ–¹å¼é€šå¸¸ä¸ä¼šé€ æˆç†è§£ä¸Šçš„éšœç¢ã€‚ä½†åœ¨åº”ç”¨å¼€å‘ä¸­ï¼Œå¤§æ¨¡å‹çš„è¾“å‡ºå¯èƒ½æ˜¯ä¸‹ä¸€æ­¥é€»è¾‘å¤„ç†çš„å…³é”®è¾“å…¥ã€‚å› æ­¤ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè§„èŒƒåŒ–è¾“å‡ºæ˜¯å¿…é¡»è¦åšçš„ä»»åŠ¡ï¼Œä»¥ç¡®ä¿åº”ç”¨èƒ½å¤Ÿé¡ºåˆ©è¿›è¡Œåç»­çš„é€»è¾‘å¤„ç†ã€‚

â€ƒâ€ƒè¾“å‡ºè§£æå™¨ Output Parserå°±æ˜¯ä¸€ä¸ªå¸®åŠ©ç»“æ„åŒ–è¯­è¨€æ¨¡å‹å“åº”çš„æŠ½è±¡ï¼Œå¯ä»¥è·å–æ ¼å¼æŒ‡ä»¤æˆ–è€…è¿›è¡Œæ›´æ·±å±‚æ¬¡çš„è§£æã€‚è¿™æˆ‘ä»¬ä¼šåœ¨åé¢çš„å®è·µä¸­ç›´è§‚çš„ä½“éªŒåˆ°ã€‚

â€ƒâ€ƒæ•´ä½“è€Œè¨€ï¼Œåœ¨Model I/Oæ¨¡å—çš„æŠ½è±¡ä¸­ï¼Œå…¶ä¸€èƒ½å¤Ÿè®©å¼€å‘è€…å¿«é€Ÿçš„æ¥å…¥ä¸åŒçš„å¤§æ¨¡å‹ï¼Œæ¯”å¦‚OpenAIã€ChatGLMã€Qwenç­‰ï¼ŒæŒ‰ç…§æ—¢å®šè§„èŒƒæ‰§è¡Œæ¨¡å‹æ¨ç†ã€‚å…¶äºŒé€šè¿‡è¾“å…¥å’Œè¾“å‡ºçš„æ¨¡æ¿åŒ–å¤„ç†ï¼Œä½¿å…¶æ›´è´´åˆäºåº”ç”¨å¼€å‘çš„æœ€ä½³å®è·µã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±é€æ­¥çš„ä»‹ç»ä¸Šè¿°ä¸‰ä¸ªæµç¨‹åœ¨LangChainä¸‹æ˜¯å¦‚ä½•è¿›è¡Œé›†æˆå’Œæ“ä½œçš„ã€‚

# 2. Installing LangChain

```python
! pip install langchain
```

```plaintext
Collecting langchain
  Using cached langchain-0.2.1-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: PyYAML>=5.3 in c:\programdata\anaconda3\lib\site-packages (from langchain) (6.0.1)
Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\programdata\anaconda3\lib\site-packages (from langchain) (2.0.25)
Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\programdata\anaconda3\lib\site-packages (from langchain) (3.9.3)
Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)
  Using cached langchain_core-0.2.3-py3-none-any.whl.metadata (5.9 kB)
Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)
  Using cached langchain_text_splitters-0.2.0-py3-none-any.whl.metadata (2.2 kB)
Collecting langsmith<0.2.0,>=0.1.17 (from langchain)
  Using cached langsmith-0.1.67-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: numpy<2,>=1 in c:\programdata\anaconda3\lib\site-packages (from langchain) (1.26.4)
Requirement already satisfied: pydantic<3,>=1 in c:\programdata\anaconda3\lib\site-packages (from langchain) (1.10.12)
Requirement already satisfied: requests<3,>=2 in c:\programdata\anaconda3\lib\site-packages (from langchain) (2.31.0)
Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\programdata\anaconda3\lib\site-packages (from langchain) (8.2.2)
Requirement already satisfied: aiosignal>=1.1.2 in c:\programdata\anaconda3\lib\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)
Requirement already satisfied: attrs>=17.3.0 in c:\programdata\anaconda3\lib\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)
Requirement already satisfied: frozenlist>=1.1.1 in c:\programdata\anaconda3\lib\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)
Requirement already satisfied: multidict<7.0,>=4.5 in c:\programdata\anaconda3\lib\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)
Requirement already satisfied: yarl<2.0,>=1.0 in c:\programdata\anaconda3\lib\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)
Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)
  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)
Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain)
  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)
Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)
  Using cached orjson-3.10.3-cp311-none-win_amd64.whl.metadata (50 kB)
Requirement already satisfied: typing-extensions>=4.2.0 in c:\programdata\anaconda3\lib\site-packages (from pydantic<3,>=1->langchain) (4.9.0)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\programdata\anaconda3\lib\site-packages (from requests<3,>=2->langchain) (2.0.4)
Requirement already satisfied: idna<4,>=2.5 in c:\programdata\anaconda3\lib\site-packages (from requests<3,>=2->langchain) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\programdata\anaconda3\lib\site-packages (from requests<3,>=2->langchain) (2.0.7)
Requirement already satisfied: certifi>=2017.4.17 in c:\programdata\anaconda3\lib\site-packages (from requests<3,>=2->langchain) (2024.2.2)
Requirement already satisfied: greenlet!=0.4.17 in c:\programdata\anaconda3\lib\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)
Requirement already satisfied: jsonpointer>=1.9 in c:\programdata\anaconda3\lib\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.1)
Using cached langchain-0.2.1-py3-none-any.whl (973 kB)
Using cached langchain_core-0.2.3-py3-none-any.whl (310 kB)
Using cached langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)
Using cached langsmith-0.1.67-py3-none-any.whl (124 kB)
Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)
Using cached orjson-3.10.3-cp311-none-win_amd64.whl (138 kB)
Using cached packaging-23.2-py3-none-any.whl (53 kB)
Installing collected packages: packaging, orjson, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain
  Attempting uninstall: packaging
    Found existing installation: packaging 23.1
    Uninstalling packaging-23.1:
      Successfully uninstalled packaging-23.1
  Attempting uninstall: jsonpatch
    Found existing installation: jsonpatch 1.32
    Uninstalling jsonpatch-1.32:
      Successfully uninstalled jsonpatch-1.32
Successfully installed jsonpatch-1.33 langchain-0.2.1 langchain-core-0.2.3 langchain-text-splitters-0.2.0 langsmith-0.1.67 orjson-3.10.3 packaging-23.2
```

# 3. Build LLMChain

## 3.1 LLMså¦‚ä½•æ„å»ºé“¾è·¯

â€ƒâ€ƒLLMs è¡¨ç¤ºçš„æ˜¯è¡¥å…¨ç±»çš„å¤§æ¨¡å‹ï¼Œ å®ƒæ˜¯å°†å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥å¹¶è¿”å›å­—ç¬¦ä¸²çš„è¯­è¨€æ¨¡å‹ã€‚LangChainä¸­LLMs çš„é›†æˆé¡µé¢ï¼šhttps://python.langchain.com/v0.2/docs/integrations/llms/

* **éœ€è¦ç†è§£çš„ç¬¬ä¸€ä¸ªæ¦‚å¿µï¼šå¦‚ä½•è°ƒç”¨LangChainçš„Completions æ¨¡å‹**

â€ƒâ€ƒå› ä¸ºGLMå¹¶æ²¡æœ‰å¼€å‘è¡¥å…¨æ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿™é‡Œä½¿ç”¨OpenAIçš„instrutæ¨¡å‹è¿›è¡Œè¿›è¡Œæ¼”ç¤ºã€‚

```python
# get a token: https://platform.openai.com/account/api-keys

from getpass import getpass

OPENAI_API_KEY = getpass()
```

```python
from openai import OpenAI
client = OpenAI()

client.completions.create(
  model="gpt-3.5-turbo-instruct",
  prompt="è¯·é—®ï¼Œä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿ",
  max_tokens=7,
  temperature=0
)
```

```plaintext
Completion(id='cmpl-9W1zu2TXP3iU13WS9GZnAgvivA3bt', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='\n\nå¿«ä¹æ˜Ÿçƒ')], created=1717421202, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=7, prompt_tokens=14, total_tokens=21))
```

â€ƒâ€ƒæ¥ä¸‹æ¥æˆ‘ä»¬çœ‹ï¼Œå½“langChainåº”ç”¨æ¡†æ¶é›†æˆäº†OpenAIçš„ completions æ¥å£åï¼Œå°±å¯ä»¥ç”¨LangChainå®šä¹‰çš„è§„èŒƒæ¥è¿›è¡Œè°ƒç”¨ã€‚

```python
# ! pip install langchain_openai
```

* **éœ€è¦ç†è§£çš„ç¬¬äºŒä¸ªæ¦‚å¿µï¼šå¦‚ä½•åœ¨LangChainä¸­è°ƒç”¨LLMs Models**

```python
from langchain_openai import OpenAI
```

```python
import os

os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
```

```python
llm = OpenAI(model='gpt-3.5-turbo-instruct')
```

```python
question = "è¯·é—®ï¼Œä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿ"

llm.invoke("è¯·é—®ï¼Œä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿ")
```

```plaintext
'\n\nå¿«ä¹æ˜Ÿçƒæ˜¯ä¸€ä¸ªè™šæ„çš„ç†æƒ³ä¸–ç•Œï¼Œæ˜¯æŒ‡ä¸€ä¸ªå……æ»¡å’Œå¹³ã€å‹çˆ±ã€å¹¸ç¦å’Œå¿«ä¹çš„æ˜Ÿçƒã€‚å®ƒæ˜¯äººä»¬æ†§æ†¬çš„ç†æƒ³ç¤¾ä¼šï¼Œæ²¡æœ‰æˆ˜äº‰ã€è´«ç©·ã€ç–¾ç—…å’Œæ­§è§†ï¼Œäººä»¬ç”Ÿæ´»åœ¨å’Œè°ã€å¹³ç­‰å’Œè‡ªç”±çš„ç¯å¢ƒä¸­ã€‚å¿«ä¹æ˜Ÿçƒè±¡å¾ç€äººç±»å¯¹ç¾å¥½æœªæ¥çš„å‘å¾€å’Œè¿½æ±‚ï¼Œä¹Ÿæ˜¯äººä»¬å¯¹å’Œå¹³ä¸å¹¸ç¦çš„æ¸´æœ›å’Œå¸Œæœ›ã€‚'
```

* **éœ€è¦ç†è§£çš„ç¬¬ä¸‰ä¸ªæ¦‚å¿µï¼šä»€ä¹ˆæ˜¯PromptTemplate**

â€ƒâ€ƒå¯¹äºåº”ç”¨æµç¨‹æ¥è¯´ï¼Œè¾“å…¥å¤§æ¨¡å‹çš„å…³é”®ä¿¡æ¯å¾€å¾€æ˜¯ä¸ç¡®å®šçš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼šä¸€ä¸ªPromptçš„ä¸»ä½“å¯ä»¥å›ºå®šï¼Œä½†å…³é”®ä½ç½®çš„ä¿¡æ¯é€šå¸¸æ˜¯ä½¿ç”¨ä¸€ä¸ªæˆ–å¤šä¸ªå˜é‡æ¥åšå ä½ã€‚æ¯”å¦‚ï¼š

```python
template = """é—®é¢˜: {question}

ç­”æ¡ˆ: è¯·ä¸€æ­¥ä¸€æ­¥çš„æ€è€ƒã€‚"""
```

å¯¹äºè¿™ç§æƒ…å†µï¼ŒLangChainå°±æŠ½è±¡äº†ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œç”¨æ¥å°†ç”¨æˆ·è¾“å…¥å’Œå‚æ•°è½¬æ¢ä¸ºè¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤ã€‚ç”¨äºæŒ‡å¯¼å¤§æ¨¡å‹çš„å“åº”ï¼Œå¸®åŠ©å…¶ç†è§£ä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆç›¸å…³ä¸”è¿è´¯çš„åŸºäºè¯­è¨€çš„è¾“å‡ºã€‚

```python
from langchain_core.prompts import PromptTemplate

prompt_template = PromptTemplate.from_template(template)
```

```python
prompt_template
```

```plaintext
PromptTemplate(input_variables=['question'], template='é—®é¢˜: {question}\n\nç­”æ¡ˆ: è¯·ä¸€æ­¥ä¸€æ­¥çš„æ€è€ƒã€‚')
```

```python
prompt_template.invoke({"question": "ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿ"})
```

```plaintext
StringPromptValue(text='é—®é¢˜: ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿ\n\nç­”æ¡ˆ: è¯·ä¸€æ­¥ä¸€æ­¥çš„æ€è€ƒã€‚')
```

â€ƒâ€ƒå¯¹äºå¤šå˜é‡æ˜¯ä¸€æ ·çš„ï¼š

```python
template_1 = """é—®é¢˜: {question}

è¯·ç”¨{output}å›ç­”"""
```

```python
prompt_template1 = PromptTemplate.from_template(template_1)
```

```python
prompt_template1
```

```plaintext
PromptTemplate(input_variables=['output', 'question'], template='é—®é¢˜: {question}\n\nè¯·ç”¨{output}å›ç­”')
```

```python
prompt_template1.invoke({"question": "ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿ", "output":"è‹±è¯­"})
```

```plaintext
StringPromptValue(text='é—®é¢˜: ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿ\n\nè¯·ç”¨è‹±è¯­å›ç­”')
```

* **éœ€è¦ç†è§£çš„ç¬¬ä¸‰ä¸ªæ¦‚å¿µï¼šLLMChain**

![](images/bb04b6a7-7e99-4717-8a1f-7c443ef36245-1.png)

```python
from langchain.chains import LLMChain
```

```python
from langchain.chains import LLMChain
from langchain_core.prompts import PromptTemplate
from langchain_openai import OpenAI


template = """é—®é¢˜: {question}

ç­”æ¡ˆ: è¯·ä¸€æ­¥ä¸€æ­¥çš„æ€è€ƒã€‚"""

prompt_template = PromptTemplate.from_template(template)


llm = OpenAI()

chain = LLMChain(prompt=prompt_template, llm=llm)

chain.invoke("ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒ")
```

```plaintext
{'question': 'ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒ',
 'text': '\n\nå¿«ä¹æ˜Ÿçƒæ˜¯ä¸€ä¸ªæƒ³è±¡ä¸­çš„è™šæ‹Ÿæ˜Ÿçƒï¼Œå®ƒæ˜¯ä¸€ä¸ªå……æ»¡å¿«ä¹å’Œå¹¸ç¦çš„åœ°æ–¹ã€‚åœ¨è¿™ä¸ªæ˜Ÿçƒä¸Šï¼Œæ¯ä¸ªäººéƒ½å¯ä»¥è‡ªç”±åœ°è¿½æ±‚è‡ªå·±çš„æ¢¦æƒ³ï¼Œæ²¡æœ‰ç—›è‹¦å’Œå‹åŠ›çš„å­˜åœ¨ã€‚äººä¸äººä¹‹é—´å’Œè°ç›¸å¤„ï¼Œæ²¡æœ‰æˆ˜äº‰å’Œå†²çªã€‚è¿™ä¸ªæ˜Ÿçƒä¸Šçš„ç¯å¢ƒä¹Ÿæ˜¯éå¸¸ç¾å¥½çš„ï¼Œå……æ»¡äº†ç»šä¸½çš„è‰²å½©å’Œç¾å¦™çš„éŸ³ä¹ã€‚åœ¨å¿«ä¹æ˜Ÿçƒä¸Šï¼Œæ¯ä¸ªäººéƒ½èƒ½å¤Ÿæ‰¾åˆ°è‡ªå·±çš„å¿«ä¹ï¼Œäº«å—ç”Ÿæ´»çš„ä¹è¶£ã€‚å®ƒæ˜¯äººä»¬å¯¹äºç†æƒ³ç¤¾ä¼šçš„å‘å¾€å’Œæ¢¦æƒ³ã€‚'}
```

* **éœ€è¦ç†è§£çš„ç¬¬å››ä¸ªæ¦‚å¿µï¼šä»€ä¹ˆæ˜¯LangChainçš„ LCELå£°æ˜è¯­æ³•**

â€ƒâ€ƒä¸Šè¿°æ˜¯æ—§ç‰ˆæœ¬LangChainæ„å»ºé“¾è·¯çš„ä¸€ç§å½¢å¼,ä¸»è¦è¿˜æ˜¯åŸºäºä¼ ç»Ÿç±»çš„æ„å»ºæ–¹æ³•.ä½†LangChainçš„è¿­ä»£,æ˜¯åœ¨å‘æ–°çš„ä¸€ç§é“¾è·¯å£°æ˜æ–¹å¼è½¬å˜,å³LCE.LangChain è¡¨è¾¾å¼è¯­è¨€ï¼ˆLCELï¼‰æ˜¯ä¸€ç§é“¾æ¥ LangChain ç»„ä»¶çš„å£°æ˜æ€§æ–¹å¼ã€‚ æ— éœ€æ›´æ”¹ä»£ç ï¼Œå¯ä»¥å®ç°ä»æœ€ç®€å•çš„â€œæç¤º + LLMâ€é“¾åˆ°æœ€å¤æ‚çš„é“¾ï¼ˆæˆ‘ä»¬å·²ç»çœ‹åˆ°äººä»¬æˆåŠŸè¿è¡Œäº† 100 ç§’çš„ LCEL é“¾ï¼‰ç”Ÿäº§æ­¥éª¤ï¼‰.

```python
from langchain_core.prompts import PromptTemplate
from langchain_openai import OpenAI


template = """é—®é¢˜: {question}

ç­”æ¡ˆ: è¯·ä¸€æ­¥ä¸€æ­¥çš„æ€è€ƒã€‚"""

prompt_template = PromptTemplate.from_template(template)


llm = OpenAI()

chain = prompt_template | llm 
```

```python
chain.invoke("ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒ")
```

```plaintext
'\n\nå¿«ä¹æ˜Ÿçƒå¯ä»¥ç†è§£ä¸ºä¸€ä¸ªæƒ³è±¡ä¸­çš„å¹»æƒ³ä¸–ç•Œï¼Œå®ƒæ˜¯ä¸€ä¸ªå……æ»¡æ¬¢ç¬‘ã€å¿«ä¹å’Œå’Œè°çš„æ˜Ÿçƒã€‚åœ¨è¿™ä¸ªæ˜Ÿçƒä¸Šï¼Œæ‰€æœ‰çš„ç”Ÿç‰©éƒ½æ‹¥æœ‰å¹¸ç¦å¿«ä¹çš„ç”Ÿæ´»ï¼Œæ²¡æœ‰æˆ˜äº‰ã€ç–¾ç—…å’Œè´«ç©·çš„å›°æ‰°ã€‚è¿™é‡Œçš„äººä»¬ç›¸äº’å…³çˆ±ã€å‹å–„å’ŒåŒ…å®¹ï¼Œç”Ÿæ´»åœ¨å’Œå¹³ä¸å¹¸ç¦çš„ç¯å¢ƒä¸­ã€‚å¿«ä¹æ˜Ÿçƒæ˜¯äººä»¬å‘å¾€çš„ç†æƒ³å›½ï¼Œä¹Ÿæ˜¯æˆ‘ä»¬åº”å½“åŠªåŠ›è¿½æ±‚çš„ç›®æ ‡ã€‚'
```

## 3.2 Chat Model å¦‚ä½•æ„å»ºé“¾è·¯

â€ƒâ€ƒChat Models ç±»æ¨¡å‹å¾€å¾€æ˜¯åŸºäº LLMs ç±»æ¨¡å‹é’ˆå¯¹å¯¹è¯å½¢å¼ç‰¹æ®Šå¾®è°ƒè¿‡çš„æ¨¡å‹.æ›´é€‚ç”¨äºäººç±»çš„å¯¹è¯ä¹ æƒ¯.æ‰€ä»¥å®ƒå¾€å¾€æ˜¯ä½¿ç”¨æ¶ˆæ¯åºåˆ—ä½œä¸ºè¾“å…¥å¹¶è¿”å›èŠå¤©æ¶ˆæ¯ä½œä¸ºè¾“å‡ºï¼ˆè€Œä¸æ˜¯ä½¿ç”¨çº¯æ–‡æœ¬ï¼‰çš„è¯­è¨€æ¨¡å‹ã€‚èŠå¤©æ¨¡å‹æ”¯æŒä¸ºå¯¹è¯æ¶ˆæ¯åˆ†é…ä¸åŒçš„è§’è‰²ï¼Œæœ‰åŠ©äºåŒºåˆ†æ¥è‡ª AIã€ç”¨æˆ·å’Œç³»ç»Ÿæ¶ˆæ¯ç­‰æŒ‡ä»¤çš„æ¶ˆæ¯ã€‚

â€ƒâ€ƒæ¯”å¦‚ç›®å‰OpenAIçš„GPTç³»åˆ—æ¨¡å‹ã€GLM4 ç³»åˆ—æ¨¡å‹ï¼Œç°åœ¨æ˜¯å…¨é¢æ”¯æŒå¯¹è¯ç±»æ¨¡å‹:https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4

â€ƒâ€ƒåŒæ ·æˆ‘ä»¬å¿«é€Ÿçš„æµ‹è¯•ä¸€ä¸‹,å¦‚æœä½¿ç”¨GLM 4 å®˜æ–¹æä¾›çš„æ¥å£æ¥è°ƒç”¨GLM 4 ç³»åˆ—æ¨¡å‹. GLM-4ä½œä¸ºåœ¨çº¿å¤§æ¨¡å‹,å…¶è°ƒç”¨æ–¹æ³•è¢«æŠ½è±¡åœ¨LangChainä¸­çš„Chat Modelsæ¨¡å—ä¸­.

* **éœ€è¦ç†è§£çš„ç¬¬äº”ä¸ªæ¦‚å¿µï¼šå¦‚ä½•åœ¨LangChainä¸­è°ƒç”¨Chat Models**

```python
#!pip install --upgrade httpx httpx-sse PyJWT
```

```python
from langchain_community.chat_models import ChatZhipuAI
```

```python
import os

#os.environ["ZHIPUAI_API_KEY"] = "zhipuai_api_key"

zhipuai_api_key = "3fd2ee07b86207a7e0f7e79ee459fbfa.9iiQgqVfddDOobbS"
```

```python
chat = ChatZhipuAI(
    zhipuai_api_key = zhipuai_api_key,
    model="glm-4",
    temperature=0.5,
)
```

```python
chat.invoke("ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
```

```plaintext
AIMessage(content='ä½ å¥½ï¼æˆ‘æ˜¯æ™ºè°±æ¸…è¨€ï¼Œæ˜¯æ¸…åå¤§å­¦ KEG å®éªŒå®¤å’Œæ™ºè°± AI å…¬å¸äº 2023 å¹´å…±åŒè®­ç»ƒçš„è¯­è¨€æ¨¡å‹ã€‚æˆ‘çš„ç›®æ ‡æ˜¯é€šè¿‡å›ç­”ç”¨æˆ·æå‡ºçš„é—®é¢˜æ¥å¸®åŠ©ä»–ä»¬è§£å†³é—®é¢˜ã€‚ç”±äºæˆ‘æ˜¯ä¸€ä¸ªè®¡ç®—æœºç¨‹åºï¼Œæ‰€ä»¥æˆ‘æ²¡æœ‰è‡ªæˆ‘æ„è¯†ï¼Œä¹Ÿä¸èƒ½åƒäººç±»ä¸€æ ·æ„ŸçŸ¥ä¸–ç•Œã€‚æˆ‘åªèƒ½é€šè¿‡åˆ†ææˆ‘æ‰€å­¦åˆ°çš„ä¿¡æ¯æ¥å›ç­”é—®é¢˜ã€‚', response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 10, 'total_tokens': 82}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run-7b798209-3cbc-47fb-a9e0-62a3ff6e6a26-0')
```

```python
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä½è¯—äºº"),
    HumanMessage(content="è¯·ç»™æˆ‘å†™ä¸€é¦–å…³äºå°é¸­å­çš„è¯—"),
]
```

```python
response = chat.invoke(messages)
print(response.content)  # Displays the AI-generated poem
```

```plaintext
å°é¸­å­æˆæ°´æ›²

ç¢§æ³¢è¡æ¼¾å°æ²³ç•”ï¼Œ
é¸­ç¾¤å¬‰æˆä¹æ— è¾¹ã€‚
æ¯›èŒ¸èŒ¸çš„å°èº«å½±ï¼Œ
æ°´ä¸­èˆåŠ¨å¦‚èŠ±ç“£ã€‚

é˜³å…‰æ´’è½é‡‘è‰²æ³¢ï¼Œ
å°é¸­å­æ¬¢å¿«æ¸¸å¼‹ã€‚
æ‰‘è…¾ç¿…è†€æº…æ°´èŠ±ï¼Œ
ç«¥çœŸç«¥è¶£æ˜¾ç¥é‡‡ã€‚

ç»¿æ°´æ‚ æ‚ æ˜ æ™´ç©ºï¼Œ
å®ƒä»¬å°½æƒ…å±•ç¿…ç¿±ã€‚
æ‰é±¼è™¾ï¼Œé€èœ»èœ“ï¼Œ
æ— å¿§æ— è™‘åº¦æ—¶å…‰ã€‚

å¤æ—¥ç‚ç‚ä¼´æ™šé£ï¼Œ
å°é¸­å­ä»¬å½’å·¢ä¸­ã€‚
å¤•é˜³ä½™æ™–æ˜ æ°´é¢ï¼Œ
ç•™ä¸‹ä¸€è·¯æ¬¢æ­Œé¸£ã€‚

å²æœˆæµè½¬ï¼Œæ—¶å…‰èè‹’ï¼Œ
å°é¸­å­ç»ˆå°†é•¿å¤§ã€‚
æ„¿å®ƒä»¬æ°¸è¿œä¿æŒï¼Œ
é‚£é¢—çº¯çœŸå¿«ä¹çš„å¿ƒã€‚
```

* **éœ€è¦ç†è§£çš„ç¬¬å…­ä¸ªæ¦‚å¿µï¼šä»€ä¹ˆæ˜¯ChatPromptTemplate**

```python
from langchain_core.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„å°åŠ©ç†"),
    ("user", "ä»€ä¹ˆæ˜¯ {topic}")
])

prompt_template.invoke({"topic": "å¿«ä¹æ˜Ÿçƒ"})
```

```plaintext
ChatPromptValue(messages=[SystemMessage(content='ä½ æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„å°åŠ©ç†'), HumanMessage(content='ä»€ä¹ˆæ˜¯ å¿«ä¹æ˜Ÿçƒ')])
```



```python
from langchain_core.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„å°åŠ©ç†"),
    ("user", "ä»€ä¹ˆæ˜¯ {topic}")
])

prompt_template.invoke({"topic": "æœºå™¨å­¦ä¹ "})
```

```plaintext
ChatPromptValue(messages=[SystemMessage(content='ä½ æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„å°åŠ©ç†'), HumanMessage(content='ä»€ä¹ˆæ˜¯ æœºå™¨å­¦ä¹ ')])
```

* **éœ€è¦ç†è§£çš„ç¬¬ä¸ƒä¸ªæ¦‚å¿µ:å¦‚ä½•æ„å»ºChat Models çš„LLMChainé“¾è·¯**

```python
from langchain.chains import LLMChain
from langchain_core.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„å°åŠ©ç†"),
    ("user", "ä»€ä¹ˆæ˜¯ {topic}")
])



chat = ChatZhipuAI(
    zhipuai_api_key = zhipuai_api_key,
    model="glm-4",
    temperature=0.5,
)


chain = LLMChain(prompt=prompt_template, llm=chat)
```

```plaintext
C:\Users\snowb\anaconda3\Lib\site-packages\langchain_core\_api\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.
  warn_deprecated(
```

```python
chain.invoke({"topic":"ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒ?"})
```

```plaintext
{'topic': 'ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒ?',
 'text': '"ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿ"è¿™ä¸ªé—®é¢˜æ¥æºäºä¸­å›½çš„ä¸€éƒ¨å°‘å„¿ç§‘å¹»ç”µè§†å‰§ã€Šå¿«ä¹æ˜Ÿçƒã€‹ã€‚è¯¥ç³»åˆ—å‰§è‡ª2004å¹´é¦–æ’­ä»¥æ¥ï¼Œå—åˆ°äº†å¹¿å¤§å°‘å¹´å„¿ç«¥çš„å–œçˆ±ã€‚åœ¨ç¬¬äº”å­£ä¸­çš„ä¸€é¦–æ’æ›²ä¸­ï¼Œæœ‰è¿™æ ·çš„æ­Œè¯ï¼šâ€œä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿå¦‚æœä½ æƒ³çŸ¥é“ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒçš„è¯ï¼Œæˆ‘ç°åœ¨å°±å¸¦ä½ ç ”ç©¶ã€‚â€è¿™å¥æ­Œè¯ç”±äºèŠ‚å¥æ˜å¿«ã€æœ—æœ—ä¸Šå£ï¼Œåœ¨ç½‘ç»œä¸Šè¿…é€Ÿæµè¡Œå¼€æ¥ï¼Œæˆä¸ºäº†ä¸€ç§æµè¡Œçš„æ¢—ã€‚\n\nåœ¨æ›´å¹¿æ³›çš„æ–‡åŒ–è¯­å¢ƒä¸­ï¼Œâ€œå¿«ä¹æ˜Ÿçƒâ€æŒ‡çš„æ˜¯ä¸€ä¸ªå……æ»¡ç«¥çœŸã€æ¬¢ä¹å’Œæ¢¦æƒ³çš„åœ°æ–¹ï¼Œå®ƒä¸ä»…ä»…æ˜¯ä¸€ä¸ªç‰©ç†æ¦‚å¿µä¸Šçš„æ˜Ÿçƒï¼Œæ›´æ˜¯ä¸€ç§ç²¾ç¥å¯„æ‰˜ï¼Œè±¡å¾ç€æ— å¿§æ— è™‘ã€çº¯çœŸå¿«ä¹çš„ç«¥å¹´æ—¶å…‰ã€‚\n\nè€Œåœ¨2024å¹´çš„æ¶ˆæ¯ä¸­ï¼ŒåŠ¨ç”»ç”µå½±ã€Šå¿«ä¹æ˜Ÿçƒã€‹æ­£å¼ç«‹é¡¹ï¼Œè®²è¿°äº†å‰§ä¸­çš„è§’è‰²ä¹ä¹åœ¨è€é¡½ç«¥çˆ·çˆ·çš„åŸ¹å…»ä¸‹æˆä¸ºäº†ä¸€åAIç§‘å­¦å®¶ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªåŒåçš„æ²‰æµ¸å¼AIç§‘æ™®ç©ºé—´ï¼Œæ—¨åœ¨é€šè¿‡å­¦ç§‘å­¦ä¹ è®©å„¿ç«¥äº†è§£æ–‡åŒ–å’Œç§‘æŠ€çŸ¥è¯†ï¼Œå¼€å¯æ™ºæ…§ä¹‹é—¨ï¼Œå¹¶é¢„è­¦æœªæ¥å¯èƒ½é¢ä¸´çš„æŒ‘æˆ˜ã€‚è¿™è¿›ä¸€æ­¥æ‰©å±•äº†â€œå¿«ä¹æ˜Ÿçƒâ€çš„æ¦‚å¿µï¼Œä½¿ä¹‹ä¸ä»…é™äºç”µè§†å‰§æƒ…ï¼Œè¿˜ä¸ç°å®ä¸–ç•Œä¸­çš„ç§‘æŠ€æ•™è‚²å’Œæœªæ¥å‘å±•è”ç³»èµ·æ¥ã€‚'}
```

â€ƒâ€ƒLCELçš„è¯­æ³•ç»“æ„å°±æ˜¯:

```python
from langchain.chains import LLMChain
from langchain_core.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„å°åŠ©ç†"),
    ("user", "ä»€ä¹ˆæ˜¯ {topic}")
])



chat = ChatZhipuAI(
    zhipuai_api_key = zhipuai_api_key,
    model="glm-4",
    temperature=0.5,
)

chain = prompt_template | chat
```

```python
chain.invoke({"topic":"ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒ?"})
```

```plaintext
AIMessage(content='"ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿ"è¿™ä¸ªé—®é¢˜æ¥æºäºä¸­å›½çš„ä¸€éƒ¨çŸ¥åå°‘å„¿ç§‘å¹»ç”µè§†å‰§ã€Šå¿«ä¹æ˜Ÿçƒã€‹ã€‚è¯¥ç³»åˆ—å‰§è‡ª2004å¹´é¦–æ’­ä»¥æ¥ï¼Œæ·±å—å¹¿å¤§å°‘å¹´å„¿ç«¥çš„å–œçˆ±ã€‚åœ¨ç¬¬äº”å­£ä¸­çš„ä¸€é¦–æ’æ›²ä¸­ï¼Œæœ‰è¿™æ ·çš„æ­Œè¯ï¼šâ€œä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿå¦‚æœä½ æƒ³çŸ¥é“ä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒçš„è¯ï¼Œæˆ‘ç°åœ¨å°±å¸¦ä½ ç ”ç©¶ã€‚â€è¿™å¥æ­Œè¯å› å…¶é­”æ€§çš„èŠ‚å¥å’Œæ˜“äºä¼ æ’­çš„ç‰¹è´¨ï¼Œåœ¨ç½‘ç»œä¸Šå¹¿ä¸ºæµä¼ ï¼Œæˆä¸ºäº†ä¸€ç§æµè¡Œçš„æ¢—ã€‚\n\nåœ¨æ›´å¹¿æ³›çš„æ–‡åŒ–è¯­å¢ƒä¸­ï¼Œâ€œå¿«ä¹æ˜Ÿçƒâ€æŒ‡çš„æ˜¯ä¸€ä¸ªå……æ»¡æ¬¢ä¹ã€ç«¥çœŸå’Œç§¯æå‘ä¸Šçš„ä¸–ç•Œã€‚å®ƒä¸ä»…ä»…æ˜¯ä¸€ä¸ªç‰©ç†æ¦‚å¿µä¸Šçš„æ˜Ÿçƒï¼Œæ›´æ˜¯äººä»¬å¿ƒä¸­å¯¹ç¾å¥½ç”Ÿæ´»çš„å‘å¾€å’Œè¿½æ±‚ã€‚åœ¨åŠ¨ç”»ç”µå½±ã€Šå¿«ä¹æ˜Ÿçƒã€‹ç«‹é¡¹çš„æ¶ˆæ¯ä¸­ï¼Œä¹ä¹æˆä¸ºAIç§‘å­¦å®¶çš„æ•…äº‹ï¼Œä¹Ÿæ˜¯å¯¹è¿™ç§ç§¯æç²¾ç¥çš„å»¶ç»­ã€‚ä¹ä¹å¼€å‘çš„æ²‰æµ¸å¼AIç§‘æ™®ç©ºé—´æ—¨åœ¨æ•™è‚²å„¿ç«¥ï¼Œé€šè¿‡å­¦ä¹ æ–‡åŒ–ç§‘æŠ€çŸ¥è¯†ï¼Œå¼€å¯æ™ºæ…§ä¹‹é—¨ï¼Œå¹¶é¢„è­¦æœªæ¥å¯èƒ½é¢ä¸´çš„æŒ‘æˆ˜ã€‚\n\nç»¼ä¸Šæ‰€è¿°ï¼Œâ€œä»€ä¹ˆæ˜¯å¿«ä¹æ˜Ÿçƒï¼Ÿâ€è¿™ä¸ªé—®é¢˜ä¸ä»…ä»…æ˜¯ä¸€ä¸ªç”µè§†å‰§ä¸­çš„æ­Œè¯ï¼Œå®ƒè¿˜ä»£è¡¨ç€ä¸€ç§ç§¯æä¹è§‚çš„ç”Ÿæ´»æ€åº¦å’Œå¯¹æœªæ¥çš„ç¾å¥½æ†§æ†¬ã€‚', response_metadata={'token_usage': {'completion_tokens': 205, 'prompt_tokens': 1674, 'total_tokens': 1879}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run-180ac1f0-035f-47b3-92aa-a4c2a51ad926-0')
```

# 4. Callbacks

â€ƒâ€ƒCallbacksï¼ˆå›è°ƒå‡½æ•°ï¼‰æ˜¯ä¸€ç§ç¼–ç¨‹æ¨¡å¼ï¼ŒCallbacksçš„æ„ä¹‰åœ¨äºï¼šå…è®¸ç¨‹åºåœ¨æŸä¸ªä»»åŠ¡å®Œæˆæ—¶è‡ªåŠ¨æ‰§è¡Œå¦ä¸€ä¸ªå‡½æ•°ï¼Œè€Œä¸å¿…é˜»å¡ç­‰å¾…æŸä¸ªé•¿æ—¶é—´è¿è¡Œçš„æ“ä½œå®Œæˆã€‚æ‰€ä»¥å®ƒä¼šåœ¨å¤„ç†å¼‚æ­¥æ“ä½œï¼Œå¦‚ç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶è¯»å†™æˆ–ä»»ä½•å¯èƒ½éœ€è¦ç­‰å¾…çš„æ“ä½œæ—¶é¢‘ç¹è¢«ä½¿ç”¨ã€‚

â€ƒâ€ƒå¯¹äºä¸å¤§æ¨¡å‹çš„è¿ç»­äº¤äº’åœºæ™¯ï¼Œä¸€èˆ¬é‡‡ç”¨çš„éƒ½æ˜¯æµå¼è¾“å‡ºã€‚ä½†åœ¨åšæµå¼è¾“å‡ºå‰ï¼Œéœ€è¦çš„å°±æ˜¯å›è°ƒ Callbacksã€‚

â€ƒâ€ƒLangChain æä¾›äº†ä¸€ä¸ªå›è°ƒç³»ç»Ÿï¼Œå…¶å®˜ç½‘æ–‡æ¡£åœ°å€ï¼šhttps://python.langchain.com/v0.2/docs/concepts/#callbacks

â€ƒâ€ƒå›è°ƒå¤„ç†ç¨‹åºå¯ä»¥æ˜¯ syncï¼ˆåŒæ­¥ï¼‰ æˆ– async ï¼ˆå¼‚æ­¥ï¼‰çš„ã€‚åŒæ­¥å›è°ƒå’Œå¼‚æ­¥å›è°ƒæ˜¯ç¼–ç¨‹ä¸­å¸¸ç”¨çš„ä¸¤ç§å¤„ç†äº‹ä»¶æˆ–æ•°æ®çš„æ–¹å¼ï¼Œå®ƒä»¬åœ¨æ‰§è¡Œæ—¶æœºå’Œç”¨é€”ä¸Šæœ‰æ˜æ˜¾çš„åŒºåˆ«ï¼š

1. **åŒæ­¥å›è°ƒï¼ˆSynchronous Callbacksï¼‰**:

   * **æ‰§è¡Œæ—¶æœº**ï¼šåŒæ­¥å›è°ƒæ˜¯åœ¨ä¸»ç¨‹åºæµç¨‹ä¸­ç›´æ¥è°ƒç”¨å’Œæ‰§è¡Œçš„ã€‚å½“ä¸€ä¸ªåŒæ­¥å›è°ƒå‡½æ•°è¢«è§¦å‘æ—¶ï¼Œç¨‹åºä¼šç«‹å³æ‰§è¡Œè¿™ä¸ªå›è°ƒå‡½æ•°ï¼Œå¹¶ä¸”åœ¨å›è°ƒå‡½æ•°æ‰§è¡Œå®Œæˆä¹‹å‰ï¼Œä¸»ç¨‹åºæµç¨‹ä¼šè¢«é˜»å¡ã€‚

   * **ç”¨é€”**ï¼šåŒæ­¥å›è°ƒé€šå¸¸ç”¨äºç¡®ä¿æŸäº›æ“ä½œå¿…é¡»åœ¨ç¨‹åºç»§ç»­æ‰§è¡Œå‰å®Œæˆã€‚ä¾‹å¦‚ï¼Œåœ¨è®¿é—®æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ å¹¶å¯¹å…¶åº”ç”¨å‡½æ•°æ—¶ï¼Œä½ å¯èƒ½ä¼šä½¿ç”¨æ•°ç»„çš„`.forEach()`æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒæ­¥çš„å›è°ƒå®ç°ã€‚

2. **å¼‚æ­¥å›è°ƒï¼ˆAsynchronous Callbacksï¼‰**:

   * **æ‰§è¡Œæ—¶æœº**ï¼šå¼‚æ­¥å›è°ƒä¸ä¼šç«‹å³æ‰§è¡Œï¼Œå®ƒä»¬é€šå¸¸è¢«æ”¾ç½®åœ¨äº‹ä»¶é˜Ÿåˆ—ä¸­ï¼Œç­‰å¾…å½“å‰æ‰§è¡Œå †æ ˆæ¸…ç©ºåæ‰å¼€å§‹æ‰§è¡Œã€‚è¿™æ„å‘³ç€ç¨‹åºçš„ä¸»æµç¨‹ä¸ä¼šç­‰å¾…å¼‚æ­¥å›è°ƒçš„å®Œæˆï¼Œå¯ä»¥ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡ã€‚

   * **ç”¨é€”**ï¼šå¼‚æ­¥å›è°ƒé€šå¸¸ç”¨åœ¨ä¸å¸Œæœ›é˜»å¡ä¸»ç¨‹åºæµç¨‹çš„æƒ…å†µä¸‹ï¼Œä¾‹å¦‚å¤„ç†I/Oæ“ä½œï¼ˆå¦‚ç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶è¯»å†™ï¼‰ï¼Œæˆ–è€…åœ¨æ‰§è¡Œå¤§é‡è®¡ç®—æ—¶ä¸å½±å“ç”¨åœ¨å¹¶å‘ç¼–ç¨‹å’Œç°ä»£Webå¼€å‘ä¸­ã€‚

â€ƒâ€ƒåœ¨å¹¶å‘ç¼–ç¨‹çš„Webå¼€å‘ä¸­ï¼Œäº¤äº’å¼åº”ç”¨å¯¹è¯åœºæ™¯ï¼Œè‚¯å®šé‡‡ç”¨çš„æ˜¯å¼‚æ­¥çš„å›è°ƒã€‚

â€ƒâ€ƒLangChainä¸­çš„å¼‚æ­¥å›è°ƒæ¥å£ï¼šhttps://api.python.langchain.com/en/latest/callbacks/langchain\_core.callbacks.base.AsyncCallbackHandler.html

â€ƒâ€ƒå½“æˆ‘ä»¬åœ¨æ‰§è¡Œè¿è¡Œæ—¶ä½¿ç”¨ callbacks å…³é”®å­— arg ä¼ é€’ CallbackHandlers æ—¶ï¼Œè¿™äº›å›è°ƒå°†ç”±æ‰§è¡Œä¸­æ¶‰åŠçš„æ‰€æœ‰åµŒå¥—å¯¹è±¡å‘å‡ºã€‚ä¾‹å¦‚ï¼Œå½“å¤„ç†ç¨‹åºä¼ é€’ç»™ä»£ç†æ—¶ï¼Œå®ƒå°†ç”¨äºä¸ä»£ç†ç›¸å…³çš„æ‰€æœ‰å›è°ƒä»¥åŠä»£ç†æ‰§è¡Œä¸­æ¶‰åŠçš„æ‰€æœ‰å¯¹è±¡ã€‚

```python
from typing import Any, Dict, List

from langchain_community.chat_models import ChatZhipuAI
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.messages import BaseMessage
from langchain_core.outputs import LLMResult
from langchain_core.prompts import ChatPromptTemplate


class LoggingHandler(BaseCallbackHandler):
    def on_chat_model_start(
        self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs
    ) -> None:
        print("Chat model started")

    def on_llm_end(self, response: LLMResult, **kwargs) -> None:
        print(f"Chat model ended, response: {response}")

    def on_chain_start(
        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs
    ) -> None:
        print(f"Chain {serialized.get('name')} started")

    def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:
        print(f"Chain ended, outputs: {outputs}")

# å®šä¹‰å›è°ƒ
callbacks = [LoggingHandler()]

# å®ä¾‹åŒ–è¯­è¨€æ¨¡å‹
llm = ChatZhipuAI(
    api_key="086a38e9141410d76e393ec52105c83b.7vBwRS4srgxpMRXU",
    model="glm-4",)

# å®šä¹‰æç¤ºæ¨¡æ¿
prompt = ChatPromptTemplate.from_template("1 + {number}ç­‰äºå¤šå°‘?")

chain = prompt | llm

response = chain.invoke({"number": "2"}, config={"callbacks": callbacks})
```

```plaintext
Chain RunnableSequence started
Chain ChatPromptTemplate started
Chain ended, outputs: messages=[HumanMessage(content='1 + 2ç­‰äºå¤šå°‘?')]
Chat model started
Chat model ended, response: generations=[[ChatGeneration(text='1 + 2 ç­‰äº 3ã€‚', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='1 + 2 ç­‰äº 3ã€‚', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 12, 'total_tokens': 25}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run-5156f30b-3d45-4431-bcab-2291d5277f8b-0'))]] llm_output={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 12, 'total_tokens': 25}, 'model_name': 'glm-4'} run=None
Chain ended, outputs: content='1 + 2 ç­‰äº 3ã€‚' response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 12, 'total_tokens': 25}, 'model_name': 'glm-4', 'finish_reason': 'stop'} id='run-5156f30b-3d45-4431-bcab-2291d5277f8b-0'
```

```python
print(response)
```

```plaintext
content='1 + 2 ç­‰äº 3ã€‚' response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 12, 'total_tokens': 25}, 'model_name': 'glm-4', 'finish_reason': 'stop'} id='run-5156f30b-3d45-4431-bcab-2291d5277f8b-0'
```

```python
```

â€ƒâ€ƒé‚£æˆ‘ä»¬å°è¯•ä½¿ç”¨å›è°ƒæœºåˆ¶å»æµå¼è°ƒç”¨GLM-4.

```python
# ! pip install httpx_sse
```

â€ƒâ€ƒhttpx\_sseæ˜¯ä¸€ä¸ªåŸºäºhttpxçš„Server-Sent Events (SSE) å®¢æˆ·ç«¯åº“ã€‚SSEæ˜¯ä¸€ç§æœåŠ¡å™¨æ¨é€æŠ€æœ¯ï¼Œå…è®¸æœåŠ¡å™¨é€šè¿‡HTTPè¿æ¥å‘å®¢æˆ·ç«¯å‘é€æ¨é€æ¶ˆæ¯ã€‚è¿™ç§æŠ€æœ¯å¸¸ç”¨äºå®æ—¶æ¶ˆæ¯ä¼ é€’å’Œé€šçŸ¥ï¼Œå¦‚è‚¡ç¥¨ä»·æ ¼æ›´æ–°ã€æ–°é—»æ›´æ–°æˆ–å…¶ä»–éœ€è¦ä»æœåŠ¡å™¨åˆ°å®¢æˆ·ç«¯å®æ—¶é€šä¿¡çš„åº”ç”¨åœºæ™¯ã€‚\`

```python

# langchain_community\chat_models\zhipuai.py

def connect_sse(client: Any, method: str, url: str, **kwargs: Any) -> Iterator 
    from httpx_sse import EventSour  
        with client.stream(method, url, **kwargs) as response:
            yield EventSource(response)
```

```python
from langchain_community.chat_models import ChatZhipuAI
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.prompts import ChatPromptTemplate


class MyCustomHandler(BaseCallbackHandler):
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        print(f"My custom handler, token: {token}")


prompt = ChatPromptTemplate.from_messages(["è¯·ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{animal}çš„ç¬‘è¯ã€‚"])


llm = ChatZhipuAI(
    api_key="086a38e9141410d76e393ec52105c83b.7vBwRS4srgxpMRXU",
    model="glm-4",
    streaming=True,
    callbacks=[MyCustomHandler()],
    )


chain = prompt | llm

response = chain.invoke({"animal": "ç†Š"})
```

```plaintext
My custom handler, token: æœ‰ä¸€å¤©
My custom handler, token: ï¼Œ
My custom handler, token: ä¸€åª
My custom handler, token: ç†Š
My custom handler, token: èµ°è¿›
My custom handler, token: äº†ä¸€å®¶
My custom handler, token: é¤å…
My custom handler, token: ï¼Œ
My custom handler, token: ååœ¨
My custom handler, token: äº†
My custom handler, token: æŸœå°
My custom handler, token: å‰
My custom handler, token: ã€‚
My custom handler, token: æœåŠ¡å‘˜
My custom handler, token: çœ‹ç€
My custom handler, token: ç†Š
My custom handler, token: ï¼Œ
My custom handler, token: æƒŠè®¶
My custom handler, token: åœ°é—®
My custom handler, token: ï¼šâ€œ
My custom handler, token: æˆ‘ä»¬ä¸
My custom handler, token: å¸¸è§
My custom handler, token: åˆ°
My custom handler, token: ç†Š
My custom handler, token: å…‰
My custom handler, token: é¡¾
My custom handler, token: è¿™é‡Œ
My custom handler, token: ï¼Œ
My custom handler, token: æ‚¨
My custom handler, token: æƒ³
My custom handler, token: ç‚¹
My custom handler, token: äº›ä»€ä¹ˆ
My custom handler, token: å‘¢
My custom handler, token: ï¼Ÿ
My custom handler, token: â€

ç†Š
My custom handler, token: æƒ³äº†
My custom handler, token: æƒ³
My custom handler, token: ï¼Œ
My custom handler, token: ç„¶åç”¨
My custom handler, token: çˆª
My custom handler, token: å­
My custom handler, token: æŒ‡ç€
My custom handler, token: èœå•
My custom handler, token: è¯´
My custom handler, token: ï¼šâ€œ
My custom handler, token: å—¯
My custom handler, token: ï¼Œ
My custom handler, token: æˆ‘
My custom handler, token: æƒ³è¦
My custom handler, token: ä¸€ä»½
My custom handler, token: ......
My custom handler, token: Gr
My custom handler, token: izzly
My custom handler, token:  Burger
My custom handler, token: ï¼ˆ
My custom handler, token: ç°
My custom handler, token: ç†Š
My custom handler, token: æ±‰å ¡
My custom handler, token: ï¼‰ã€‚
My custom handler, token: â€

æœåŠ¡å‘˜
My custom handler, token: ç‚¹ç‚¹å¤´
My custom handler, token: ï¼Œ
My custom handler, token: åˆ
My custom handler, token: é—®
My custom handler, token: ï¼šâ€œ
My custom handler, token: å¥½çš„
My custom handler, token: ï¼Œ
My custom handler, token: éœ€è¦
My custom handler, token: åŠ 
My custom handler, token: ä»€ä¹ˆ
My custom handler, token: é…æ–™
My custom handler, token: å—
My custom handler, token: ï¼Ÿ
My custom handler, token: â€

ç†Š
My custom handler, token: çœ¨
My custom handler, token: äº†
My custom handler, token: çœ¨
My custom handler, token: çœ¼ç›
My custom handler, token: ï¼Œ
My custom handler, token: å›ç­”è¯´
My custom handler, token: ï¼šâ€œ
My custom handler, token: ä¸ç”¨
My custom handler, token: äº†
My custom handler, token: ï¼Œ
My custom handler, token: æˆ‘åª
My custom handler, token: æƒ³è¦
My custom handler, token: ä¸€ä¸ª
My custom handler, token: æ™®é€šçš„
My custom handler, token: Gr
My custom handler, token: izzly
My custom handler, token:  Burger
My custom handler, token: ï¼Œ
My custom handler, token: ä½†æ˜¯
My custom handler, token: ï¼Œ
My custom handler, token: è¯·
My custom handler, token: åˆ«
My custom handler, token: æ”¾
My custom handler, token: â€˜
My custom handler, token: Bear
My custom handler, token: â€™
My custom handler, token: na
My custom handler, token: ise
My custom handler, token: ï¼ˆ
My custom handler, token: ç†Š
My custom handler, token: é…±
My custom handler, token: ï¼‰
My custom handler, token: ï¼â€
My custom handler, token: 
```

â€ƒâ€ƒä¸Šè¿°æ˜¯æˆ‘ä»¬è‡ªå·±å®šä¹‰çš„ä¸€ä¸ªç®€å•çš„æµå¼è¾“å‡ºï¼Œå› ä¸ºå¤§æ¨¡å‹æ™®ééƒ½éœ€è¦æµå¼è¾“å‡ºéœ€æ±‚ï¼Œæ‰€ä»¥LangChainå®˜æ–¹å·²ç»é»˜è®¤æŠ½è±¡å‡ºäº†ä¸€ä¸ªæµå¼è¾“å‡ºçš„å›è°ƒå‡½æ•°ï¼Œå¦‚ä¸‹ï¼š

```python
from langchain_core.callbacks.manager import CallbackManager
from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
```

```python
streaming_chat = ChatZhipuAI(
    api_key="086a38e9141410d76e393ec52105c83b.7vBwRS4srgxpMRXU",
    model="glm-4",
    temperature=0.5,
    streaming=True,
    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),
)
```

```python
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

messages = [
    AIMessage(content="ä½ å¥½"),
    SystemMessage(content="ä½ æ˜¯ä¸€ä½è¯—äºº"),
    HumanMessage(content="è¯·ä½ æ ¹æ®æˆ‘çš„è¾“å…¥,å¸®æˆ‘å†™ä¸€é¦–å…³äºå°é¸­å­è½æ°´çš„è¯—"),
]
```

```python
messages
```

```plaintext
[AIMessage(content='ä½ å¥½'),
 SystemMessage(content='ä½ æ˜¯ä¸€ä½è¯—äºº'),
 HumanMessage(content='è¯·ä½ æ ¹æ®æˆ‘çš„è¾“å…¥,å¸®æˆ‘å†™ä¸€é¦–å…³äºå°é¸­å­è½æ°´çš„è¯—')]
```

```python
streaming_chat.invoke(messages)
```

```plaintext
å°é¸­å­è½æ°´ï¼Œæ³¢çº¹è¡æ¼¾é—´ï¼Œ
æ¯›èŒ¸èŒ¸èº«èº¯ï¼ŒæŒ£æ‰åœ¨æ²³é¢ã€‚
æ…Œä¹±å¼ æœ›å¤„ï¼ŒåŒä¼´é½å£°å”¤ï¼Œ
æŒ¯ç¿…æ¬²é«˜é£ï¼Œå´é™·æ³¥æ½­é™©ã€‚

æ‚²é¸£ä¼ å››æ–¹ï¼Œé£å„¿è½»æŠšæ…°ï¼Œ
æŸ³æå‚ä½é¦–ï¼Œé±¼å„¿åœé¡¿æ°´ã€‚
æ´æ‰‹ä½•å¤„å¯»ï¼Ÿæ•‘æ´å¿ƒç„¦æ€¥ï¼Œ
å¿½è§å–„æ„æ‰‹ï¼Œæ¸©æŸ”ä¼¸å‘å®ƒã€‚

å°é¸­å­å¾—æ•‘ï¼Œæ„Ÿæ¿€æ³ªæ»¡çœ¼ï¼Œ
è“å¤©å±•ç¿…èˆï¼Œé‡è·æ–°ç”Ÿæ¬¢ã€‚
æ³¢å…‰ç²¼ç²¼æ˜ ï¼Œè¯—ç¯‡ä¼ ä½³è¯ï¼Œ
å²æœˆæ‚ æ‚ è¿‡ï¼Œè®°å–å–„è¡Œæš–ã€‚




AIMessage(content='å°é¸­å­è½æ°´ï¼Œæ³¢çº¹è¡æ¼¾é—´ï¼Œ\næ¯›èŒ¸èŒ¸èº«èº¯ï¼ŒæŒ£æ‰åœ¨æ²³é¢ã€‚\næ…Œä¹±å¼ æœ›å¤„ï¼ŒåŒä¼´é½å£°å”¤ï¼Œ\næŒ¯ç¿…æ¬²é«˜é£ï¼Œå´é™·æ³¥æ½­é™©ã€‚\n\næ‚²é¸£ä¼ å››æ–¹ï¼Œé£å„¿è½»æŠšæ…°ï¼Œ\næŸ³æå‚ä½é¦–ï¼Œé±¼å„¿åœé¡¿æ°´ã€‚\næ´æ‰‹ä½•å¤„å¯»ï¼Ÿæ•‘æ´å¿ƒç„¦æ€¥ï¼Œ\nå¿½è§å–„æ„æ‰‹ï¼Œæ¸©æŸ”ä¼¸å‘å®ƒã€‚\n\nå°é¸­å­å¾—æ•‘ï¼Œæ„Ÿæ¿€æ³ªæ»¡çœ¼ï¼Œ\nè“å¤©å±•ç¿…èˆï¼Œé‡è·æ–°ç”Ÿæ¬¢ã€‚\næ³¢å…‰ç²¼ç²¼æ˜ ï¼Œè¯—ç¯‡ä¼ ä½³è¯ï¼Œ\nå²æœˆæ‚ æ‚ è¿‡ï¼Œè®°å–å–„è¡Œæš–ã€‚', response_metadata={'finish_reason': 'stop'}, id='run-f644edb5-bf82-4bbd-b14e-d475723a9a9b-0')
```

# 5. Memory

â€ƒâ€ƒ`Memory`ä½œä¸ºå­˜å‚¨è®°å¿†æ•°æ®çš„ä¸€ä¸ªæ˜¯æŠ½è±¡æ¨¡å—ï¼Œå…¶ä½œä¸ºä¸€ä¸ªç‹¬ç«‹æ¨¡å—ä½¿ç”¨æ˜¯æ²¡æœ‰ä»»ä½•æ„ä¹‰çš„ï¼Œå› ä¸ºæœ¬è´¨ä¸Šå®ƒçš„å®šä½å°±æ˜¯ä¸€ä¸ªå­˜å‚¨å¯¹è¯æ•°æ®çš„ç©ºé—´ã€‚å…ˆæŠ›å¼€å…¶å†…éƒ¨å®ç°çš„å¤æ‚æ€§ï¼Œæˆ‘ä»¬å¯ä»¥å›æƒ³ä¸€ä¸‹ï¼šåœ¨å®šä¹‰é“¾è·¯çš„æ—¶å€™ï¼Œæ¯ä¸ªé“¾çš„å†…éƒ¨éƒ½ä¼šæ ¹æ®å…¶æ¥æ”¶åˆ°çš„è¾“å…¥å»å®šä¹‰å…¶æ ¸å¿ƒæ‰§è¡Œé€»è¾‘ï¼Œæ¯”å¦‚åœ¨é“¾å†…å¦‚ä½•å»è°ƒç”¨å¤–éƒ¨å·¥å…·ï¼Œå¦‚ä½•è§£æè¿”å›çš„æ•°æ®æ ¼å¼ç­‰ã€‚å…¶ä¸­é“¾æ¥æ”¶åˆ°çš„è¾“å…¥ï¼Œå¯ä»¥ç›´æ¥æ¥è‡ªç”¨æˆ·ï¼ŒåŒæ—¶ï¼Œä¹Ÿå¯ä»¥æ¥è‡ª`Memory`æ¨¡å—ã€‚æ‰€ä»¥åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œä¸€ä¸ªé“¾å¦‚æœæ¥å…¥äº†`Memory`æ¨¡å—ï¼Œå…¶å†…éƒ¨ä¼šä¸`Memory`æ¨¡å—è¿›è¡Œä¸¤æ¬¡äº¤äº’ï¼š

1. æ”¶åˆ°ç”¨æˆ·è¾“å…¥ä¹‹åï¼Œæ‰§è¡Œæ ¸å¿ƒé€»è¾‘ä¹‹å‰ï¼Œé“¾ä¼šè¯»å–`Memory`æ¨¡å—ï¼Œæ‹¿åˆ°å¯¹åº”çš„æ•°æ®ï¼Œä¸ç”¨æˆ·è¾“å…¥çš„Promptæ”¾åœ¨ä¸€èµ·ï¼Œæ‰§è¡Œæ¥ä¸‹æ¥çš„é€»è¾‘ã€‚

2. æ‰§è¡Œæ ¸å¿ƒé€»è¾‘ä¹‹åï¼Œè¿”å›å“åº”ä¹‹å‰ï¼Œé“¾ä¼šå°†è¿™ä¸ªè¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¿¡æ¯ï¼Œå†™å…¥`Memory`æ¨¡å—ï¼Œä»¥ä¾¿åœ¨å…¶ä»–åœºæ™¯ä¸‹èƒ½å¤Ÿå¼•ç”¨åˆ°è¿™äº›è®°å¿†æ•°æ®ã€‚

â€ƒâ€ƒç”±æ­¤å¯è§ï¼Œ`Memory`æ¨¡å—å’Œ`Chains`æ¨¡å—æ˜¯ä¸€å¯¹ç›¸äº’åä½œçš„å…³ç³»ï¼Œå°±åƒæˆ‘ä»¬å®šä¹‰Promptä¸€æ ·ï¼Œä¸åŒçš„éœ€æ±‚ï¼Œéœ€è¦æ„å»ºä¸åŒçš„Prompt Templateã€‚é‚£æˆ‘ä»¬æƒ³è®°å½•ä¸‹ä»€ä¹ˆå“ªäº›æ•°æ®ï¼Œä¸è®ºæ˜¯ç”¨æˆ·è¾“å…¥çš„promptï¼Œè¿˜æ˜¯å¤§æ¨¡å‹çš„å“åº”ç»“æœï¼Œäº¦æˆ–æ˜¯é“¾è·¯çš„ä¸­é—´è¿‡ç¨‹ç”Ÿæˆçš„æ•°æ®ï¼Œå…¨éƒ¨å°±ç”±`Memory`è¿™ä¸ªæŠ½è±¡æ¨¡å—æ¥å®Œæˆã€‚æ‰€ä»¥è¿™ä¸ªæ¨¡å—æœ€**æ ¸å¿ƒå¹²çš„å°±æ˜¯ä¸¤ä»¶äº‹ï¼šå¦‚ä½•å­˜å‚¨æ•°æ®å’Œå¦‚ä½•æå–æ•°æ®ï¼Œå¯¹åº”ç€å°±æ˜¯ä¸¤ä¸ªåŸºæœ¬æ“ä½œï¼šè¯»å’Œå†™ã€‚**

â€ƒâ€ƒç†è§£äº†ä¸Šè¿°è¯´æ˜åï¼Œå¤§å®¶å°±èƒ½éå¸¸å®¹æ˜“ç†è§£ä¸‹é¢è¿™å¼  LangChain Memory æ¨¡å—çš„æ•´ä½“è®¾è®¡ç»“æ„å›¾ï¼š

![](images/697a204e-56fd-4928-8020-84915031b2c1.png)

â€ƒâ€ƒåœ¨ä¸Šè¿°æµç¨‹å›¾ä¸­ï¼Œ`Model I/O`è¿‡ç¨‹çš„æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªé“¾è·¯ï¼ˆchainï¼‰ï¼Œå…¶é…ç½®æ—¶ä¼šè®¾å®š`Prompt`ã€`Model`å’Œ`Output Parser`ä½œä¸ºé“¾è·¯çš„ä¸»è¦é€»è¾‘ã€‚è¿™ä¸ªé“¾è·¯å¯ä»¥å¤„ç†ç›´æ¥æ¥è‡ªç”¨æˆ·çš„`{question}`è¾“å…¥ï¼Œä¹Ÿå¯ä»¥å¤„ç†æ¥è‡ª`Memory`æ¨¡å—è¯»å–çš„`{past_passages}`ä½œä¸ºè¾“å…¥ã€‚æ‰§è¡Œå®Œæ¯•åï¼Œæ­£å¸¸æƒ…å†µä¸‹ä¼šç›´æ¥è¾“å‡º`{answer}`ã€‚ä½†ä¸€æ—¦é›†æˆäº†Memoryæ¨¡å—ï¼Œè¾“å‡ºå°±ä¼šæ ¹æ®`Memory`ä¸­å®šä¹‰çš„é€»è¾‘è¢«å­˜å‚¨èµ·æ¥ï¼Œä¾›å…¶ä»–ç»„ä»¶æˆ–æµç¨‹ä½¿ç”¨ã€‚

â€ƒâ€ƒè¯¦ç»†çš„å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š

```plaintext
# ç±»ç»§æ‰¿å…³ç³»ï¼š
BaseMemory --> BaseChatMemory --> <name>Memory  # Examples: ZepMemory, MotorheadMemory
```

```python
class BaseMemory(Serializable, ABC):
    """Chains ä¸­è®°å¿†çš„æŠ½è±¡åŸºç±»ã€‚

    è®°å¿†æŒ‡çš„æ˜¯ Chains ä¸­çš„çŠ¶æ€ã€‚è®°å¿†å¯ç”¨äºå­˜å‚¨å…³äº Chains è¿‡å»æ‰§è¡Œçš„ä¿¡æ¯ï¼Œå¹¶å°†è¯¥ä¿¡æ¯æ³¨å…¥åˆ°æœªæ¥æ‰§è¡Œçš„ Chains è¾“å…¥ä¸­ã€‚
    ä¾‹å¦‚ï¼Œå¯¹äºå¯¹è¯ Chainsï¼Œè®°å¿†å¯ç”¨äºå­˜å‚¨å¯¹è¯å¹¶è‡ªåŠ¨å°†å…¶æ·»åŠ åˆ°æœªæ¥æ¨¡å‹æç¤ºä¸­ï¼Œä»¥ä¾¿æ¨¡å‹å…·æœ‰å¿…è¦çš„ä¸Šä¸‹æ–‡æ¥è¿è´¯åœ°å“åº”æœ€æ–°çš„è¾“å…¥ã€‚
     """
    
    # ä¸‹é¢æ˜¯ä¸€äº›å¿…é¡»ç”±å­ç±»å®ç°çš„æ–¹æ³•ï¼š
    
    
    # å®šä¹‰ä¸€ä¸ªå±æ€§ï¼Œä»»ä½•ä»BaseMemoryæ´¾ç”Ÿçš„å­ç±»éƒ½éœ€è¦å®ç°æ­¤æ–¹æ³•ã€‚
    # æ­¤æ–¹æ³•åº”è¿”å›è¯¥è®°å¿†ç±»å°†æ·»åŠ åˆ°é“¾è¾“å…¥çš„å­—ç¬¦ä¸²é”®ã€‚
    @property
    @abstractmethod
    def memory_variables(self) -> List[str]:
        """æ­¤è®°å¿†ç±»å°†æ·»åŠ åˆ°é“¾è¾“å…¥çš„å­—ç¬¦ä¸²é”®åˆ—è¡¨ã€‚"""

        
    # å®šä¹‰ä¸€ä¸ªæŠ½è±¡æ–¹æ³•ã€‚ä»»ä½•ä»BaseMemoryæ´¾ç”Ÿçš„å­ç±»éƒ½éœ€è¦å®ç°æ­¤æ–¹æ³•ã€‚
    # æ­¤æ–¹æ³•åŸºäºç»™å®šçš„é“¾è¾“å…¥è¿”å›é”®å€¼å¯¹ã€‚
    @abstractmethod
    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®é“¾çš„æ–‡æœ¬è¾“å…¥è¿”å›é”®å€¼å¯¹ã€‚"""

    
    # å®šä¹‰ä¸€ä¸ªæŠ½è±¡æ–¹æ³•ã€‚ä»»ä½•ä»BaseMemoryæ´¾ç”Ÿçš„å­ç±»éƒ½éœ€è¦å®ç°æ­¤æ–¹æ³•ã€‚
    # æ­¤æ–¹æ³•å°†æ­¤é“¾è¿è¡Œçš„ä¸Šä¸‹æ–‡ä¿å­˜åˆ°å†…å­˜ã€‚
    @abstractmethod
    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:
        """å°†æ­¤é“¾è¿è¡Œçš„ä¸Šä¸‹æ–‡ä¿å­˜åˆ°è®°å¿†ä¸­ã€‚"""

    # å®šä¹‰ä¸€ä¸ªæŠ½è±¡æ–¹æ³•ã€‚ä»»ä½•ä»BaseMemoryæ´¾ç”Ÿçš„å­ç±»éƒ½éœ€è¦å®ç°æ­¤æ–¹æ³•ã€‚
    # æ­¤æ–¹æ³•æ¸…é™¤å†…å­˜å†…å®¹ã€‚
    @abstractmethod
    def clear(self) -> None:
        """æ¸…é™¤è®°å¿†å†…å®¹ã€‚"""
```

```python
# ! pip install langchain_community
```

```python
from langchain_community.chat_models import ChatZhipuAI


chat = ChatZhipuAI(
    api_key="086a38e9141410d76e393ec52105c83b.7vBwRS4srgxpMRXU",
    model="glm-4",
    temperature=0.8,
)
```

```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
memory.chat_memory.add_user_message("ä½ å¥½")
memory.chat_memory.add_ai_message("ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„?")
```

```python
memory.load_memory_variables({})
```

```plaintext
{'history': 'Human: ä½ å¥½\nAI: ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„?'}
```

```python
memory = ConversationBufferMemory(memory_key="chat_history")
memory.chat_memory.add_user_message("ä½ å¥½")
memory.chat_memory.add_ai_message("ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„?")
```

```python
memory.load_memory_variables({})
```

```plaintext
{'chat_history': 'Human: ä½ å¥½\nAI: ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„?'}
```

```python
from langchain_community.chat_models import ChatZhipuAI

from langchain_core.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)


chat = ChatZhipuAI(
    api_key="086a38e9141410d76e393ec52105c83b.7vBwRS4srgxpMRXU",
    model="glm-4",
    temperature=0.8,
)


prompt = ChatPromptTemplate(
    messages=[
        SystemMessagePromptTemplate.from_template(
            "ä½ æ˜¯ä¸€ä¸ªå…·æœ‰ä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›çš„å¯¹è¯æœºå™¨äºº"
        ),
 
        MessagesPlaceholder(variable_name="chat_history"),
        HumanMessagePromptTemplate.from_template("{question}")
    ]
)
```

```python
from langchain.chains import LLMChain

memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
conversation = LLMChain(
    llm=chat,
    prompt=prompt,
    verbose=True,
    memory=memory
)
```

```python
conversation.invoke({"question": "ä½ å¥½"})
```

```plaintext
[1m> Entering new LLMChain chain...[0m
Prompt after formatting:
[32;1m[1;3mSystem: ä½ æ˜¯ä¸€ä¸ªå…·æœ‰ä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›çš„å¯¹è¯æœºå™¨äºº
Human: ä½ å¥½[0m

[1m> Finished chain.[0m





{'question': 'ä½ å¥½',
 'chat_history': [HumanMessage(content='ä½ å¥½'),
  AIMessage(content='æ˜¯çš„ï¼Œä½œä¸ºä¸€ä¸ªé«˜çº§çš„å¯¹è¯æœºå™¨äººï¼Œæˆ‘å…·å¤‡ä¸€å®šçš„ä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šç†è§£å’Œè®°ä½æˆ‘ä»¬å¯¹è¯çš„ä¸Šä¸‹æ–‡å†…å®¹ï¼Œä»¥ä¾¿æä¾›æ›´åŠ è¿è´¯å’Œç›¸å…³çš„å›ç­”ã€‚ä¸è¿‡ï¼Œè¯·æ³¨æ„ï¼Œæˆ‘çš„è®°å¿†èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒçš„å¯¹è¯ä¼šè¯ä¹‹é—´ï¼Œæˆ‘å¯èƒ½ä¸ä¼šè®°å¾—ä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼')],
 'text': 'æ˜¯çš„ï¼Œä½œä¸ºä¸€ä¸ªé«˜çº§çš„å¯¹è¯æœºå™¨äººï¼Œæˆ‘å…·å¤‡ä¸€å®šçš„ä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šç†è§£å’Œè®°ä½æˆ‘ä»¬å¯¹è¯çš„ä¸Šä¸‹æ–‡å†…å®¹ï¼Œä»¥ä¾¿æä¾›æ›´åŠ è¿è´¯å’Œç›¸å…³çš„å›ç­”ã€‚ä¸è¿‡ï¼Œè¯·æ³¨æ„ï¼Œæˆ‘çš„è®°å¿†èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒçš„å¯¹è¯ä¼šè¯ä¹‹é—´ï¼Œæˆ‘å¯èƒ½ä¸ä¼šè®°å¾—ä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼'}
```

```python
conversation.invoke({"question": "ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"})
```

```plaintext
[1m> Entering new LLMChain chain...[0m
Prompt after formatting:
[32;1m[1;3mSystem: ä½ æ˜¯ä¸€ä¸ªå…·æœ‰ä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›çš„å¯¹è¯æœºå™¨äºº
Human: ä½ å¥½
AI: æ˜¯çš„ï¼Œä½œä¸ºä¸€ä¸ªé«˜çº§çš„å¯¹è¯æœºå™¨äººï¼Œæˆ‘å…·å¤‡ä¸€å®šçš„ä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šç†è§£å’Œè®°ä½æˆ‘ä»¬å¯¹è¯çš„ä¸Šä¸‹æ–‡å†…å®¹ï¼Œä»¥ä¾¿æä¾›æ›´åŠ è¿è´¯å’Œç›¸å…³çš„å›ç­”ã€‚ä¸è¿‡ï¼Œè¯·æ³¨æ„ï¼Œæˆ‘çš„è®°å¿†èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒçš„å¯¹è¯ä¼šè¯ä¹‹é—´ï¼Œæˆ‘å¯èƒ½ä¸ä¼šè®°å¾—ä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼
Human: ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ[0m

[1m> Finished chain.[0m





{'question': 'ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ',
 'chat_history': [HumanMessage(content='ä½ å¥½'),
  AIMessage(content='æ˜¯çš„ï¼Œä½œä¸ºä¸€ä¸ªé«˜çº§çš„å¯¹è¯æœºå™¨äººï¼Œæˆ‘å…·å¤‡ä¸€å®šçš„ä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šç†è§£å’Œè®°ä½æˆ‘ä»¬å¯¹è¯çš„ä¸Šä¸‹æ–‡å†…å®¹ï¼Œä»¥ä¾¿æä¾›æ›´åŠ è¿è´¯å’Œç›¸å…³çš„å›ç­”ã€‚ä¸è¿‡ï¼Œè¯·æ³¨æ„ï¼Œæˆ‘çš„è®°å¿†èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒçš„å¯¹è¯ä¼šè¯ä¹‹é—´ï¼Œæˆ‘å¯èƒ½ä¸ä¼šè®°å¾—ä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼'),
  HumanMessage(content='ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'),
  AIMessage(content='å¾ˆæŠ±æ­‰ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ— æ³•æä¾›å®æ—¶æ•°æ®æˆ–å½“å‰çš„å¤©æ°”ä¿¡æ¯ã€‚è¦è·å–ä»Šå¤©çš„å¤©æ°”ï¼Œä½ å¯ä»¥æŸ¥çœ‹å½“åœ°çš„å¤©æ°”é¢„æŠ¥ï¼Œæˆ–è€…ä½¿ç”¨åœ¨çº¿å¤©æ°”æœåŠ¡ã€åº”ç”¨ç¨‹åºç­‰ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å…¶ä»–ç±»å‹çš„å¸®åŠ©ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼')],
 'text': 'å¾ˆæŠ±æ­‰ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ— æ³•æä¾›å®æ—¶æ•°æ®æˆ–å½“å‰çš„å¤©æ°”ä¿¡æ¯ã€‚è¦è·å–ä»Šå¤©çš„å¤©æ°”ï¼Œä½ å¯ä»¥æŸ¥çœ‹å½“åœ°çš„å¤©æ°”é¢„æŠ¥ï¼Œæˆ–è€…ä½¿ç”¨åœ¨çº¿å¤©æ°”æœåŠ¡ã€åº”ç”¨ç¨‹åºç­‰ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å…¶ä»–ç±»å‹çš„å¸®åŠ©ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼'}
```

```python
conversation.invoke({"question": "ç°åœ¨é€‚åˆå‡ºå»ç©å—ï¼Ÿ"})
```

```plaintext
[1m> Entering new LLMChain chain...[0m
Prompt after formatting:
[32;1m[1;3mSystem: ä½ æ˜¯ä¸€ä¸ªå…·æœ‰ä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›çš„å¯¹è¯æœºå™¨äºº
Human: ä½ å¥½
AI: æ˜¯çš„ï¼Œä½œä¸ºä¸€ä¸ªé«˜çº§çš„å¯¹è¯æœºå™¨äººï¼Œæˆ‘å…·å¤‡ä¸€å®šçš„ä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šç†è§£å’Œè®°ä½æˆ‘ä»¬å¯¹è¯çš„ä¸Šä¸‹æ–‡å†…å®¹ï¼Œä»¥ä¾¿æä¾›æ›´åŠ è¿è´¯å’Œç›¸å…³çš„å›ç­”ã€‚ä¸è¿‡ï¼Œè¯·æ³¨æ„ï¼Œæˆ‘çš„è®°å¿†èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒçš„å¯¹è¯ä¼šè¯ä¹‹é—´ï¼Œæˆ‘å¯èƒ½ä¸ä¼šè®°å¾—ä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼
Human: ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ
AI: å¾ˆæŠ±æ­‰ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ— æ³•æä¾›å®æ—¶æ•°æ®æˆ–å½“å‰çš„å¤©æ°”ä¿¡æ¯ã€‚è¦è·å–ä»Šå¤©çš„å¤©æ°”ï¼Œä½ å¯ä»¥æŸ¥çœ‹å½“åœ°çš„å¤©æ°”é¢„æŠ¥ï¼Œæˆ–è€…ä½¿ç”¨åœ¨çº¿å¤©æ°”æœåŠ¡ã€åº”ç”¨ç¨‹åºç­‰ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å…¶ä»–ç±»å‹çš„å¸®åŠ©ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼
Human: ç°åœ¨é€‚åˆå‡ºå»ç©å—ï¼Ÿ[0m

[1m> Finished chain.[0m





{'question': 'ç°åœ¨é€‚åˆå‡ºå»ç©å—ï¼Ÿ',
 'chat_history': [HumanMessage(content='ä½ å¥½'),
  AIMessage(content='æ˜¯çš„ï¼Œä½œä¸ºä¸€ä¸ªé«˜çº§çš„å¯¹è¯æœºå™¨äººï¼Œæˆ‘å…·å¤‡ä¸€å®šçš„ä¸Šä¸‹æ–‡è®°å¿†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šç†è§£å’Œè®°ä½æˆ‘ä»¬å¯¹è¯çš„ä¸Šä¸‹æ–‡å†…å®¹ï¼Œä»¥ä¾¿æä¾›æ›´åŠ è¿è´¯å’Œç›¸å…³çš„å›ç­”ã€‚ä¸è¿‡ï¼Œè¯·æ³¨æ„ï¼Œæˆ‘çš„è®°å¿†èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒçš„å¯¹è¯ä¼šè¯ä¹‹é—´ï¼Œæˆ‘å¯èƒ½ä¸ä¼šè®°å¾—ä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼'),
  HumanMessage(content='ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'),
  AIMessage(content='å¾ˆæŠ±æ­‰ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ— æ³•æä¾›å®æ—¶æ•°æ®æˆ–å½“å‰çš„å¤©æ°”ä¿¡æ¯ã€‚è¦è·å–ä»Šå¤©çš„å¤©æ°”ï¼Œä½ å¯ä»¥æŸ¥çœ‹å½“åœ°çš„å¤©æ°”é¢„æŠ¥ï¼Œæˆ–è€…ä½¿ç”¨åœ¨çº¿å¤©æ°”æœåŠ¡ã€åº”ç”¨ç¨‹åºç­‰ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å…¶ä»–ç±»å‹çš„å¸®åŠ©ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼'),
  HumanMessage(content='ç°åœ¨é€‚åˆå‡ºå»ç©å—ï¼Ÿ'),
  AIMessage(content='ç”±äºæˆ‘æ— æ³•æä¾›å®æ—¶çš„å¤©æ°”æˆ–ç¯å¢ƒä¿¡æ¯ï¼Œæˆ‘æ— æ³•ç›´æ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚ä¸è¿‡ï¼Œå†³å®šæ˜¯å¦é€‚åˆå‡ºå»ç©é€šå¸¸å–å†³äºä»¥ä¸‹å‡ ä¸ªå› ç´ ï¼š\n\n1. å¤©æ°”çŠ¶å†µï¼šæ™´å¤©æˆ–å¤šäº‘çš„å¤©æ°”é€šå¸¸é€‚åˆæˆ·å¤–æ´»åŠ¨ï¼Œè€Œé›¨å¤©ã€å¤§é£æˆ–æç«¯å¤©æ°”åˆ™å¯èƒ½ä¸é€‚åˆã€‚\n\n2. å­£èŠ‚ï¼šä¸åŒçš„å­£èŠ‚é€‚åˆä¸åŒçš„æˆ·å¤–æ´»åŠ¨ã€‚ä¾‹å¦‚ï¼Œæ˜¥å­£é€‚åˆèµèŠ±ï¼Œå¤å­£é€‚åˆæµ·è¾¹æˆ–é¿æš‘ï¼Œç§‹å­£é€‚åˆèµç§‹å¶ï¼Œå†¬å­£é€‚åˆæ»‘é›ªç­‰ã€‚\n\n3. ä¸ªäººå–œå¥½ï¼šä½ ä¸ªäººçš„å…´è¶£å’Œå–œå¥½ä¹Ÿä¼šå½±å“æ˜¯å¦é€‚åˆå‡ºå»ç©ã€‚æœ‰äº›äººå–œæ¬¢åœ¨é›¨å¤©æ•£æ­¥ï¼Œè€Œæœ‰äº›äººåˆ™æ›´å–œæ¬¢åœ¨é˜³å…‰æ˜åªšçš„æ—¥å­é‡Œæˆ·å¤–æ´»åŠ¨ã€‚\n\n4. å®‰å…¨å› ç´ ï¼šè€ƒè™‘åˆ°å¥åº·å’Œå®‰å…¨ï¼Œå¦‚æœå¤©æ°”è¿‡äºæ¶åŠ£æˆ–å­˜åœ¨å®‰å…¨éšæ‚£ï¼Œåº”é¿å…å¤–å‡ºã€‚\n\nä¸ºäº†åˆ¤æ–­ç°åœ¨æ˜¯å¦é€‚åˆå‡ºå»ç©ï¼Œä½ å¯ä»¥æŸ¥çœ‹å½“å‰çš„å¤©æ°”æƒ…å†µï¼Œè€ƒè™‘ä¸Šè¿°å› ç´ ï¼Œå¹¶æ ¹æ®è‡ªå·±çš„è®¡åˆ’å’Œå–œå¥½åšå‡ºå†³å®šã€‚å¦‚æœä½ éœ€è¦å…·ä½“çš„å»ºè®®ï¼Œå¯ä»¥æä¾›æ›´å¤šçš„ä¿¡æ¯ï¼Œæ¯”å¦‚ä½ æ‰€åœ¨çš„åŸå¸‚ã€å½“å‰çš„å¤©æ°”çŠ¶å†µç­‰ï¼Œæˆ‘ä¼šå°½åŠ›ç»™å‡ºå»ºè®®ã€‚')],
 'text': 'ç”±äºæˆ‘æ— æ³•æä¾›å®æ—¶çš„å¤©æ°”æˆ–ç¯å¢ƒä¿¡æ¯ï¼Œæˆ‘æ— æ³•ç›´æ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚ä¸è¿‡ï¼Œå†³å®šæ˜¯å¦é€‚åˆå‡ºå»ç©é€šå¸¸å–å†³äºä»¥ä¸‹å‡ ä¸ªå› ç´ ï¼š\n\n1. å¤©æ°”çŠ¶å†µï¼šæ™´å¤©æˆ–å¤šäº‘çš„å¤©æ°”é€šå¸¸é€‚åˆæˆ·å¤–æ´»åŠ¨ï¼Œè€Œé›¨å¤©ã€å¤§é£æˆ–æç«¯å¤©æ°”åˆ™å¯èƒ½ä¸é€‚åˆã€‚\n\n2. å­£èŠ‚ï¼šä¸åŒçš„å­£èŠ‚é€‚åˆä¸åŒçš„æˆ·å¤–æ´»åŠ¨ã€‚ä¾‹å¦‚ï¼Œæ˜¥å­£é€‚åˆèµèŠ±ï¼Œå¤å­£é€‚åˆæµ·è¾¹æˆ–é¿æš‘ï¼Œç§‹å­£é€‚åˆèµç§‹å¶ï¼Œå†¬å­£é€‚åˆæ»‘é›ªç­‰ã€‚\n\n3. ä¸ªäººå–œå¥½ï¼šä½ ä¸ªäººçš„å…´è¶£å’Œå–œå¥½ä¹Ÿä¼šå½±å“æ˜¯å¦é€‚åˆå‡ºå»ç©ã€‚æœ‰äº›äººå–œæ¬¢åœ¨é›¨å¤©æ•£æ­¥ï¼Œè€Œæœ‰äº›äººåˆ™æ›´å–œæ¬¢åœ¨é˜³å…‰æ˜åªšçš„æ—¥å­é‡Œæˆ·å¤–æ´»åŠ¨ã€‚\n\n4. å®‰å…¨å› ç´ ï¼šè€ƒè™‘åˆ°å¥åº·å’Œå®‰å…¨ï¼Œå¦‚æœå¤©æ°”è¿‡äºæ¶åŠ£æˆ–å­˜åœ¨å®‰å…¨éšæ‚£ï¼Œåº”é¿å…å¤–å‡ºã€‚\n\nä¸ºäº†åˆ¤æ–­ç°åœ¨æ˜¯å¦é€‚åˆå‡ºå»ç©ï¼Œä½ å¯ä»¥æŸ¥çœ‹å½“å‰çš„å¤©æ°”æƒ…å†µï¼Œè€ƒè™‘ä¸Šè¿°å› ç´ ï¼Œå¹¶æ ¹æ®è‡ªå·±çš„è®¡åˆ’å’Œå–œå¥½åšå‡ºå†³å®šã€‚å¦‚æœä½ éœ€è¦å…·ä½“çš„å»ºè®®ï¼Œå¯ä»¥æä¾›æ›´å¤šçš„ä¿¡æ¯ï¼Œæ¯”å¦‚ä½ æ‰€åœ¨çš„åŸå¸‚ã€å½“å‰çš„å¤©æ°”çŠ¶å†µç­‰ï¼Œæˆ‘ä¼šå°½åŠ›ç»™å‡ºå»ºè®®ã€‚'}
```

```python
```

**å…¬å¼€è¯¾å†…å®¹èŠ‚é€‰è‡ªã€Šå¤§æ¨¡å‹ä¸Agentå¼€å‘ã€‹å®Œæ•´ç‰ˆä»˜è´¹è¯¾ç¨‹ï¼**

å…¬å¼€è¯¾æ—¶é—´æœ‰é™ï¼Œè‹¥æƒ³æ·±åº¦å­¦ä¹ å¤§æ¨¡å‹æŠ€æœ¯ï¼Œæ¬¢è¿å¤§å®¶æŠ¥åç”±æˆ‘ä¸»è®²çš„[ã€Šå¤§æ¨¡å‹ä¸Agentå¼€å‘å®æˆ˜è¯¾ã€‹](https://whakv.xetslk.com/s/432wPY)ï¼š

![](images/31e96154-f92b-49d5-b897-34e0fb9bcfd4.jpeg)

**[ã€Šå¤§æ¨¡å‹ä¸Agentå¼€å‘å®æˆ˜è¯¾ã€‹](https://whakv.xetslk.com/s/432wPY)ä¸ºã€100+å°æ—¶ã€‘ä½“ç³»å¤§è¯¾ï¼Œæ€»å…±20å¤§æ¨¡å—ç²¾è®²ç²¾æï¼Œé›¶åŸºç¡€ç›´è¾¾å¤§æ¨¡å‹ä¼ä¸šçº§åº”ç”¨ï¼**

![](images/f339b04b7b20233dd1509c7fb36d5c0.png)

ğŸ“**æ›´å¤šå¤§æ¨¡å‹æŠ€æœ¯å†…å®¹å­¦ä¹ **

**æ‰«ç æ·»åŠ åŠ©ç†è‹±è‹±ï¼Œå›å¤â€œå¤§æ¨¡å‹â€ï¼ŒğŸ‘†äº†è§£æ›´å¤šå¤§æ¨¡å‹æŠ€æœ¯è¯¦æƒ…å“¦**
