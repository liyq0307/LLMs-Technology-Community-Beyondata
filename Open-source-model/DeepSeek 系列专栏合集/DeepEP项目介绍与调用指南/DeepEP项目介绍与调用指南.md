## ä¸€ã€DeepEPé¡¹ç›®ä»‹ç»

### 1. DeepEPé¡¹ç›®å‘å¸ƒè¯¦æƒ…

&#x20;       å½“åœ°æ—¶é—´2æœˆ25å·ï¼ŒDeepSeekå¼€æºå‘¨ç¬¬äºŒå¤©ï¼Œæ­£å¼å‘å¸ƒDeepEPï¼Œä¸€ä¸ªMoEæ¨¡å‹è®­ç»ƒä¸æ¨ç†å†…éƒ¨é€šä¿¡åŠ é€Ÿåº“ã€‚

![](images/5354d41a-7bb3-43a9-9aad-2d946d3a07fe.png)

ğŸš€ å¼€æºå‘¨ç¬¬äºŒå¤©ï¼šDeepEP

å¾ˆé«˜å…´ä»‹ç»DeepEPâ€”â€”é¦–ä¸ªå¼€æºEPé€šä¿¡åº“ï¼Œç”¨äºMoEæ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†ã€‚

âœ… é«˜æ•ˆä¸”ä¼˜åŒ–çš„å…¨åˆ°å…¨é€šä¿¡

âœ… æ”¯æŒèŠ‚ç‚¹å†…å’ŒèŠ‚ç‚¹é—´é€šä¿¡ï¼Œå…¼å®¹NVLinkå’ŒRDMA

âœ… é«˜ååé‡çš„å†…æ ¸ï¼Œç”¨äºè®­ç»ƒå’Œæ¨ç†å‰å¡«å……

âœ… ä½å»¶è¿Ÿå†…æ ¸ï¼Œç”¨äºæ¨ç†è§£ç 

âœ… åŸç”ŸFP8è°ƒåº¦æ”¯æŒ

âœ… çµæ´»çš„GPUèµ„æºæ§åˆ¶ï¼Œæ”¯æŒè®¡ç®—ä¸é€šä¿¡çš„é‡å 

DeepEPæ˜¯ä¸€ä¸ªä¸ºMixture-of-Experts (MoE) æ¨¡å‹ä¼˜åŒ–çš„é€šä¿¡åº“ï¼Œæä¾›é«˜ååé‡å’Œä½å»¶è¿Ÿçš„GPUå†…æ ¸ï¼Œç”¨äºMoEè°ƒåº¦å’Œåˆå¹¶æ“ä½œã€‚å…¶ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š

* **é«˜æ€§èƒ½**ï¼šæ”¯æŒNVLinkå’ŒRDMAè¿›è¡ŒèŠ‚ç‚¹å†…å¤–é€šä¿¡ï¼Œé’ˆå¯¹éå¯¹ç§°åŸŸå¸¦å®½è½¬å‘ä¼˜åŒ–äº†å†…æ ¸ã€‚

* **ä½ç²¾åº¦æ“ä½œ**ï¼šåŒ…æ‹¬FP8æ”¯æŒï¼Œç”¨äºé«˜æ•ˆè®¡ç®—ã€‚

* **ä½å»¶è¿Ÿæ¨ç†**ï¼šæä¾›ä½¿ç”¨çº¯RDMAçš„ä½å»¶è¿Ÿå†…æ ¸ï¼Œå‡å°‘æ¨ç†è§£ç çš„å»¶è¿Ÿã€‚

* **é€šä¿¡ä¸è®¡ç®—é‡å **ï¼šå¼•å…¥äº†ä¸€ç§åŸºäºé’©å­çš„æ–¹å¼ï¼Œä¸å ç”¨SMèµ„æºã€‚

* **è‡ªé€‚åº”è·¯ç”±ä¸æµé‡éš”ç¦»**ï¼šæ”¯æŒè‡ªé€‚åº”è·¯ç”±ä»¥å®ç°ä½å»¶è¿Ÿå†…æ ¸ï¼Œå¹¶é€šè¿‡è™šæ‹Ÿé€šé“è¿›è¡Œæµé‡éš”ç¦»ã€‚

æ€§èƒ½åŸºå‡†æµ‹è¯•æ˜¾ç¤ºï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒå’Œæ¨ç†å‰å¡«å……ä»»åŠ¡ä¸­ï¼Œååé‡æœ‰æ˜¾è‘—æé«˜ã€‚è¯¥åº“è¦æ±‚ä½¿ç”¨Hopper GPUï¼ŒPython 3.8+ï¼ŒCUDA 12.3+ï¼ŒPyTorch 2.1+ï¼Œä»¥åŠNVLink/RDMAç½‘ç»œã€‚

ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œç”¨æˆ·åº”è¿›è¡Œæµ‹è¯•å¹¶ä½¿ç”¨è‡ªåŠ¨è°ƒä¼˜é…ç½®ã€‚DeepEPåœ¨MITè®¸å¯è¯ä¸‹å‘å¸ƒï¼ŒNVSHMEMç›¸å…³ä»£ç é™¤å¤–ã€‚

### 2. DeepEPå·¥ä½œåŸç†è§£æ

&#x20;è¦ç†è§£DeepEPå¦‚ä½•å·¥ä½œï¼Œå¯ä»¥å°†å…¶æ¯”ä½œä¸€æ¡ç¹å¿™çš„é«˜é€Ÿå…¬è·¯ï¼Œå…¶ä¸­æ±½è½¦ä»£è¡¨æ•°æ®ï¼ŒåŸå¸‚è±¡å¾è®¡ç®—æœºç»„ä»¶ã€‚å¦‚æœæ²¡æœ‰ç²¾å¿ƒè§„åˆ’çš„é“è·¯å’Œäº¤é€šè§„åˆ™ï¼Œæ‹¥å µå’Œå»¶è¿Ÿæ˜¯ä¸å¯é¿å…çš„ã€‚DeepEPå°±åƒä¸€å¥—å…ˆè¿›çš„é«˜é€Ÿå…¬è·¯ç³»ç»Ÿï¼Œæ—¨åœ¨æœ€å¤§åŒ–æ•ˆç‡ï¼Œç¡®ä¿æ•°æ®æµç•…ä¸”å¿«é€Ÿåœ°ä¼ è¾“ï¼Œå…·æœ‰å¤šä¸ªå…³é”®ç‰¹æ€§ã€‚

* **ä¼˜åŒ–çš„å…¨åˆ°å…¨é€šä¿¡**
  åœ¨Mixture of Experts (MoE)æ¨¡å‹ä¸­ï¼Œæ¯ä¸ªä¸“å®¶å¿…é¡»ä¸å…¶ä»–æ‰€æœ‰ä¸“å®¶äº¤æ¢æ•°æ®ã€‚DeepEPä½¿è¿™ä¸€è¿‡ç¨‹å¾—ä»¥æ— ç“¶é¢ˆåœ°è¿›è¡Œï¼Œç±»ä¼¼äºä¸ºæ¯è¾†è½¦æä¾›ä¸“å±çš„é«˜é€Ÿè½¦é“ã€‚

* **æ”¯æŒèŠ‚ç‚¹å†…å’ŒèŠ‚ç‚¹é—´é€šä¿¡**
  èŠ‚ç‚¹å†…é€šä¿¡å‘ç”Ÿåœ¨åŒä¸€è®¡ç®—æœºèŠ¯ç‰‡å†…ï¼Œç±»ä¼¼äºè½¦è¾†åœ¨åŸå¸‚å†…è¡Œé©¶ã€‚DeepEPåˆ©ç”¨**NVLink**ï¼ŒNVIDIAçš„é«˜é€Ÿè¿æ¥æŠ€æœ¯ï¼ŒåŠ é€Ÿè¿™ä¸€è¿‡ç¨‹ã€‚
  èŠ‚ç‚¹é—´é€šä¿¡å‘ç”Ÿåœ¨ä¸åŒè®¡ç®—æœºæˆ–èŠ¯ç‰‡ä¹‹é—´ï¼Œç±»ä¼¼äºæ±½è½¦åœ¨åŸå¸‚é—´è¡Œé©¶ã€‚DeepEPåˆ©ç”¨\*\*RDMAï¼ˆè¿œç¨‹ç›´æ¥å†…å­˜è®¿é—®ï¼‰\*\*ç›´æ¥åœ¨æœºå™¨ä¹‹é—´ä¼ è¾“æ•°æ®ï¼Œå‡å°‘å»¶è¿Ÿå¹¶ä¼˜åŒ–æ€§èƒ½ã€‚

* **é«˜ååé‡ã€ä½å»¶è¿ŸGPUå†…æ ¸**
  GPUé©±åŠ¨AIæ¨¡å‹ï¼Œä½†å…¶æ•ˆç‡å–å†³äºå¦‚ä½•å¤„ç†å’Œäº¤æ¢æ•°æ®ã€‚DeepEPé›†æˆäº†ä¸“é—¨çš„**GPUå†…æ ¸**ï¼Œæœ€å¤§åŒ–å¤„ç†é€Ÿåº¦ï¼Œå°†ç­‰å¾…æ—¶é—´å‡å°‘åˆ°å‡ ä¹ä¸ºé›¶ã€‚

* **çµæ´»çš„èµ„æºæ§åˆ¶**
  DeepEPå…è®¸å¼€å‘äººå‘˜åŠ¨æ€åˆ†é…è®¡ç®—ä»»åŠ¡åˆ°ä¸åŒçš„GPUï¼Œèƒ½å¤Ÿæ— ç¼é€‚åº”ä¸åŒçš„ç¡¬ä»¶é…ç½®ã€‚

é€šè¿‡åœ¨å„ä¸ªå±‚é¢ä¼˜åŒ–æ•°æ®æµï¼ŒDeepEPç¡®ä¿å³ä½¿æ˜¯æœ€å¤æ‚å’Œåˆ†å¸ƒå¼çš„AIç³»ç»Ÿä¹Ÿèƒ½å¹³ç¨³é«˜æ•ˆåœ°è¿è¡Œã€‚

## äºŒã€DeepEPé¡¹ç›®éƒ¨ç½²æµç¨‹

* DeepEPé¡¹ç›®å®˜ç½‘ï¼šhttps://github.com/deepseek-ai/DeepEP

![](images/807377df-517f-476c-b252-b4e1e2f808e6.png)

### 1. DeepEPåŠŸèƒ½è¯¦è§£

#### 1.1 DeepEP

&#x20;DeepEPæ˜¯ä¸€ä¸ªä¸ºMixture-of-Experts (MoE) å’Œä¸“å®¶å¹¶è¡Œï¼ˆEPï¼‰é‡èº«å®šåˆ¶çš„é€šä¿¡åº“ã€‚å®ƒæä¾›é«˜ååé‡å’Œä½å»¶è¿Ÿçš„å…¨åˆ°å…¨GPUå†…æ ¸ï¼Œä¹Ÿç§°ä¸ºMoEè°ƒåº¦å’Œåˆå¹¶æ“ä½œã€‚è¯¥åº“è¿˜æ”¯æŒä½ç²¾åº¦æ“ä½œï¼ŒåŒ…æ‹¬FP8ã€‚

&#x20;ä¸ºäº†ä¸DeepSeek-V3è®ºæ–‡ä¸­æå‡ºçš„ç»„é™é—¨æ§ç®—æ³•å¯¹é½ï¼ŒDeepEPæä¾›äº†ä¸€å¥—é’ˆå¯¹éå¯¹ç§°åŸŸå¸¦å®½è½¬å‘ä¼˜åŒ–çš„å†…æ ¸ï¼Œä¾‹å¦‚å°†æ•°æ®ä»NVLinkåŸŸè½¬å‘åˆ°RDMAåŸŸã€‚è¿™äº›å†…æ ¸æä¾›é«˜ååé‡ï¼Œé€‚ç”¨äºè®­ç»ƒå’Œæ¨ç†å‰å¡«å……ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œå®ƒä»¬æ”¯æŒSMï¼ˆæµå¼å¤šå¤„ç†å™¨ï¼‰æ•°é‡æ§åˆ¶ã€‚

&#x20;å¯¹äºå»¶è¿Ÿæ•æ„Ÿçš„æ¨ç†è§£ç ï¼ŒDeepEPåŒ…æ‹¬ä¸€å¥—ä½å»¶è¿Ÿå†…æ ¸ï¼Œé‡‡ç”¨çº¯RDMAä»¥æœ€å°åŒ–å»¶è¿Ÿã€‚è¯¥åº“è¿˜å¼•å…¥äº†ä¸€ç§åŸºäºé’©å­çš„é€šä¿¡ä¸è®¡ç®—é‡å æ–¹æ³•ï¼Œä¸å ç”¨ä»»ä½•SMèµ„æºã€‚

&#x20;æ³¨æ„ï¼šè¯¥åº“ä¸­çš„å®ç°å¯èƒ½ä¸DeepSeek-V3è®ºæ–‡ä¸­çš„æŸäº›éƒ¨åˆ†ç•¥æœ‰ä¸åŒã€‚

#### 1.2 **æ€§èƒ½**

* **ä½¿ç”¨NVLinkå’ŒRDMAè½¬å‘çš„æ™®é€šå†…æ ¸**

&#x20;æˆ‘ä»¬åœ¨H800ï¼ˆæœ€å¤§NVLinkå¸¦å®½çº¦ä¸º160 GB/sï¼‰ä¸Šæµ‹è¯•äº†æ™®é€šå†…æ ¸ï¼Œæ¯ä¸ªè¿æ¥åˆ°CX7 InfiniBand 400 Gb/s RDMAç½‘ç»œå¡ï¼ˆæœ€å¤§å¸¦å®½çº¦ä¸º50 GB/sï¼‰ã€‚å¹¶ä¸”æˆ‘ä»¬éµå¾ªDeepSeek-V3/R1çš„é¢„è®­ç»ƒè®¾ç½®ï¼ˆæ¯æ‰¹æ¬¡4096ä¸ªtokenï¼Œ7168ä¸ªéšè—å±‚ï¼Œtop-4ç»„ï¼Œtop-8ä¸“å®¶ï¼ŒFP8è°ƒåº¦å’ŒBF16åˆå¹¶ï¼‰ã€‚

| ç±»å‹  | è°ƒåº¦ #EP | ç“¶é¢ˆå¸¦å®½             | åˆå¹¶ #EP | ç“¶é¢ˆå¸¦å®½             |
| --- | ------ | ---------------- | ------ | ---------------- |
| èŠ‚ç‚¹å†… | 8      | 153 GB/sï¼ˆNVLinkï¼‰ | 8      | 158 GB/sï¼ˆNVLinkï¼‰ |
| èŠ‚ç‚¹é—´ | 16     | 43 GB/sï¼ˆRDMAï¼‰    | 16     | 43 GB/sï¼ˆRDMAï¼‰    |
| èŠ‚ç‚¹é—´ | 32     | 44 GB/sï¼ˆRDMAï¼‰    | 32     | 47 GB/sï¼ˆRDMAï¼‰    |
| èŠ‚ç‚¹é—´ | 64     | 46 GB/sï¼ˆRDMAï¼‰    | 64     | 45 GB/sï¼ˆRDMAï¼‰    |

* **ä½¿ç”¨çº¯RDMAçš„ä½å»¶è¿Ÿå†…æ ¸**

&#x20;æˆ‘ä»¬åœ¨H800ä¸Šæµ‹è¯•äº†ä½å»¶è¿Ÿå†…æ ¸ï¼Œæ¯ä¸ªè¿æ¥åˆ°CX7 InfiniBand 400 Gb/s RDMAç½‘ç»œå¡ï¼ˆæœ€å¤§å¸¦å®½çº¦ä¸º50 GB/sï¼‰ã€‚å¹¶ä¸”æˆ‘ä»¬éµå¾ªå…¸å‹çš„DeepSeek-V3/R1ç”Ÿäº§è®¾ç½®ï¼ˆæ¯æ‰¹æ¬¡128ä¸ªtokenï¼Œ7168ä¸ªéšè—å±‚ï¼Œtop-8ä¸“å®¶ï¼ŒFP8è°ƒåº¦å’ŒBF16åˆå¹¶ï¼‰ã€‚

| è°ƒåº¦ #EP | å»¶è¿Ÿ     | RDMAå¸¦å®½  | åˆå¹¶ #EP | å»¶è¿Ÿ     | RDMAå¸¦å®½  |
| ------ | ------ | ------- | ------ | ------ | ------- |
| 8      | 163 us | 46 GB/s | 8      | 318 us | 46 GB/s |
| 16     | 173 us | 43 GB/s | 16     | 329 us | 44 GB/s |
| 32     | 182 us | 41 GB/s | 32     | 350 us | 41 GB/s |
| 64     | 186 us | 40 GB/s | 64     | 353 us | 41 GB/s |
| 128    | 192 us | 39 GB/s | 128    | 369 us | 39 GB/s |
| 256    | 194 us | 39 GB/s | 256    | 360 us | 40 GB/s |

#### 1.3 **æ™®é€šå†…æ ¸ï¼ˆNormal Kernelsï¼‰å’Œä½å»¶è¿Ÿå†…æ ¸ï¼ˆLow-latency Kernelsï¼‰è§£é‡Š**

è¿™ä¸¤å¼ è¡¨åˆ†åˆ«å±•ç¤ºäº†DeepEPåœ¨ä¸åŒç±»å‹å†…æ ¸ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼š

1. **æ™®é€šå†…æ ¸ï¼ˆNormal Kernelsï¼‰**ï¼š

   * è¿™é‡Œçš„â€œæ™®é€šå†…æ ¸â€æŒ‡çš„æ˜¯ä½¿ç”¨NVLinkå’ŒRDMAæŠ€æœ¯ä¼ è¾“æ•°æ®çš„å¸¸è§„å†…æ ¸ï¼Œé€‚ç”¨äº**è®­ç»ƒä»»åŠ¡å’Œæ¨ç†å‰å¡«å……ä»»åŠ¡**ï¼ˆä¾‹å¦‚è®¡ç®—ä¸­é—´ç»“æœç­‰ï¼‰ã€‚

   * ç¬¬ä¸€å¼ è¡¨ä¸­çš„æ•°æ®å±•ç¤ºäº†èŠ‚ç‚¹å†…å’ŒèŠ‚ç‚¹é—´é€šä¿¡çš„å¸¦å®½ï¼Œè¯æ˜äº†é€šè¿‡**NVLink**å’Œ**RDMA**ä¼ è¾“æ•°æ®æ—¶ï¼ŒDeepEPèƒ½å¤Ÿæä¾›è¶³å¤Ÿçš„å¸¦å®½æ”¯æŒè¿™äº›è®¡ç®—ä»»åŠ¡ï¼Œç¡®ä¿ä»»åŠ¡èƒ½å¤Ÿé¡ºåˆ©è¿›è¡Œè€Œä¸å‡ºç°ç“¶é¢ˆã€‚

   * ä¾‹å¦‚ï¼Œè¡¨æ ¼ä¸­\*\*èŠ‚ç‚¹å†…ï¼ˆIntranodeï¼‰**çš„å¸¦å®½ä¸º153 GB/sï¼ˆNVLinkï¼‰ï¼Œè€Œ**èŠ‚ç‚¹é—´ï¼ˆInternodeï¼‰\*\*çš„å¸¦å®½ä¸º43-47 GB/sï¼ˆRDMAï¼‰ã€‚è¿™è¯´æ˜ï¼Œåœ¨ä¸åŒç¡¬ä»¶é…ç½®ä¸‹ï¼ŒDeepEPèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨è¿™äº›æŠ€æœ¯è¿›è¡Œé«˜ååé‡çš„æ•°æ®ä¼ è¾“ã€‚

2. **ä½å»¶è¿Ÿå†…æ ¸ï¼ˆLow-latency Kernelsï¼‰**ï¼š

   * â€œä½å»¶è¿Ÿå†…æ ¸â€åˆ™ä¸“é—¨é’ˆå¯¹æ¨ç†ä»»åŠ¡è¿›è¡Œä¼˜åŒ–ï¼Œå°¤å…¶æ˜¯**æ¨ç†è§£ç **ï¼ˆinference decodingï¼‰ã€‚è¿™ç§ä»»åŠ¡é€šå¸¸å¯¹å»¶è¿Ÿéå¸¸æ•æ„Ÿï¼Œæ‰€ä»¥éœ€è¦é€šè¿‡**RDMA**æŠ€æœ¯æ¥æœ€å¤§é™åº¦åœ°å‡å°‘å»¶è¿Ÿã€‚

   * ç¬¬äºŒå¼ è¡¨å±•ç¤ºäº†ä¸åŒæ•°é‡ä¸“å®¶ï¼ˆ#EPï¼‰ä¸‹çš„å»¶è¿Ÿè¡¨ç°ï¼Œè¡¨æ ¼ä¸­çš„æ•°æ®è¡¨æ˜ï¼ŒDeepEPåœ¨ä½¿ç”¨çº¯RDMAçš„æƒ…å†µä¸‹èƒ½å¤Ÿå®ç°éå¸¸ä½çš„å»¶è¿Ÿã€‚ä¾‹å¦‚ï¼Œå½“è°ƒåº¦8ä¸ªä¸“å®¶æ—¶ï¼Œå»¶è¿Ÿä¸º**163å¾®ç§’**ï¼›å½“è°ƒåº¦128ä¸ªä¸“å®¶æ—¶ï¼Œå»¶è¿Ÿä¸º**192å¾®ç§’**ã€‚è¿™ä¸ªä½å»¶è¿Ÿæ€§èƒ½å¯¹äºå®æ—¶æ¨ç†éå¸¸é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è§„æ¨¡åˆ†å¸ƒå¼è®¡ç®—ä¸­ã€‚

**å¯è¡Œæ€§è¯æ˜**

è¿™ä¸¤å¼ è¡¨çš„ä¸»è¦ä½œç”¨æ˜¯å±•ç¤ºåŸºäº**NVLink**å’Œ**RDMA**æŠ€æœ¯çš„DeepEPåœ¨å®é™…ä»»åŠ¡ä¸­çš„**é«˜æ€§èƒ½**å’Œ**ä½å»¶è¿Ÿ**ï¼Œå¹¶**è¯æ˜è¿™é¡¹æŠ€æœ¯çš„å¯è¡Œæ€§**ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒå’Œæ¨ç†ä¸­çš„åº”ç”¨ã€‚å®ƒä»¬å¸®åŠ©æˆ‘ä»¬ç†è§£ï¼š

* **å¯æ‰©å±•æ€§**ï¼šè¡¨æ ¼ä¸­å±•ç¤ºçš„å¸¦å®½å’Œå»¶è¿Ÿéšç€è°ƒåº¦ä¸“å®¶æ•°ç›®çš„å¢åŠ è€Œå˜åŒ–ï¼Œè¯æ˜DeepEPèƒ½å¤Ÿåœ¨ä¸åŒè§„æ¨¡çš„ä»»åŠ¡ä¸‹é«˜æ•ˆè¿è¡Œï¼Œä¸”éšç€ä»»åŠ¡çš„æ‰©å±•ï¼Œæ€§èƒ½è¡¨ç°ä»ç„¶æ˜¯å¯æ¥å—çš„ã€‚

* **ä¼˜åŒ–æ•ˆæœ**ï¼šé€šè¿‡è¿™äº›æµ‹è¯•æ•°æ®ï¼ŒDeepEPå±•ç¤ºäº†å…¶ä¼˜åŒ–è¿‡çš„å†…æ ¸èƒ½å¤Ÿæ˜¾è‘—æé«˜æ•°æ®ä¼ è¾“é€Ÿåº¦å¹¶å‡å°‘å»¶è¿Ÿï¼Œä»è€Œèƒ½å¤Ÿæ»¡è¶³å¤§è§„æ¨¡AIæ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„éœ€æ±‚ã€‚

#### 1.4 è®­ç»ƒä»»åŠ¡ã€æ¨ç†å‰å¡«å……ä»»åŠ¡å’Œæ¨ç†è§£ç æ¦‚å¿µè§£é‡Š

1. **è®­ç»ƒä»»åŠ¡ï¼ˆTraining Taskï¼‰**ï¼š

* è®­ç»ƒä»»åŠ¡

* æŒ‡çš„æ˜¯åœ¨æ·±åº¦å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œç”¨äºè®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹çš„ä»»åŠ¡ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸æ¶ˆè€—è®¡ç®—èµ„æºçš„è¿‡ç¨‹ï¼Œé€šå¸¸åŒ…æ‹¬ï¼š

  * **å‰å‘ä¼ æ’­ï¼ˆForward Propagationï¼‰**ï¼šå°†è¾“å…¥æ•°æ®é€šè¿‡ç¥ç»ç½‘ç»œä¼ é€’ï¼Œå¾—åˆ°é¢„æµ‹è¾“å‡ºã€‚

  * **æŸå¤±è®¡ç®—ï¼ˆLoss Calculationï¼‰**ï¼šè®¡ç®—ç½‘ç»œé¢„æµ‹å€¼å’Œå®é™…æ ‡ç­¾ä¹‹é—´çš„è¯¯å·®ã€‚

  * **åå‘ä¼ æ’­ï¼ˆBackward Propagationï¼‰**ï¼šé€šè¿‡è¯¯å·®åå‘ä¼ æ’­æ›´æ–°æ¨¡å‹çš„æƒé‡ï¼Œä½¿æ¨¡å‹é€æ¸æ›´å¥½åœ°è¿›è¡Œé¢„æµ‹ã€‚

  * **å‚æ•°æ›´æ–°ï¼ˆParameter Updateï¼‰**ï¼šä½¿ç”¨ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ï¼‰æ›´æ–°æ¨¡å‹ä¸­çš„å‚æ•°ã€‚

è®­ç»ƒä»»åŠ¡çš„ç›®çš„æ˜¯**è®©æ¨¡å‹é€šè¿‡å¤§é‡çš„è®­ç»ƒæ•°æ®å­¦ä¹ æ¨¡å¼å’Œè§„å¾‹**ï¼Œä»¥ä¾¿èƒ½å¤Ÿå¯¹æ–°æ•°æ®åšå‡ºå‡†ç¡®çš„é¢„æµ‹ã€‚

2. **æ¨ç†å‰å¡«å……ä»»åŠ¡ï¼ˆInference Prefilling Taskï¼‰**ï¼š

* **æ¨ç†å‰å¡«å……ä»»åŠ¡**é€šå¸¸æ˜¯åœ¨è¿›è¡Œæ¨ç†ä¹‹å‰ï¼Œå‡†å¤‡æ¨¡å‹è¾“å…¥æ•°æ®çš„è¿‡ç¨‹ã€‚æ¯”å¦‚ï¼Œåœ¨åšå¤§è§„æ¨¡çš„æ¨ç†æ—¶ï¼Œå¯èƒ½éœ€è¦æå‰å°†ä¸€äº›æ•°æ®åŠ è½½åˆ°å†…å­˜æˆ–è€…è¿›è¡Œå¿…è¦çš„é¢„å¤„ç†ï¼Œä»¥ç¡®ä¿æ¨ç†ä»»åŠ¡çš„é«˜æ•ˆæ‰§è¡Œã€‚

* è¿™ä¸ªè¿‡ç¨‹é€šå¸¸æ¶‰åŠå°†æ¨¡å‹éœ€è¦çš„è¾“å…¥æ•°æ®æå‰å‡†å¤‡å¥½ï¼Œä»¥å‡å°‘å®é™…æ¨ç†è¿‡ç¨‹ä¸­ç­‰å¾…æ•°æ®åŠ è½½çš„æ—¶é—´ã€‚\*\*â€œå‰å¡«å……â€\*\*å°±æ˜¯æå‰å¡«å……æ•°æ®ï¼Œä¸ºæ¨ç†ä»»åŠ¡åšå¥½å‡†å¤‡ã€‚

3. **æ¨ç†è§£ç ï¼ˆInference Decodingï¼‰**ï¼š

* **æ¨ç†**æ˜¯æŒ‡ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹çš„è¿‡ç¨‹ï¼Œä¹Ÿå°±æ˜¯æ¨¡å‹åº”ç”¨äºå®é™…åœºæ™¯çš„é˜¶æ®µã€‚ä¾‹å¦‚ï¼Œç»™å®šä¸€å¼ å›¾ç‰‡ï¼Œæ¨¡å‹æ¨ç†å‡ºå…¶ä¸­çš„ç‰©ä½“ç±»åˆ«ï¼›æˆ–è€…ç»™å®šä¸€æ®µæ–‡æœ¬ï¼Œæ¨¡å‹ç”Ÿæˆå¯¹åº”çš„ç­”æ¡ˆã€‚

* **æ¨ç†è§£ç **ç‰¹æŒ‡æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹æ ¹æ®è¾“å…¥æ•°æ®ï¼ˆå¦‚ä¸€æ®µæ–‡æœ¬ï¼‰**ç”Ÿæˆè¾“å‡ºç»“æœ**çš„è¿‡ç¨‹ã€‚è§£ç è¿‡ç¨‹é€šå¸¸æ¶‰åŠå°†æ¨¡å‹è¾“å‡ºçš„å‘é‡æˆ–æ¦‚ç‡è½¬åŒ–ä¸ºå®é™…çš„ç»“æœï¼Œä¾‹å¦‚å°†ç”Ÿæˆçš„æ–‡æœ¬åºåˆ—ä»æ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºè§£ç æˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ã€‚

  * ä¾‹å¦‚ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œå¦‚æœæ¨¡å‹æ˜¯ç”Ÿæˆæ–‡æœ¬çš„æ¨¡å‹ï¼ˆå¦‚GPTç±»æ¨¡å‹ï¼‰ï¼Œé‚£ä¹ˆâ€œè§£ç â€è¿‡ç¨‹å°±æ˜¯æ¨¡å‹ä»å†…éƒ¨çš„æ•°å€¼è¡¨ç¤ºï¼ˆå¦‚logitsã€æ¦‚ç‡åˆ†å¸ƒç­‰ï¼‰ç”Ÿæˆæœ€ç»ˆçš„è¯è¯­æˆ–å¥å­ã€‚

  * åœ¨å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­ï¼Œè§£ç å¯èƒ½æ˜¯æŒ‡å°†æ¨¡å‹ç”Ÿæˆçš„ç‰¹å¾å‘é‡è½¬åŒ–ä¸ºå®é™…çš„å›¾åƒã€‚

### 2. DeepEPéƒ¨ç½²æµç¨‹

#### 2.1 å¿«é€Ÿå¼€å§‹

\*\* ç¯å¢ƒè¦æ±‚\*\*

* Hopper GPUï¼ˆä»¥åå¯èƒ½æ”¯æŒæ›´å¤šæ¶æ„æˆ–è®¾å¤‡ï¼‰

* Python 3.8åŠä»¥ä¸Šç‰ˆæœ¬

* CUDA 12.3åŠä»¥ä¸Šç‰ˆæœ¬

* PyTorch 2.1åŠä»¥ä¸Šç‰ˆæœ¬

* ç”¨äºèŠ‚ç‚¹å†…é€šä¿¡çš„NVLink

* ç”¨äºèŠ‚ç‚¹é—´é€šä¿¡çš„RDMAç½‘ç»œ

* ä¸‹è½½å¹¶å®‰è£…NVSHMEMä¾èµ–

DeepEPè¿˜ä¾èµ–äºæˆ‘ä»¬ä¿®æ”¹è¿‡çš„NVSHMEMã€‚è¯·å‚è€ƒæˆ‘ä»¬çš„[NVSHMEMå®‰è£…æŒ‡å—](https://chatgpt.com/c/%E9%93%BE%E6%8E%A5)è·å–è¯¦ç»†çš„å®‰è£…è¯´æ˜ã€‚

#### 2.2 å¼€å‘

1. **æ„å»ºå¹¶åˆ›å»ºSOæ–‡ä»¶çš„ç¬¦å·é“¾æ¥**

```bash
NVSHMEM_DIR=/path/to/installed/nvshmem python setup.py build
```

* ä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„å¹³å°ä¿®æ”¹å…·ä½“çš„SOæ–‡ä»¶å

```bash
ln -s build/lib.linux-x86_64-cpython-38/deep_ep_cpp.cpython-38-x86_64-linux-gnu.so
```

1. **è¿è¡Œæµ‹è¯•ç”¨ä¾‹**

```bash
python tests/test_intranode.py
python tests/test_internode.py
python tests/test_low_latency.py
```

#### 2.3 å®‰è£…

```bash
NVSHMEM_DIR=/path/to/installed/nvshmem python setup.py install
```

ç„¶åï¼Œåœ¨ä½ çš„Pythoné¡¹ç›®ä¸­å¯¼å…¥`deep_ep`ï¼Œå°±å¯ä»¥å¼€å§‹ä½¿ç”¨äº†ï¼

ä»¥ä¸‹æ˜¯è¿™æ®µå†…å®¹çš„ç¿»è¯‘ï¼š

#### 2.4 ç½‘ç»œé…ç½®

DeepEPå·²ç»é€šè¿‡InfiniBandç½‘ç»œè¿›è¡Œäº†å……åˆ†æµ‹è¯•ã€‚ä¸è¿‡ï¼Œç†è®ºä¸Šå®ƒä¹Ÿä¸\*\*RDMA over Converged Ethernet (RoCE)\*\*å…¼å®¹ã€‚

#### 2.5 æµé‡éš”ç¦»

InfiniBandé€šè¿‡\*\*è™šæ‹Ÿé€šé“ï¼ˆVLï¼‰\*\*æ”¯æŒæµé‡éš”ç¦»ã€‚

ä¸ºäº†é¿å…ä¸åŒç±»å‹æµé‡ä¹‹é—´çš„å¹²æ‰°ï¼Œæˆ‘ä»¬å»ºè®®å°†ä¸åŒçš„å·¥ä½œè´Ÿè½½åˆ’åˆ†åˆ°ä¸åŒçš„è™šæ‹Ÿé€šé“ä¸­ï¼Œå…·ä½“åˆ’åˆ†å¦‚ä¸‹ï¼š

* ä½¿ç”¨æ™®é€šå†…æ ¸çš„å·¥ä½œè´Ÿè½½

* ä½¿ç”¨ä½å»¶è¿Ÿå†…æ ¸çš„å·¥ä½œè´Ÿè½½

* å…¶ä»–å·¥ä½œè´Ÿè½½

å¯¹äºDeepEPï¼Œä½ å¯ä»¥é€šè¿‡è®¾ç½®`NVSHMEM_IB_SL`ç¯å¢ƒå˜é‡æ¥æ§åˆ¶è™šæ‹Ÿé€šé“çš„åˆ†é…ã€‚

#### 2.6 è‡ªé€‚åº”è·¯ç”±

è‡ªé€‚åº”è·¯ç”±æ˜¯InfiniBandäº¤æ¢æœºæä¾›çš„ä¸€ç§é«˜çº§è·¯ç”±åŠŸèƒ½ï¼Œèƒ½å¤Ÿå‡åŒ€åœ°å°†æµé‡åˆ†é…åˆ°å¤šä¸ªè·¯å¾„ä¸Šã€‚ç›®å‰ï¼Œä½å»¶è¿Ÿå†…æ ¸æ”¯æŒè‡ªé€‚åº”è·¯ç”±ï¼Œè€Œæ™®é€šå†…æ ¸åˆ™ä¸æ”¯æŒï¼ˆå¯èƒ½å¾ˆå¿«ä¼šåŠ å…¥æ­¤åŠŸèƒ½ï¼‰ã€‚å¯ç”¨è‡ªé€‚åº”è·¯ç”±ç”¨äºæ™®é€šèŠ‚ç‚¹é—´å†…æ ¸æ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ­»é”æˆ–æ•°æ®æŸåé—®é¢˜ã€‚

å¯¹äºä½å»¶è¿Ÿå†…æ ¸ï¼Œå¯ç”¨è‡ªé€‚åº”è·¯ç”±å¯ä»¥å®Œå…¨æ¶ˆé™¤ç”±äºè·¯ç”±å†²çªå¯¼è‡´çš„ç½‘ç»œæ‹¥å¡ï¼Œä½†ä¹Ÿä¼šå¼•å…¥é¢å¤–çš„å»¶è¿Ÿã€‚æˆ‘ä»¬å»ºè®®åœ¨ä»¥ä¸‹é…ç½®ä¸‹ä»¥è·å¾—æœ€ä½³æ€§èƒ½ï¼š

* åœ¨ç½‘ç»œè´Ÿè½½è¾ƒé‡çš„ç¯å¢ƒä¸­å¯ç”¨è‡ªé€‚åº”è·¯ç”±

* åœ¨ç½‘ç»œè´Ÿè½½è¾ƒè½»çš„ç¯å¢ƒä¸­ä½¿ç”¨é™æ€è·¯ç”±

#### 2.7 æ‹¥å¡æ§åˆ¶

ç”±äºæˆ‘ä»¬åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æœªè§‚å¯Ÿåˆ°æ˜¾è‘—çš„æ‹¥å¡ï¼Œå› æ­¤**æ‹¥å¡æ§åˆ¶è¢«ç¦ç”¨**ã€‚

ä»¥ä¸‹æ˜¯è¿™æ®µå†…å®¹çš„ç¿»è¯‘ï¼š

### 3. åœ¨æ¨¡å‹è®­ç»ƒæˆ–æ¨ç†å‰å¡«å……ä¸­çš„ç¤ºä¾‹ä½¿ç”¨

æ™®é€šå†…æ ¸å¯ç”¨äºæ¨¡å‹è®­ç»ƒæˆ–æ¨ç†å‰å¡«å……é˜¶æ®µï¼ˆä¸åŒ…æ‹¬åå‘ä¼ æ’­éƒ¨åˆ†ï¼‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºçš„ç¤ºä¾‹ä»£ç ã€‚

```python
import torch
import torch.distributed as dist
from typing import List, Tuple, Optional, Union

from deep_ep import Buffer, EventOverlap

# é€šä¿¡ç¼“å†²åŒºï¼ˆå°†åœ¨è¿è¡Œæ—¶åˆ†é…ï¼‰
_buffer: Optional[Buffer] = None

# è®¾ç½®è¦ä½¿ç”¨çš„SMæ•°é‡
# æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªé™æ€å˜é‡
Buffer.set_num_sms(24)

# ä½ å¯ä»¥åœ¨æ¡†æ¶åˆå§‹åŒ–æ—¶è°ƒç”¨æ­¤å‡½æ•°
def get_buffer(group: dist.ProcessGroup, hidden_bytes: int) -> Buffer:
    global _buffer
    
    # æ³¨æ„ï¼šä½ ä¹Ÿå¯ä»¥ç”¨é€šè¿‡æ‰€æœ‰æµ‹è¯•å¾—å‡ºçš„è‡ªåŠ¨è°ƒä¼˜ç»“æœæ›¿æ¢`get_*_config`
    num_nvl_bytes, num_rdma_bytes = 0, 0
    for config in (Buffer.get_dispatch_config(group.size()), Buffer.get_combine_config(group.size())):
        num_nvl_bytes = max(config.get_nvl_buffer_size_hint(hidden_bytes, group.size()), num_nvl_bytes)
        num_rdma_bytes = max(config.get_rdma_buffer_size_hint(hidden_bytes, group.size()), num_rdma_bytes)

    # å¦‚æœç¼“å†²åŒºä¸å­˜åœ¨æˆ–ç¼“å†²åŒºå¤§å°ä¸è¶³ï¼Œåˆ™åˆ†é…ç¼“å†²åŒº
    # æ³¨æ„ï¼šç½‘ç»œçš„è‡ªé€‚åº”è·¯ç”±é…ç½®**å¿…é¡»å…³é—­**
    if _buffer is None or _buffer.group != group or _buffer.num_nvl_bytes < num_nvl_bytes or _buffer.num_rdma_bytes < num_rdma_bytes:
        _buffer = Buffer(group, num_nvl_bytes, num_rdma_bytes)
    return _buffer


def get_hidden_bytes(x: torch.Tensor) -> int:
    t = x[0] if isinstance(x, tuple) else x
    return t.size(1) * max(t.element_size(), 2)


def dispatch_forward(x: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],
                     topk_idx: torch.Tensor, topk_weights: torch.Tensor,
                     num_experts: int, previous_event: Optional[EventOverlap] = None) -> \
        Tuple[Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]], torch.Tensor, torch.Tensor, List, Tuple, EventOverlap]:
    # æ³¨æ„ï¼šå¯é€‰çš„`previous_event`æ„å‘³ç€ä½ å¸Œæœ›å°†å…¶ä½œä¸ºåˆ†æ´¾å†…æ ¸çš„ä¾èµ–é¡¹ï¼Œå®ƒå¯èƒ½åœ¨é€šä¿¡ä¸è®¡ç®—é‡å æ—¶å¾ˆæœ‰ç”¨ã€‚
    # æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ`Buffer.dispatch`æ–‡æ¡£
    global _buffer

    # åœ¨å®é™…åˆ†æ´¾ä¹‹å‰è®¡ç®—å¸ƒå±€
    num_tokens_per_rank, num_tokens_per_rdma_rank, num_tokens_per_expert, is_token_in_rank, previous_event = \
        _buffer.get_dispatch_layout(topk_idx, num_experts,
                                    previous_event=previous_event, async_finish=True,
                                    allocate_on_comm_stream=previous_event is not None)
    # æ‰§è¡ŒMoEåˆ†æ´¾
    # æ³¨æ„ï¼šCPUå°†ç­‰å¾…GPUçš„ä¿¡å·åˆ°è¾¾ï¼Œå› æ­¤è¿™ä¸CUDAå›¾ä¸å…¼å®¹
    # å¯¹äºæ›´é«˜çº§çš„ç”¨æ³•ï¼Œè¯·å‚é˜…`dispatch`å‡½æ•°çš„æ–‡æ¡£
    recv_x, recv_topk_idx, recv_topk_weights, num_recv_tokens_per_expert_list, handle, event = \
        _buffer.dispatch(x, topk_idx=topk_idx, topk_weights=topk_weights,
                         num_tokens_per_rank=num_tokens_per_rank, num_tokens_per_rdma_rank=num_tokens_per_rdma_rank,
                         is_token_in_rank=is_token_in_rank, num_tokens_per_expert=num_tokens_per_expert,
                         previous_event=previous_event, async_finish=True,
                         allocate_on_comm_stream=True)
    # å…³äºäº‹ä»¶ç®¡ç†ï¼Œè¯·å‚è€ƒ`EventOverlap`ç±»çš„æ–‡æ¡£
    return recv_x, recv_topk_idx, recv_topk_weights, num_recv_tokens_per_expert_list, handle, event


def dispatch_backward(grad_recv_x: torch.Tensor, grad_recv_topk_weights: torch.Tensor, handle: Tuple) -> \
        Tuple[torch.Tensor, torch.Tensor, EventOverlap]:
    global _buffer

    # MoEåˆ†æ´¾çš„åå‘è¿‡ç¨‹å®é™…ä¸Šæ˜¯ä¸€ä¸ªåˆå¹¶æ“ä½œ
    # å¯¹äºæ›´é«˜çº§çš„ç”¨æ³•ï¼Œè¯·å‚é˜…`combine`å‡½æ•°çš„æ–‡æ¡£
    combined_grad_x, combined_grad_recv_topk_weights, event = \
        _buffer.combine(grad_recv_x, handle, topk_weights=grad_recv_topk_weights, async_finish=True)

    # å…³äºäº‹ä»¶ç®¡ç†ï¼Œè¯·å‚è€ƒ`EventOverlap`ç±»çš„æ–‡æ¡£
    return combined_grad_x, combined_grad_recv_topk_weights, event


def combine_forward(x: torch.Tensor, handle: Tuple, previous_event: Optional[EventOverlap] = None) -> \
        Tuple[torch.Tensor, EventOverlap]:
    global _buffer

    # æ‰§è¡ŒMoEåˆå¹¶
    # å¯¹äºæ›´é«˜çº§çš„ç”¨æ³•ï¼Œè¯·å‚é˜…`combine`å‡½æ•°çš„æ–‡æ¡£
    combined_x, _, event = _buffer.combine(x, handle, async_finish=True, previous_event=previous_event,
                                           allocate_on_comm_stream=previous_event is not None)

    # å…³äºäº‹ä»¶ç®¡ç†ï¼Œè¯·å‚è€ƒ`EventOverlap`ç±»çš„æ–‡æ¡£
    return combined_x, event


def combine_backward(grad_combined_x: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],
                     handle: Tuple, previous_event: Optional[EventOverlap] = None) -> \
        Tuple[Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]], EventOverlap]:
    global _buffer

    # MoEåˆå¹¶çš„åå‘è¿‡ç¨‹å®é™…ä¸Šæ˜¯ä¸€ä¸ªåˆ†æ´¾æ“ä½œ
    # å¯¹äºæ›´é«˜çº§çš„ç”¨æ³•ï¼Œè¯·å‚é˜…`combine`å‡½æ•°çš„æ–‡æ¡£
    grad_x, _, _, _, _, event = _buffer.dispatch(grad_combined_x, handle=handle, async_finish=True,
                                                 previous_event=previous_event,
                                                 allocate_on_comm_stream=previous_event is not None)

    # å…³äºäº‹ä»¶ç®¡ç†ï¼Œè¯·å‚è€ƒ`EventOverlap`ç±»çš„æ–‡æ¡£
    return grad_x, event
```

å¦å¤–ï¼Œåˆ†æ´¾å‡½æ•°å†…éƒ¨ï¼Œæˆ‘ä»¬å¯èƒ½ä¸çŸ¥é“å½“å‰rankéœ€è¦æ¥æ”¶å¤šå°‘ä¸ªtokensã€‚å› æ­¤ï¼Œä¼šæ¶‰åŠåˆ°ä¸€ä¸ªéšå¼çš„CPUç­‰å¾…GPUæ¥æ”¶è®¡æ•°ä¿¡å·çš„è¿‡ç¨‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![](images/30eb2a9e-7230-40fe-80fb-fe3596db1465.png)

### 4. åœ¨æ¨ç†è§£ç ä¸­çš„ç¤ºä¾‹ä½¿ç”¨

ä½å»¶è¿Ÿå†…æ ¸å¯ä»¥ç”¨äºæ¨ç†è§£ç é˜¶æ®µï¼Œå¦‚ä¸‹é¢çš„ç¤ºä¾‹ä»£ç æ‰€ç¤ºã€‚

```python
import torch
import torch.distributed as dist
from typing import Tuple, Optional

from deep_ep import Buffer

# é€šä¿¡ç¼“å†²åŒºï¼ˆå°†åœ¨è¿è¡Œæ—¶åˆ†é…ï¼‰
# æ³¨æ„ï¼šä½å»¶è¿Ÿå†…æ ¸æ²¡æœ‰SMæ§åˆ¶API
_buffer: Optional[Buffer] = None


# ä½ å¯ä»¥åœ¨æ¡†æ¶åˆå§‹åŒ–æ—¶è°ƒç”¨æ­¤å‡½æ•°
def get_buffer(group: dist.ProcessGroup, num_max_dispatch_tokens_per_rank: int, hidden: int, num_experts: int) -> Buffer:
    # æ³¨æ„ï¼šä½å»¶è¿Ÿæ¨¡å¼ä¼šæ¯”æ™®é€šæ¨¡å¼æ¶ˆè€—æ›´å¤šç©ºé—´
    # å› æ­¤æˆ‘ä»¬å»ºè®®`num_max_dispatch_tokens_per_rank`ï¼ˆè§£ç å¼•æ“ä¸­çš„å®é™…æ‰¹é‡å¤§å°ï¼‰åº”å°äº256
    global _buffer
    num_rdma_bytes = Buffer.get_low_latency_rdma_size_hint(num_max_dispatch_tokens_per_rank, hidden, group.size(), num_experts)

    # å¦‚æœç¼“å†²åŒºä¸å­˜åœ¨æˆ–ç¼“å†²åŒºå¤§å°ä¸è¶³ï¼Œåˆ™åˆ†é…ç¼“å†²åŒº
    if _buffer is None or _buffer.group != group or not _buffer.low_latency_mode or _buffer.num_rdma_bytes < num_rdma_bytes:
        # æ³¨æ„ï¼šä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼ŒQPæ•°é‡**å¿…é¡»**ç­‰äºæœ¬åœ°ä¸“å®¶çš„æ•°é‡
        assert num_experts % group.size() == 0
        _buffer = Buffer(group, 0, num_rdma_bytes, low_latency_mode=True, num_qps_per_rank=num_experts // group.size())
    return _buffer


def low_latency_dispatch(hidden_states: torch.Tensor, topk_idx: torch.Tensor, num_max_dispatch_tokens_per_rank: int, num_experts: int):
    global _buffer

    # æ‰§è¡ŒMoEåˆ†æ´¾ï¼Œå…¼å®¹CUDAå›¾ï¼ˆä½†æ˜¯ä½ å¯èƒ½éœ€è¦åœ¨é‡æ”¾æ—¶æ¢å¤ä¸€äº›ç¼“å†²åŒºçŠ¶æ€ï¼‰
    recv_hidden_states, recv_expert_count, handle, event, hook = \
        _buffer.low_latency_dispatch(hidden_states, topk_idx, num_max_dispatch_tokens_per_rank, num_experts,
                                     async_finish=False, return_recv_hook=True)

    # æ³¨æ„ï¼šå®é™…çš„å¼ é‡åªæœ‰åœ¨ä½ è°ƒç”¨`hook()`æ—¶æ‰ä¼šæ¥æ”¶ï¼Œ
    # å®ƒå¯¹åŒæ‰¹é‡å å¾ˆæœ‰ç”¨ï¼Œä½†**æ²¡æœ‰ä»»ä½•SMå ç”¨**ã€‚
    # å¦‚æœä½ ä¸æƒ³é‡å ï¼Œè¯·è®¾ç½®`return_recv_hook=False`
    # ä¹‹åï¼Œä½ å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„GEMMåº“æ¥ç”¨è¿™ç§ç‰¹å®šæ ¼å¼è¿›è¡Œè®¡ç®—
    return recv_hidden_states, recv_expert_count, handle, event, hook


def low_latency_combine(hidden_states: torch.Tensor,
                        topk_idx: torch.Tensor, topk_weights: torch.Tensor, handle: Tuple):
    global _buffer

    # æ‰§è¡ŒMoEåˆå¹¶ï¼Œå…¼å®¹CUDAå›¾ï¼ˆä½†ä½ å¯èƒ½éœ€è¦åœ¨é‡æ”¾æ—¶æ¢å¤ä¸€äº›ç¼“å†²åŒºçŠ¶æ€ï¼‰
    combined_hidden_states, event_overlap, hook = \
        _buffer.low_latency_combine(hidden_states, topk_idx, topk_weights, handle,
                                    async_finish=False, return_recv_hook=True)

    # æ³¨æ„ï¼šä¸åˆ†æ´¾å†…æ ¸ä¸­æè¿°çš„è¡Œä¸ºç›¸åŒ
    return combined_hidden_states, event_overlap, hook
```

å¯¹äºåŒå¾®æ‰¹é‡å ï¼Œæ‚¨å¯ä»¥å‚è€ƒä»¥ä¸‹å›¾ç¤ºã€‚é€šè¿‡æˆ‘ä»¬çš„æ¥æ”¶é’©å­æ¥å£ï¼ŒRDMAç½‘ç»œæµé‡åœ¨åå°å‘ç”Ÿï¼Œè€Œä¸ä¼šå ç”¨ä»»ä½•GPU SMsç”¨äºè®¡ç®—éƒ¨åˆ†ã€‚ä½†æ˜¯è¯·æ³¨æ„ï¼Œé‡å çš„éƒ¨åˆ†å¯ä»¥è¿›è¡Œè°ƒæ•´ï¼Œå³æ³¨æ„åŠ›/åˆ†æ´¾/MoE/åˆå¹¶è¿™å››ä¸ªéƒ¨åˆ†çš„æ‰§è¡Œæ—¶é—´å¯èƒ½å¹¶ä¸å®Œå…¨ç›¸åŒã€‚æ‚¨å¯ä»¥æ ¹æ®å·¥ä½œè´Ÿè½½çš„éœ€æ±‚è°ƒæ•´é˜¶æ®µè®¾ç½®ã€‚

![](images/6bcda229-784c-42ff-8275-73d54c522597.png)

* æ³¨æ„äº‹é¡¹

ä¸ºäº†å®ç°æé™æ€§èƒ½ï¼Œæˆ‘ä»¬å‘ç°å¹¶ä½¿ç”¨äº†ä¸€æ¡æ–‡æ¡£å¤–çš„PTXæŒ‡ä»¤ï¼š`ld.global.nc.L1::no_allocate.L2::256B`ã€‚è¿™æ¡æŒ‡ä»¤ä¼šå¯¼è‡´æœªå®šä¹‰è¡Œä¸ºï¼šä½¿ç”¨éä¸€è‡´æ€§åªè¯»PTXä¿®é¥°ç¬¦`.nc`è®¿é—®GPUæ˜“å¤±æ€§å†…å­˜ã€‚ä½†ç»è¿‡æµ‹è¯•ï¼Œåœ¨Hopperæ¶æ„ä¸Šä½¿ç”¨`.L1::no_allocate`æ—¶ï¼Œå…¶æ­£ç¡®æ€§èƒ½å¤Ÿå¾—åˆ°ä¿è¯ï¼Œä¸”æ€§èƒ½ä¼šå¤§å¹…æå‡ã€‚å¦‚æœæ‚¨åœ¨å…¶ä»–å¹³å°ä¸Šå‘ç°å†…æ ¸æ— æ³•æ­£å¸¸å·¥ä½œï¼Œå¯ä»¥åœ¨`setup.py`ä¸­æ·»åŠ `DISABLE_AGGRESSIVE_PTX_INSTRS=1`æ¥ç¦ç”¨æ­¤æŒ‡ä»¤ï¼Œæˆ–æäº¤é—®é¢˜æŠ¥å‘Šã€‚

ä¸ºäº†åœ¨æ‚¨çš„é›†ç¾¤ä¸Šè·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œå»ºè®®è¿è¡Œæ‰€æœ‰æµ‹è¯•å¹¶ä½¿ç”¨æœ€ä½³çš„è‡ªåŠ¨è°ƒä¼˜é…ç½®ã€‚é»˜è®¤é…ç½®æ˜¯åŸºäºDeepSeekçš„å†…éƒ¨é›†ç¾¤è¿›è¡Œä¼˜åŒ–çš„ã€‚



**æ›´å¤šå¤§æ¨¡å‹æŠ€æœ¯å†…å®¹å­¦ä¹ **

**æ‰«ç æ·»åŠ åŠ©ç†è‹±è‹±ï¼Œå›å¤â€œå¤§æ¨¡å‹â€ï¼Œäº†è§£æ›´å¤šå¤§æ¨¡å‹æŠ€æœ¯è¯¦æƒ…å“¦ğŸ‘‡**

![](images/f339b04b7b20233dd1509c7fb36d5c0.png)

**æ‰«ç å›å¤â€œå…¥ç¾¤â€**ï¼Œå³å¯åŠ å…¥**å¤§æ¨¡å‹æŠ€æœ¯ç¤¾ç¾¤ï¼šæµ·é‡ç¡¬æ ¸ç‹¬å®¶æŠ€æœ¯`å¹²è´§å†…å®¹`+æ— é—¨æ§›`æŠ€æœ¯äº¤æµ`ï¼**
