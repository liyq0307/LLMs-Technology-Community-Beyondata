# è¯¾ç¨‹è¯´æ˜ï¼š

* ä½“éªŒè¯¾å†…å®¹èŠ‚é€‰è‡ª[ã€Š2025å¤§æ¨¡å‹åŸç†ä¸è®­ç»ƒå®æˆ˜è¯¾ã€‹(2æœˆç­)](https://whakv.xetslk.com/s/3RF3FO)å®Œæ•´ç‰ˆä»˜è´¹è¯¾ç¨‹

â€ƒ  ä½“éªŒè¯¾æ—¶é—´æœ‰é™ï¼Œè‹¥æƒ³æ·±åº¦å­¦ä¹ å¤§æ¨¡å‹æŠ€æœ¯ï¼Œæ¬¢è¿å¤§å®¶æŠ¥åç”±æˆ‘ä¸»è®²çš„[ã€Š2025å¤§æ¨¡å‹åŸç†ä¸è®­ç»ƒå®æˆ˜è¯¾ã€‹(2æœˆç­)](https://whakv.xetslk.com/s/3RF3FO)ï¼š

![](images/image.png)

![](images/image-1.png)

æ­¤å¤–ï¼Œå…¬å¼€è¯¾å…¨å¥—å­¦ä¹ èµ„æ–™ï¼Œå·²ä¸Šä¼ è‡³ç½‘ç›˜ï¼ˆhttps://pan.baidu.com/s/1wZ6jtWN-04Wt\_GhcjTeJYw?pwd=mhye ï¼‰

**éœ€è¦æ›´ç³»ç»Ÿæ·±å…¥å­¦ä¹ å¤§æ¨¡å‹å¯æ‰«ç â¬†ï¸æ·»åŠ åŠ©æ•™å’¨è¯¢å–”ï½**

***

## ã€Š2025å¤§æ¨¡å‹åŸç†ä¸è®­ç»ƒã€‹ä½“éªŒè¯¾

## DeepSeek R1 GRPOç®—æ³•å®æˆ˜

### ä¸€ã€DeepSeek R1æ¨¡å‹è®­ç»ƒæµç¨‹å›é¡¾ä¸å‡†å¤‡å·¥ä½œ

* å›é¡¾DeepSeek R1è®­ç»ƒæµç¨‹

![](images/4ba1da80-1188-46f0-849b-74adcf32efb1.png)

* DeepSeek R1æ¨¡å‹èƒŒåçš„åŠŸè‡£ï¼šGRPOç®—æ³•

â€ƒâ€ƒåœ¨äº†è§£äº†DeepSeek R1çš„è®­ç»ƒæµç¨‹ä¹‹åï¼Œæ¥ä¸‹æ¥è®©æˆ‘ä»¬å¿«é€Ÿä¸Šæ‰‹å®è·µDeepSeekæå‡ºçš„GRPOç®—æ³•ï¼Œå¹¶æ‰‹åŠ¨å¤ç°DeepSeek R1è®ºæ–‡ä¸­çš„æ¨¡å‹å¼€æ‚Ÿæ—¶åˆ»ï¼Œå³é€šè¿‡GRPOè®­ç»ƒï¼Œè®©æ¨¡å‹è¯ç”Ÿæ€è€ƒé“¾ã€‚è¿™ä¹Ÿæ˜¯æ•´ä¸ªDeepSeek R1æ¨¡å‹è®­ç»ƒçš„è‡³å…³é‡è¦çš„ç¯èŠ‚ï¼Œä¹Ÿæ˜¯DeepSeek R1æ¨¡å‹ä¸ºå¤§æ¨¡å‹æŠ€æœ¯åšå‡ºçš„å“è¶Šè´¡çŒ®ã€‚

â€ƒâ€ƒæˆªæ­¢ç›®å‰ï¼Œå…¨çƒèŒƒå›´å†…å·²ç»æœ‰å¾ˆå¤šå›¢é˜Ÿå°è¯•å¤ç°DeepSeek R1ï¼Œå¹¶ä¸”åœ¨GRPOç®—æ³•å®è·µä¸Šå–å¾—äº†ä¸é”™çš„æˆç»©ï¼Œç”¨äº‹å®è¯æ˜äº†GRPOç®—æ³•æœ¬èº«çš„æœ‰æ•ˆæ€§ã€‚

â€ƒâ€ƒä¸åŒäºä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒç®—æ³•ï¼Œæˆ–è€…å¸¸ç”¨çš„PPOç®—æ³•ï¼ŒGRPOç®—æ³•æ›´åŠ çœæ—¶é«˜æ•ˆï¼Œé€šè¿‡æš´åŠ›æšä¸¾ç­–ç•¥ã€ä»¥åŠè‡ªæˆ‘ç­–ç•¥å¯¹æ¯”çš„æ–¹æ³•å¿«é€Ÿæå‡æ¨¡å‹åœ¨æ¨ç†é—®é¢˜ä¸Šåˆ¶å®šç­–ç•¥çš„èƒ½åŠ›ã€‚è¿™ä¹Ÿæ˜¯ç›®å‰å¼ºåŒ–å­¦ä¹ é¢†åŸŸã€è¢«éªŒè¯çš„æœ€æœ‰æ•ˆçš„æå‡å¤§æ¨¡å‹æ¨ç†èƒ½åŠ›çš„æ–¹æ³•ã€‚

![](images/82491785-1a98-4288-b4e1-2a37ad1d7163.png)

* GRPOç®—æ³•å®ç°æ–¹æ³•

â€ƒâ€ƒä¼´éšç€DeepSeek R1ç«éå…¨çƒï¼ŒGRPOç®—æ³•çš„ä½¿ç”¨éœ€æ±‚ä¹Ÿæ˜¯ä¸æ–­å¢åŠ ï¼Œæˆªæ­¢ç›®å‰ï¼Œä¸»æµçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶å‡æ”¯æŒGRPOç®—æ³•ï¼Œå¯ä»¥ä¸€é”®è¿›è¡Œè°ƒç”¨ã€‚åŒ…æ‹¬ï¼š

* veRLåº“ï¼šhttps://github.com/volcengine/verl

![](images/d31f3d33-e204-4b9d-9d4b-006debbbee9a.png)

* trlåº“ï¼šhttps://github.com/huggingface/trl

![](images/142e5b88-712e-48e1-a112-f9d4318fd210.png)

* OpenRLHF:https://github.com/OpenRLHF/OpenRLHF

![](images/ce1224f1-3ccf-437b-9bb9-3314a7e74963.png)

* unsloth:https://github.com/unslothai/unsloth

![](images/1ebd2795-f75a-42d7-aaa2-3f094c6be739.png)

æœ¬èŠ‚å…¬å¼€è¯¾ï¼Œæˆ‘ä»¬é‡‡ç”¨æœ€åŸºç¡€çš„trlåº“ï¼Œå¹¶åœ¨Jupyterä¸­å®Œæˆå›´ç»•Qwen2.5-0.5B-instructæ¨¡å‹çš„GRPOå¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œå¹¶å¤ç°DeepSeek R1æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„ahaæ—¶åˆ»ï¼Œå¦èµ·è¯ç”Ÿæ€è€ƒè¿‡ç¨‹ã€‚

* æ¨èå®éªŒç¯å¢ƒ

â€ƒâ€ƒä¸ºäº†å…¼é¡¾å®éªŒæ•ˆæœä¸è¿è¡Œæ•ˆç‡ï¼ŒGRPOè®­ç»ƒè¿‡ç¨‹çº¦éœ€è¦17Gæ˜¾å­˜ï¼Œå¹¶è¿è¡Œ4-6ä¸ªå°æ—¶å·¦å³ã€‚è‹¥åœ¨AutoDLä¸Šç§ŸèµæœåŠ¡å™¨ï¼Œå¯é€‰3090å•å¡æœåŠ¡å™¨ï¼Œæ¯å°æ—¶1.5å…ƒï¼Œæ€»æˆæœ¬çº¦8-10å…ƒã€‚

â€ƒâ€ƒå…¬å¼€è¯¾å®éªŒç¯å¢ƒå¦‚ä¸‹ï¼š

![](images/e2a4f5bb-a763-4bac-9b36-2575a7ccacab.png)

â€ƒâ€ƒæ›´å¤šå…³äºAutoDLæœåŠ¡å™¨ç§Ÿèµæ–¹æ³•ä¸è¿œç¨‹è¿æ¥æ–¹æ³•ï¼Œå¯ä»¥å‚è€ƒå…¬å¼€è¯¾ã€ŠAutoDLå¿«é€Ÿå…¥é—¨æŒ‡å—ã€‹ï¼šhttps://www.bilibili.com/video/BV1bxB7YYEST/

![](images/bb5da2e9-3b70-4760-977c-fc58a8f6904d.png)

* è¯¾ä»¶èµ„æ–™é¢†å–

â€ƒâ€ƒå…¬å¼€è¯¾å…¨å¥—è¯¾ä»¶èµ„æ–™ï¼ŒåŒ…æ‹¬è¯¾ä»¶ã€ä»£ç ã€GRPOè®­ç»ƒæ•°æ®é›†ã€è®­ç»ƒå‰åæ¨¡å‹æƒé‡ã€ä»¥åŠå‚è€ƒèµ„æ–™ç­‰ï¼Œå‡å·²ä¸Šä¼ ç½‘ç›˜ï¼š

![](images/e217355c-2119-4575-82b3-9f713d0da7d1.png)

**æ‰«ç æ·»åŠ åŠ©æ•™ï¼Œå³å¯é¢†å–å…¨éƒ¨èµ„æ–™ğŸ‘‡**

![](images/image-2.png)

* å®éªŒç›®æ ‡

â€ƒâ€ƒæœ¬èŠ‚å…¬å¼€è¯¾ï¼Œæˆ‘ä»¬å°†å€ŸåŠ©trlåº“ï¼Œå¤åˆ»DeepSeek R1å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ ¸å¿ƒæŠ€æœ¯ï¼ŒGRPOï¼Œå¹¶åœ¨Qwen2.5-0.5B-Instructå°å°ºå¯¸æ¨¡å‹ä¸Šï¼Œè®­ç»ƒä»¤å…¶è¯ç”Ÿæ¨ç†èƒ½åŠ›ã€‚

è®­ç»ƒå‰å›å¤ï¼š

![](images/d850af2a-1793-49ba-abea-47c5f1571e96.png)

è®­ç»ƒåå›å¤ï¼š

![](images/5cb1353e-77fb-435b-8f9e-3e97e7e56143.png)

### äºŒã€åŸºç¡€ç¯å¢ƒå‡†å¤‡

* æ¨¡å‹ä¸‹è½½

â€ƒâ€ƒæœ¬èŠ‚å…¬å¼€è¯¾ä»¥Qwen2.5-0.5B-Instructæ¨¡å‹ä¸ºä¾‹è¿›è¡ŒGRPOå¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œå¯ä»¥ä»é­”æ­ç¤¾åŒºä¸­ä¸‹è½½æ¨¡å‹æƒé‡ï¼šhttps://www.modelscope.cn/models/Qwen/Qwen2.5-0.5B-Instruct

![](images/d81cde2a-c76e-4230-9c07-6ad092535519.png)

åœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼Œå°†æ¨¡å‹æƒé‡ä¸‹è½½åˆ°`Qwen2.5-0.5B-Instruct`æ–‡ä»¶å¤¹ä¸­ï¼š

```bash
pip install modelscope
```

```bash
mkdir ./Qwen2.5-0.5B-Instruct
modelscope download --model Qwen/Qwen2.5-0.5B-Instruct --local_dir ./Qwen2.5-0.5B-Instruct
```

![](images/d273c62d-1d1a-4d84-bdd9-59b2cfac99b8.png)

* å®‰è£…ç›¸å…³åº“

â€ƒâ€ƒç„¶åéœ€è¦å®‰è£…ç›¸å…³çš„åº“ï¼š

```bash
pip install torch
pip install transformers
pip install trl
```

![](images/975f8878-6679-4ad6-b2dd-e2b76cb23ec7.png)

* æ¨¡å‹å°è¯•è°ƒç”¨

â€ƒâ€ƒå®‰è£…å®Œæˆåï¼Œæ¥ä¸‹æ¥å³å¯æµ‹è¯•æ¨¡å‹çš„å¯¹è¯èƒ½åŠ›ï¼š

```python
from modelscope import AutoModelForCausalLM, AutoTokenizer
```

é¦–å…ˆè¯»å–æ¨¡å‹ï¼š

```python
model_name = "./models/Qwen2.5-0.5B-Instruct"
```

```python
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)
```

```plaintext
Some parameters are on the meta device because they were offloaded to the cpu.
```

åˆ›å»ºå¯¹è¯æ¶ˆæ¯ï¼š

```python
prompt = "Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?"
```

```python
messages = [
    {"role": "user", "content": prompt}
]
```

```python
messages
```

```plaintext
[{'role': 'user',
  'content': 'Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?'}]
```

å¸¦å…¥å¯¹è¯æ¨¡æ¿ï¼Œå¹¶è¿›è¡Œåˆ†è¯ï¼š

```python
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
```

```python
model_inputs
```

```plaintext
{'input_ids': tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,
            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,
             13, 151645,    198, 151644,    872,    198,  79771,    646,   1349,
            220,     23,   6816,    315,    264,   2311,    304,    220,     17,
             15,   4420,     13,   2585,   1657,   4115,    686,    432,   1896,
           1059,    311,   1349,    220,     16,     17,     15,   6816,     30,
         151645,    198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}
```

å¸¦å…¥æ¨¡å‹åˆ›å»ºå›å¤ï¼š

```python
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=512
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]
```

```python
generated_ids
```

```plaintext
[tensor([  1249,   8253,   1246,   1293,    432,   4990,  27138,    311,   1349,
            220,     16,     17,     15,   6816,     11,    582,   1184,    311,
           1156,   1477,    700,   1059,   5290,   4628,    323,   1221,    990,
            429,    311,  11047,    279,    882,   2567,    369,    220,     16,
             17,     15,   6816,    382,     16,     13,   3070,  47866,  27138,
            594,   5290,   4628,     25,   1019,    256,    481,  27138,  15804,
            220,     23,   6816,    304,    220,     17,     15,   4420,    624,
            256,    481,   2014,   1477,   1059,   5290,   4628,    304,   6816,
            817,   9383,     11,    582,  21749,    279,   1372,    315,   6816,
           1340,  15804,    553,    279,   1372,    315,   4420,    510,    257,
           1124,   9640,    257,   1124,   1318,     90,  31899,   4628,     92,
            284,   1124,  37018,     90,     23,   1124,   1318,     90,   6816,
           3417,     90,     17,     15,   1124,   1318,     90,   4420,   3417,
            284,    220,     15,     13,     19,   1124,   1318,     90,   6816,
            817,   9383,    532,    257,   1124,   2533,     17,     13,   3070,
             35,  24308,    279,   2790,    882,   4362,    311,   1349,    220,
             16,     17,     15,   6816,     25,   1019,    256,    481,   4695,
            429,    582,   1414,  27138,    594,   5290,   4628,    374,    220,
             15,     13,     19,   6816,    817,   9383,     11,    582,    646,
          11047,    279,    882,   2567,    311,   1349,    220,     16,     17,
             15,   6816,    553,  49702,    279,   1372,    315,   6816,    553,
           1059,   5290,   4628,    510,    257,   1124,   9640,    257,   1124,
           1318,     90,   1462,     92,    284,   1124,  37018,     90,     16,
             17,     15,   1124,   1318,     90,   6816,   3417,     90,     15,
             13,     19,   1124,   1318,     90,   6816,    817,   9383,   3417,
            284,    220,     18,     15,     15,   1124,   1318,     90,   4420,
            532,    257,   1124,    921,    256,    481,   7169,    279,    882,
            504,   4420,    311,   4115,    553,  49702,    553,    220,     21,
             15,    320,  11284,   1052,    525,    220,     21,     15,   4420,
            304,    458,   6460,    982,    257,   1124,   9640,    257,   1124,
           1318,     90,   1462,    304,   4115,     92,    284,   1124,  37018,
             90,     18,     15,     15,   1124,   1318,     90,   4420,   3417,
             90,     21,     15,   1124,   1318,     90,   4420,    817,   6460,
           3417,    284,    220,     20,   1124,   1318,     90,   4115,    532,
            257,   1124,   2533,  54815,     11,    432,    686,   1896,  27138,
           1124,  79075,     90,     20,     92,   4115,    311,   1349,    220,
             16,     17,     15,   6816,     13, 151645], device='cuda:0')]
```

å°†å›å¤ç»“æœè½¬åŒ–ä¸ºæ–‡æœ¬ï¼š

```python
response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
```

```python
print(response)
```

```plaintext
To determine how long it takes Joy to read 120 pages, we need to first find out her reading speed and then use that to calculate the time required for 120 pages.

1. **Calculate Joy's reading speed:**
   - Joy reads 8 pages in 20 minutes.
   - To find her reading speed in pages per minute, we divide the number of pages she reads by the number of minutes:
     \[
     \text{Reading speed} = \frac{8 \text{ pages}}{20 \text{ minutes}} = 0.4 \text{ pages per minute}
     \]

2. **Determine the total time needed to read 120 pages:**
   - Now that we know Joy's reading speed is 0.4 pages per minute, we can calculate the time required to read 120 pages by dividing the number of pages by her reading speed:
     \[
     \text{Time} = \frac{120 \text{ pages}}{0.4 \text{ pages per minute}} = 300 \text{ minutes}
     \]
   - Convert the time from minutes to hours by dividing by 60 (since there are 60 minutes in an hour):
     \[
     \text{Time in hours} = \frac{300 \text{ minutes}}{60 \text{ minutes per hour}} = 5 \text{ hours}
     \]

Therefore, it will take Joy \boxed{5} hours to read 120 pages.
```

åœ¨åˆå§‹çŠ¶æ€ä¸‹ï¼Œæ¨¡å‹å¹¶ä¸ä¼šä¸»åŠ¨è¿›è¡Œæ€è€ƒã€‚

* æ•°æ®é›†å‡†å¤‡

â€ƒâ€ƒæœ¬èŠ‚å…¬å¼€è¯¾ç”¨äºGRPOè®­ç»ƒçš„æ•°æ®é›†é€‰è‡ªOpenAI/GSM8Kæ•°æ®é›†ï¼šhttps://huggingface.co/datasets/openai/gsm8k

â€ƒâ€ƒ**OpenAI GSM8K æ•°æ®é›†** æ˜¯ä¸€ä¸ªå¹¿æ³›ç”¨äºè¯„ä¼°æ¨ç†å’Œæ•°å­¦èƒ½åŠ›çš„å¤šæ ·åŒ–æ•°å­¦é¢˜ç›®æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«å¤§çº¦ **8,000** ä¸ªæ•°å­¦é—®é¢˜ï¼Œæ¶µç›–äº†ä»å°å­¦åˆ°é«˜ä¸­çš„å„ç§æ•°å­¦é¢†åŸŸï¼ŒåŒ…æ‹¬ç®—æœ¯ã€ä»£æ•°ã€å‡ ä½•ç­‰ã€‚GSM8K æ—¨åœ¨æŒ‘æˆ˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ²¡æœ‰æ˜¾å¼æç¤ºçš„æƒ…å†µä¸‹ï¼Œè§£å†³æ›´å¤æ‚çš„æ•°å­¦æ¨ç†é—®é¢˜ã€‚æ•°æ®é›†ä¸­çš„é—®é¢˜é€šå¸¸éœ€è¦æ¨¡å‹è¿›è¡Œå¤šæ­¥æ¨ç†ï¼Œè¿œè¶…åŸºæœ¬çš„ç®—æœ¯è®¡ç®—ï¼Œå› æ­¤å®ƒè¢«å¹¿æ³›ç”¨äºæµ‹è¯•æ¨¡å‹åœ¨ç†è§£å’Œå¤„ç†æ•°å­—æ¨ç†çš„èƒ½åŠ›ã€‚

â€ƒâ€ƒGSM8K æ•°æ®é›†çš„è®¾è®¡åŸºäºè‡ªç„¶è¯­è¨€å½¢å¼ï¼Œå‘ˆç°ä¸ºé—®é¢˜-è§£ç­”å¯¹çš„å½¢å¼ï¼Œä¸”åŒ…å«äº†é—®é¢˜çš„è¯¦ç»†è§£ææ­¥éª¤ã€‚è¯¥æ•°æ®é›†è¢«å¹¿æ³›åº”ç”¨äºæ¨¡å‹çš„ **é›¶æ ·æœ¬æ¨ç†** å’Œ **å°‘æ ·æœ¬å­¦ä¹ ** ä»»åŠ¡ï¼Œæ˜¯å½“å‰ç ”ç©¶ä¸­ç”¨äºéªŒè¯è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„é‡è¦åŸºå‡†ä¹‹ä¸€ã€‚

![](images/7b342e5c-c04c-4b6f-8d57-b72340cb15be.png)

åŒæ ·ï¼Œæ•°æ®é›†å¯ä»¥å€ŸåŠ©datasetå·¥å…·è¿›è¡Œä¸‹è½½ï¼š

```bash
pip install dataset
```

è‹¥æ˜¯AutoDLç§Ÿèµçš„æœåŠ¡å™¨ï¼Œåˆ™éœ€è¦å¼€å¯å­¦æœ¯åŠ é€Ÿæ¨¡å‹ï¼Œè¿æ¥huggingfaceè¿›è¡Œä¸‹è½½ï¼š

```python
import subprocess
import os

result = subprocess.run('bash -c "source /etc/network_turbo && env | grep proxy"', shell=True, capture_output=True, text=True)
output = result.stdout
for line in output.splitlines():
    if '=' in line:
        var, value = line.split('=', 1)
        os.environ[var] = value
```

ç„¶åæŒ‰ç…§å¦‚ä¸‹æ–¹å¼è¿›è¡Œä¸‹è½½ï¼š

```python
data = load_dataset('openai/gsm8k', 'main')
```

```python
data
```

```plaintext
DatasetDict({
    train: Dataset({
        features: ['question', 'answer'],
        num_rows: 7473
    })
    test: Dataset({
        features: ['question', 'answer'],
        num_rows: 1319
    })
})
```

```python
data['train'][0]
```

```plaintext
{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',
 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n#### 72'}
```

æ­¤å¤–ï¼Œä¹Ÿå¯ä»¥åœ¨ç½‘ç›˜ä¸­ç›´æ¥ä¸‹è½½ï¼š

![](images/8ef7395c-cbe3-428e-bb97-8f2b4427f9b1.png)

**æ‰«ç æ·»åŠ åŠ©æ•™ï¼Œå³å¯é¢†å–å…¨éƒ¨èµ„æ–™ğŸ‘‡**

![](images/image-3.png)

* wandbç¯å¢ƒé…ç½®ã€å¯é€‰ã€‘

â€ƒâ€ƒåœ¨å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬å¾€å¾€éœ€è¦ç›‘æ§å’Œåˆ†æå¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè€ŒWandBå¯ä»¥å¸®åŠ©æˆ‘ä»¬å®ç°è¿™ä¸€ç›®æ ‡ã€‚å®ƒæä¾›äº†ä»¥ä¸‹å‡ ä¸ªé‡è¦çš„åŠŸèƒ½ï¼š

**å®æ—¶å¯è§†åŒ–**ï¼šWandBå¯ä»¥å®æ—¶å±•ç¤ºè®­ç»ƒè¿‡ç¨‹ä¸­å…³é”®æŒ‡æ ‡çš„å˜åŒ–ï¼Œå¦‚æŸå¤±å‡½æ•°ã€å­¦ä¹ ç‡ã€è®­ç»ƒæ—¶é—´ç­‰ã€‚é€šè¿‡è¿™äº›å¯è§†åŒ–æ•°æ®ï¼Œæˆ‘ä»¬èƒ½å¤Ÿç›´è§‚åœ°äº†è§£æ¨¡å‹çš„è®­ç»ƒè¿›å±•ï¼Œå¿«é€Ÿå‘ç°è®­ç»ƒä¸­çš„å¼‚å¸¸æˆ–ç“¶é¢ˆã€‚

**è‡ªåŠ¨è®°å½•ä¸æ—¥å¿—ç®¡ç†**ï¼šWandBä¼šè‡ªåŠ¨è®°å½•æ¯æ¬¡å®éªŒçš„å‚æ•°ã€ä»£ç ã€è¾“å‡ºç»“æœï¼Œç¡®ä¿å®éªŒç»“æœçš„å¯è¿½æº¯æ€§ã€‚æ— è®ºæ˜¯è¶…å‚æ•°çš„è®¾ç½®ï¼Œè¿˜æ˜¯æ¨¡å‹çš„æ¶æ„è°ƒæ•´ï¼ŒWandBéƒ½èƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬å®Œæ•´ä¿ç•™å®éªŒè®°å½•ï¼Œæ–¹ä¾¿åæœŸå¯¹æ¯”ä¸è°ƒä¼˜ã€‚

**æ”¯æŒä¸­æ–­ä¸æ¢å¤è®­ç»ƒ**ï¼šåœ¨é•¿æ—¶é—´çš„é¢„è®­ç»ƒä»»åŠ¡ä¸­ï¼Œç³»ç»Ÿä¸­æ–­æˆ–éœ€è¦æš‚åœæ˜¯å¸¸è§çš„æƒ…å†µã€‚é€šè¿‡WandBçš„checkpointåŠŸèƒ½ï¼Œæˆ‘ä»¬å¯ä»¥éšæ—¶æ¢å¤è®­ç»ƒï¼Œä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­è¿›è¡Œï¼Œé¿å…æ•°æ®å’Œæ—¶é—´çš„æµªè´¹ã€‚

**å¤šå®éªŒå¯¹æ¯”**ï¼šå½“æˆ‘ä»¬å°è¯•ä¸åŒçš„æ¨¡å‹é…ç½®æˆ–è¶…å‚æ•°æ—¶ï¼ŒWandBå…è®¸æˆ‘ä»¬åœ¨å¤šä¸ªå®éªŒä¹‹é—´è½»æ¾è¿›è¡Œå¯¹æ¯”åˆ†æï¼Œå¸®åŠ©æˆ‘ä»¬é€‰æ‹©æœ€ä¼˜çš„æ¨¡å‹é…ç½®ã€‚

**å›¢é˜Ÿåä½œ**ï¼šWandBè¿˜æ”¯æŒå›¢é˜Ÿåä½œï¼Œå¤šä¸ªæˆå‘˜å¯ä»¥å…±åŒæŸ¥çœ‹å®éªŒç»“æœï¼ŒååŒè°ƒè¯•æ¨¡å‹ã€‚è¿™å¯¹ç ”ç©¶å’Œé¡¹ç›®å¼€å‘ä¸­å›¢é˜Ÿçš„åˆä½œéå¸¸æœ‰å¸®åŠ©ã€‚

1. æ³¨å†Œwandbï¼šhttps://wandb.ai/site

![](images/d22a05e7-507d-4cb1-8767-07eb6d8b391f.png)

&#x20;

![](images/98a00367-9f49-402b-aa80-09b019db8195.png)

&#x20;

![](images/db97ad21-048c-4129-a8d2-c663748083da.png)

&#x20;

![](images/5158733a-778d-44ae-a4a4-c0766b000734.png)

&#x20;

![](images/96324e11-2d1c-4d61-be52-90552c8f8270.png)

2. å®‰è£…wandbï¼š

â€ƒâ€ƒåœ¨å‘½ä»¤è¡Œä¸­è¾“å…¥å¦‚ä¸‹ä»£ç å®‰è£…wandbï¼š

```bash
pip install wandb
```

![](images/935bed85-a37a-41f0-9cb1-2548459b1f7e.png)

ç„¶åå³å¯ç™»å½•wandbï¼Œåœ¨å‘½ä»¤è¡Œé¡µé¢è¾“å…¥ï¼š

```bash
wandb login
```

å¹¶æ ¹æ®æç¤ºè¾“å…¥API-KEYï¼š

![](images/466b721d-9efd-4c54-b069-260bfe0f70f6.png)

å³å¯åœ¨å½“å‰ç”µè„‘ä¸Šä¿å­˜wandbè´¦å·ä¿¡æ¯ï¼Œä¹‹åå³å¯ç›´æ¥åœ¨wandb homeä¸»é¡µä¸Šçœ‹åˆ°è®­ç»ƒè¿‡ç¨‹ã€‚è‹¥åœ¨ä»£ç ç¯å¢ƒä¸­ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹ä»£ç è¿›è¡Œè®¾ç½®ï¼š

```python
import wandb
```

```python
wandb.login(key="YOUR_WANDB_API_KEY")
```

```plaintext
Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.
[34m[1mwandb[0m: [33mWARNING[0m If you're specifying your api key in code, ensure this code is not shared publicly.
[34m[1mwandb[0m: [33mWARNING[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.
[34m[1mwandb[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc
[34m[1mwandb[0m: Currently logged in as: [33m2323365771[0m ([33m2323365771-ff[0m) to [32mhttps://api.wandb.ai[0m. Use [1m`wandb login --relogin`[0m to force relogin





True
```

```python
wandb.init(project="GRPO-test")
```

```plaintext
[34m[1mwandb[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
```

Tracking run with wandb version 0.19.6

Run data is saved locally in `/root/autodl-tmp/å¼ºåŒ–å­¦ä¹ å¤ç°/wandb/run-20250212_112711-zevsqm7e`

Syncing run [**glad-resonance-3**](https://wandb.ai/2323365771-ff/GRPO-test/runs/zevsqm7e) to [Weights & Biases](https://wandb.ai/2323365771-ff/GRPO-test) ([docs](https://wandb.me/developer-guide))

View project at <https://wandb.ai/2323365771-ff/GRPO-test>

View run at <https://wandb.ai/2323365771-ff/GRPO-test/runs/zevsqm7e>

Display W\&B run

### ä¸‰ã€GRPOå¼ºåŒ–å­¦ä¹ è®­ç»ƒæµç¨‹

â€ƒâ€ƒåœ¨å®Œæˆäº†ä¸€ç³»åˆ—çš„å‡†å¤‡å·¥ä½œåï¼Œå°±å°†æ­£å¼å¼€å§‹GRPOå¼ºåŒ–å­¦ä¹ è®­ç»ƒæµç¨‹ã€‚

#### 1.åŸºç¡€å‡†å¤‡å·¥ä½œ

* å¯¼å…¥ç›¸å…³çš„åº“

```python
import re
import torch
from datasets import load_dataset, Dataset
from transformers import AutoTokenizer, AutoModelForCausalLM
from trl import GRPOConfig, GRPOTrainer
```

```python
SYSTEM_PROMPT = """
Respond in the following format:
<reasoning>
...
</reasoning>
<answer>
...
</answer>
"""

XML_COT_FORMAT = """\
<reasoning>
{reasoning}
</reasoning>
<answer>
{answer}
</answer>
"""
```

* å®šä¹‰æç¤ºè¯æ¨¡æ¿ä¸æ¨¡å‹æ–‡æœ¬è¾“å‡ºæ ¼å¼æ¨¡æ¿

```python
SYSTEM_PROMPT = """
Respond in the following format:
<reasoning>
...
</reasoning>
<answer>
...
</answer>
"""

XML_COT_FORMAT = """\
<reasoning>
{reasoning}
</reasoning>
<answer>
{answer}
</answer>
"""
```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸¤ä¸ªå­—ç¬¦ä¸²å¸¸é‡ï¼Œå®ƒä»¬è¡¨ç¤ºäº†ä¸åŒçš„æ–‡æœ¬æ ¼å¼ï¼š

1. `SYSTEM_PROMPT = """..."""`

* **ä½œç”¨**ï¼šè¿™æ˜¯ä¸€ä¸ªå¤šè¡Œå­—ç¬¦ä¸²ï¼Œå®šä¹‰äº†ä¸€ä¸ªç³»ç»Ÿæç¤ºï¼ˆpromptï¼‰çš„æ ¼å¼ã€‚

* **å†…å®¹**ï¼š

  * `"<reasoning>"` å’Œ `"</reasoning>"`ï¼šè¿™éƒ¨åˆ†è¡¨ç¤ºæ¨ç†è¿‡ç¨‹çš„åœ°æ–¹ã€‚æ¨ç†è¿‡ç¨‹å¯èƒ½åŒ…æ‹¬æ¨¡å‹åˆ†æé—®é¢˜ã€æå‡ºå‡è®¾ã€æ¨ç†ç­‰é€»è¾‘æ¨å¯¼æ­¥éª¤ã€‚

  * `"<answer>"` å’Œ `"</answer>"`ï¼šè¿™éƒ¨åˆ†è¡¨ç¤ºæœ€ç»ˆçš„å›ç­”æˆ–ç»“è®ºçš„åœ°æ–¹ã€‚æ ¹æ®æ¨ç†ç»“æœï¼Œæ¨¡å‹å°†ç»™å‡ºç­”æ¡ˆã€‚

**ç›®çš„**ï¼š

* è¿™ä¸ªå­—ç¬¦ä¸²çš„ä½œç”¨é€šå¸¸æ˜¯åœ¨ç”Ÿæˆå‹æ¨¡å‹ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹å¦‚ä½•ç»„ç»‡å®ƒçš„å›å¤ã€‚æ¨¡å‹éœ€è¦é¦–å…ˆç»™å‡ºæ¨ç†è¿‡ç¨‹ï¼Œå†ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚è¿™ç§æ ¼å¼å¸®åŠ©å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶ä¸åªæ˜¯ç»™å‡ºç­”æ¡ˆï¼Œè¿˜å±•ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚

* ä¾‹å¦‚ï¼Œå¦‚æœä½ é—®ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ï¼Œæ¨¡å‹ä¼šå…ˆè§£é‡Šå®ƒæ˜¯å¦‚ä½•æ€è€ƒé—®é¢˜çš„ï¼Œç„¶åå†ç»™å‡ºå®ƒçš„ç­”æ¡ˆã€‚

2. `XML_COT_FORMAT = """..."""`

* **ä½œç”¨**ï¼šè¿™ä¸ªå­—ç¬¦ä¸²å®šä¹‰äº†ä¸€ä¸ª XML é£æ ¼çš„æ ¼å¼ï¼Œå¹¶å…è®¸åŠ¨æ€æ’å…¥ `reasoning` å’Œ `answer` çš„å†…å®¹ã€‚

* **å†…å®¹**ï¼š

  * `"<reasoning>{reasoning}</reasoning>"`ï¼šè¿™é‡Œ `{reasoning}` æ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œè¡¨ç¤ºå®é™…çš„æ¨ç†è¿‡ç¨‹ä¼šè¢«æ’å…¥åˆ°è¯¥ä½ç½®ã€‚

  * `"<answer>{answer}</answer>"`ï¼šç±»ä¼¼åœ°ï¼Œ`{answer}` æ˜¯å ä½ç¬¦ï¼Œç”¨äºæ’å…¥æœ€ç»ˆç­”æ¡ˆã€‚

**ç›®çš„**ï¼š

* è¿™ä¸ªæ ¼å¼æä¾›äº†ä¸€ä¸ªæ›´ç»“æ„åŒ–çš„è¾“å‡ºå½¢å¼ï¼Œé€šå¸¸åœ¨æŸäº›åº”ç”¨ä¸­ï¼Œæ¨¡å‹çš„è¾“å‡ºéœ€è¦ç¬¦åˆæŸç§ç‰¹å®šçš„æ ¼å¼ï¼ˆæ¯”å¦‚ XML æ ¼å¼ï¼‰ã€‚

* `XML_COT_FORMAT` å…è®¸é€šè¿‡ä¼ å…¥æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆçš„å…·ä½“å†…å®¹ï¼Œç”Ÿæˆç¬¦åˆè¿™ç§æ ¼å¼çš„æ–‡æœ¬ã€‚æ¯”å¦‚ï¼Œå¦‚æœæ¨ç†æ˜¯ "é¦–å…ˆåˆ†ææ•°æ®ï¼Œæ¥ç€å¾—å‡ºç»“è®º"ï¼Œè€Œç­”æ¡ˆæ˜¯ "æœ€åå¾—å‡ºç»“è®º A"ï¼Œåˆ™è¾“å‡ºå°†ä¼šç±»ä¼¼äºï¼š

```xml
<reasoning>
é¦–å…ˆåˆ†ææ•°æ®ï¼Œæ¥ç€å¾—å‡ºç»“è®ºã€‚
</reasoning>
<answer>
æœ€åå¾—å‡ºç»“è®º A
</answer>
```

#### 2.æ ¼å¼å¤„ç†å‡½æ•°ç»„

â€ƒâ€ƒç„¶åå³å¯å®šä¹‰æ ¼å¼å¤„ç†å‡½æ•°ç»„ï¼š

* **`extract_xml_answer`** ç”¨äºä» XML é£æ ¼çš„æ–‡æœ¬ä¸­æå– `<answer>` æ ‡ç­¾ä¹‹é—´çš„å†…å®¹ã€‚

* **`extract_hash_answer`** ç”¨äºä»æ–‡æœ¬ä¸­æå– `####` åçš„å†…å®¹ï¼Œè‹¥æ²¡æœ‰æ‰¾åˆ° `####`ï¼Œè¿”å› `None`ã€‚

* **`get_gsm8k_questions`** åŠ è½½ `GSM8K` æ•°æ®é›†ï¼Œå¹¶å°†é—®é¢˜ä¸ç³»ç»Ÿæç¤ºç»“åˆï¼Œæ ¼å¼åŒ–åè¿”å›ã€‚

* æœ€ç»ˆï¼Œé€šè¿‡è°ƒç”¨ `get_gsm8k_questions()`ï¼Œç¨‹åºåŠ è½½äº†æ ¼å¼åŒ–åçš„æ•°æ®é›†ï¼Œå¹¶å­˜å‚¨åœ¨ `dataset` å˜é‡ä¸­ï¼Œå‡†å¤‡åç»­å¤„ç†ã€‚

```python
def extract_xml_answer(text: str) -> str:
    answer = text.split("<answer>")[-1]
    answer = answer.split("</answer>")[0]
    return answer.strip()
```

`def extract_xml_answer(text: str) -> str:`

* **ä½œç”¨**ï¼šè¿™ä¸ªå‡½æ•°ç”¨äºä»æ–‡æœ¬ä¸­æå– `<answer>` æ ‡ç­¾ä¹‹é—´çš„å†…å®¹ã€‚

* **å®ç°**ï¼š

  * `text.split("<answer>")[-1]`ï¼šé¦–å…ˆé€šè¿‡ `split` å‡½æ•°ä»¥ `<answer>` ä¸ºåˆ†éš”ç¬¦ï¼ŒæŠŠ `text` åˆ†å‰²æˆä¸€ä¸ªåˆ—è¡¨ï¼Œ`[-1]` å–å‡ºåˆ—è¡¨çš„æœ€åä¸€ä¸ªéƒ¨åˆ†ï¼Œè¿™éƒ¨åˆ†åº”è¯¥åŒ…å«äº† `</answer>` æ ‡ç­¾ä¹‹åçš„å†…å®¹ã€‚

  * `answer.split("</answer>")[0]`ï¼šç„¶åå†é€šè¿‡ `split("</answer>")` åˆ†å‰²ï¼Œå–å‡ºç¬¬ä¸€ä¸ªéƒ¨åˆ†ï¼Œè¿™éƒ¨åˆ†å°±æ˜¯ `<answer>` æ ‡ç­¾å’Œ `</answer>` æ ‡ç­¾ä¹‹é—´çš„å†…å®¹ã€‚

  * `return answer.strip()`ï¼šæœ€åé€šè¿‡ `strip()` å»é™¤å‰åçš„ç©ºç™½å­—ç¬¦ï¼Œè¿”å›æå–å‡ºçš„ç­”æ¡ˆã€‚

* **ç”¨é€”**ï¼šè¿™ä¸ªå‡½æ•°å¸¸ç”¨äºä»åŒ…å« `<answer>` æ ‡ç­¾çš„æ–‡æœ¬ä¸­æå–å®é™…çš„ç­”æ¡ˆã€‚

```python
def extract_hash_answer(text: str) -> str | None:
    if "####" not in text:
        return None
    return text.split("####")[1].strip()
```

`def extract_hash_answer(text: str) -> str | None:`

* **ä½œç”¨**ï¼šè¿™ä¸ªå‡½æ•°ä»æ–‡æœ¬ä¸­æå–åŸºäº `####` åˆ†éš”ç¬¦çš„ç­”æ¡ˆã€‚å¦‚æœæ²¡æœ‰æ‰¾åˆ° `####`ï¼Œåˆ™è¿”å› `None`ã€‚

* **å®ç°**ï¼š

  * `if "####" not in text:`ï¼šé¦–å…ˆæ£€æŸ¥æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å« `####`ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå°±è¿”å› `None`ï¼Œè¡¨ç¤ºæ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆã€‚

  * `return text.split("####")[1].strip()`ï¼šå¦‚æœæ‰¾åˆ°äº† `####`ï¼Œé€šè¿‡ `split("####")` å°†æ–‡æœ¬åˆ†å‰²æˆä¸¤éƒ¨åˆ†ï¼Œå–å‡ºç¬¬äºŒéƒ¨åˆ†ï¼ˆå³ç´¢å¼•ä¸º 1 çš„éƒ¨åˆ†ï¼‰ã€‚ç„¶åé€šè¿‡ `strip()` å»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦ï¼Œè¿”å›æå–å‡ºçš„ç­”æ¡ˆã€‚

* **ç”¨é€”**ï¼šè¿™ä¸ªå‡½æ•°ç”¨äºä»åŒ…å« `####` çš„æ–‡æœ¬ä¸­æå–å®é™…çš„ç­”æ¡ˆã€‚å¦‚æœæ²¡æœ‰ `####`ï¼Œåˆ™è¿”å› `None`ã€‚

```python
# uncomment middle messages for 1-shot prompting
def get_gsm8k_questions(split = "train") -> Dataset:
    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore
    data = data.map(lambda x: { # type: ignore
        'prompt': [
            {'role': 'system', 'content': SYSTEM_PROMPT},
            {'role': 'user', 'content': x['question']}
        ],
        'answer': extract_hash_answer(x['answer'])
    }) # type: ignore
    return data # type: ignore
```

`def get_gsm8k_questions(split = "train") -> Dataset:`

* **ä½œç”¨**ï¼šè¿™ä¸ªå‡½æ•°ç”¨äºåŠ è½½ `GSM8K` æ•°æ®é›†å¹¶è¿”å›åŒ…å«é—®é¢˜å’Œç­”æ¡ˆçš„æ ¼å¼åŒ–æ•°æ®é›†ã€‚

* **å®ç°**ï¼š

  * `data = load_dataset('openai/gsm8k', 'main')[split]`ï¼šä½¿ç”¨ `datasets` åº“çš„ `load_dataset` å‡½æ•°åŠ è½½ `GSM8K` æ•°æ®é›†çš„ `main` ç‰ˆæœ¬ã€‚`split` å‚æ•°ï¼ˆé»˜è®¤å€¼ä¸º `"train"`ï¼‰å†³å®šåŠ è½½è®­ç»ƒé›†ã€éªŒè¯é›†æˆ–æµ‹è¯•é›†ã€‚

  * `data = data.map(lambda x: {...})`ï¼š`map` å‡½æ•°ç”¨äºå¯¹æ•°æ®é›†ä¸­çš„æ¯ä¸€æ¡è®°å½•è¿›è¡Œå¤„ç†ã€‚åœ¨è¿™é‡Œï¼Œæ¯ä¸ªæ¡ç›®çš„ `question` è¢«åŒ…è£…æˆä¸€ä¸ªå¯¹è¯ prompt æ ¼å¼ï¼Œå¹¶åŠ å…¥ç³»ç»Ÿæç¤º `SYSTEM_PROMPT`ã€‚åŒæ—¶ï¼Œ`answer` è¢«å¤„ç†ï¼Œé€šè¿‡ `extract_hash_answer` å‡½æ•°ä»åŸå§‹çš„ç­”æ¡ˆæ–‡æœ¬ä¸­æå–ç­”æ¡ˆã€‚

  * `return data`ï¼šè¿”å›å¤„ç†åçš„æ•°æ®é›†ã€‚

ç„¶åå³å¯å¯¼å…¥å¹¶å¤„ç†æ•°æ®é›†ï¼š

```python
data = load_dataset('openai/gsm8k', 'main')
```

è¿™æ®µä»£ç ä½¿ç”¨äº†`datasets`åº“ä¸­çš„`load_dataset`å‡½æ•°ï¼ŒåŠ è½½äº†OpenAIæä¾›çš„`gsm8k`æ•°æ®é›†çš„`main`ç‰ˆæœ¬ã€‚

å…·ä½“æ¥è¯´ï¼š

* `load_dataset('openai/gsm8k', 'main')`ä¼šä»`openai`çš„æœåŠ¡å™¨ä¸ŠåŠ è½½åä¸º`gsm8k`çš„æ•°æ®é›†ï¼Œå¹¶é€‰æ‹©`main`é…ç½®ï¼ˆæœ‰äº›æ•°æ®é›†å¯èƒ½æœ‰ä¸åŒçš„ç‰ˆæœ¬æˆ–å­é›†ï¼Œå¯ä»¥é€‰æ‹©ä¸åŒçš„é…ç½®ï¼‰ã€‚

* `gsm8k`æ˜¯ä¸€ä¸ªæ•°å­¦æ¨ç†æ•°æ®é›†ï¼ŒåŒ…å«äº†8,000å¤šä¸ªæ•°å­¦é—®é¢˜ï¼Œé€šå¸¸ç”¨äºè®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

`data`å˜é‡ä¼šæ¥æ”¶åˆ°è¯¥æ•°æ®é›†ã€‚å®ƒé€šå¸¸æ˜¯ä¸€ä¸ª`datasets.Dataset`å¯¹è±¡ï¼Œä½ å¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œæ•°æ®çš„å¤„ç†ã€è®­ç»ƒã€æµ‹è¯•ç­‰æ“ä½œã€‚

å¦‚æœä½ æƒ³è¿›ä¸€æ­¥äº†è§£å¦‚ä½•ä½¿ç”¨è¿™ä¸ªæ•°æ®é›†ï¼Œå¯ä»¥è°ƒç”¨ç±»ä¼¼ `data['train']` æ¥æŸ¥çœ‹è®­ç»ƒé›†çš„æ•°æ®ã€‚

å¤„ç†åçš„æ•°æ®é›†å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
data
```

```plaintext
DatasetDict({
    train: Dataset({
        features: ['question', 'answer'],
        num_rows: 7473
    })
    test: Dataset({
        features: ['question', 'answer'],
        num_rows: 1319
    })
})
```

```python
q1 = data['train'][0]
q1
```

```plaintext
{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',
 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n#### 72'}
```

#### 3.å¥–åŠ±å‡½æ•°ç»„

â€ƒâ€ƒæ¥ä¸‹æ¥ç»§ç»­å®šä¹‰å¥–åŠ±å‡½æ•°æ¨¡å‹ç»„ï¼š

* correctness\_reward\_funcï¼šæ ¹æ®æ­£ç¡®æ€§å¯¹ç­”æ¡ˆè¿›è¡Œå¥–åŠ±ã€‚

* int\_reward\_funcï¼šæ ¹æ®æ˜¯å¦ä¸ºæ•°å­—å¯¹è¾“å‡ºè¿›è¡Œå¥–åŠ±ã€‚

* strict\_format\_reward\_funcï¼šæ ¹æ®ä¸¥æ ¼çš„æ ¼å¼è¦æ±‚æ£€æŸ¥å¹¶å¥–åŠ±ã€‚

* soft\_format\_reward\_funcï¼šæ ¹æ®ç¨å¾®å®½æ¾çš„æ ¼å¼è¦æ±‚æ£€æŸ¥å¹¶å¥–åŠ±ã€‚

* count\_xmlï¼šè®¡ç®—æ–‡æœ¬ä¸­çš„ XML æ ‡ç­¾ç»“æ„å¹¶ç»™äºˆå¥–åŠ±ã€‚

* xmlcount\_reward\_funcï¼šä¸ºæ¯ä¸ªè¾“å‡ºè®¡ç®— XML æ ‡ç­¾ç»“æ„çš„ç¬¦åˆåº¦å¹¶è¿”å›å¥–åŠ±ã€‚

```python
# Reward functions
def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:
    responses = [completion[0]['content'] for completion in completions]
    q = prompts[0][-1]['content']
    extracted_responses = [extract_xml_answer(r) for r in responses]
    print('-'*20, f"Question:\n{q}", f"\nAnswer:\n{answer[0]}", f"\nResponse:\n{responses[0]}", f"\nExtracted:\n{extracted_responses[0]}")
    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]
```

correctness\_reward\_func(prompts, completions, answer, \*\*kwargs) -> list\[float]

* ä½œç”¨ï¼šè¯¥å‡½æ•°æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ˜¯å¦ä¸æ­£ç¡®ç­”æ¡ˆåŒ¹é…ï¼Œå¹¶æ ¹æ®åŒ¹é…æƒ…å†µè¿”å›å¥–åŠ±åˆ†æ•°ã€‚

* å®ç°ï¼š

* responses = \[completion\[0]\['content'] for completion in completions]ï¼šæå–æ¯ä¸ª completion ä¸­çš„å†…å®¹ï¼ˆå³æ¨¡å‹çš„è¾“å‡ºï¼‰ã€‚ã€

* q = prompts\[0]\[-1]\['content']ï¼šæå–è¾“å…¥é—®é¢˜ï¼ˆpromptï¼‰çš„å†…å®¹ã€‚

* extracted\_responses = \[extract\_xml\_answer(r) for r in responses]ï¼šä½¿ç”¨ä¹‹å‰å®šä¹‰çš„ extract\_xml\_answer å‡½æ•°æå–æ¨¡å‹è¾“å‡ºä¸­çš„ç­”æ¡ˆéƒ¨åˆ†ã€‚

* print(...)ï¼šæ‰“å°é—®é¢˜ã€æ­£ç¡®ç­”æ¡ˆã€æ¨¡å‹è¾“å‡ºå’Œæå–çš„ç­”æ¡ˆï¼Œå¸®åŠ©è°ƒè¯•ã€‚

* return \[2.0 if r == a else 0.0 for r, a in zip(extracted\_responses, answer)]ï¼šæ¯”è¾ƒæ¯ä¸ªæå–çš„å›ç­”ï¼ˆrï¼‰ä¸æ­£ç¡®ç­”æ¡ˆï¼ˆaï¼‰ã€‚å¦‚æœä¸¤è€…ç›¸åŒï¼Œè¿”å›å¥–åŠ± 2.0ï¼›å¦åˆ™è¿”å› 0.0ã€‚å¥–åŠ±æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œé•¿åº¦ä¸æ¨¡å‹çš„è¾“å‡ºæ•°ç›®ç›¸åŒã€‚

* ç”¨é€”ï¼šè¯¥å¥–åŠ±å‡½æ•°ç”¨äºè¡¡é‡æ¨¡å‹å›ç­”çš„æ­£ç¡®æ€§ï¼Œé€šå¸¸ç”¨äºç›‘ç£å­¦ä¹ æˆ–å¼ºåŒ–å­¦ä¹ ä¸­çš„æ ‡å‡†åŒ–è¯„ä¼°ã€‚

```python
def int_reward_func(completions, **kwargs) -> list[float]:
    responses = [completion[0]['content'] for completion in completions]
    extracted_responses = [extract_xml_answer(r) for r in responses]
    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]
```

int\_reward\_func(completions, \*\*kwargs) -> list\[float]

* ä½œç”¨ï¼šæ£€æŸ¥æ¨¡å‹è¾“å‡ºæ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ•´æ•°ï¼Œå¹¶æ ¹æ®ç»“æœç»™äºˆå¥–åŠ±ã€‚

* å®ç°ï¼š

* responses = \[completion\[0]\['content'] for completion in completions]ï¼šæå–æ¨¡å‹çš„å›ç­”å†…å®¹ã€‚

* extracted\_responses = \[extract\_xml\_answer(r) for r in responses]ï¼šæå–å›ç­”ä¸­çš„å†…å®¹ã€‚

* return \[0.5 if r.isdigit() else 0.0 for r in extracted\_responses]ï¼šæ£€æŸ¥æ¯ä¸ªæå–çš„å›ç­”æ˜¯å¦ä¸ºæ•°å­—å­—ç¬¦ä¸²ã€‚å¦‚æœæ˜¯æ•°å­—ï¼Œè¿”å›å¥–åŠ± 0.5ï¼›å¦åˆ™è¿”å› 0.0ã€‚

* ç”¨é€”ï¼šè¯¥å‡½æ•°ç”¨äºå¥–åŠ±æ¨¡å‹ç”Ÿæˆæ•´æ•°å½¢å¼çš„ç­”æ¡ˆï¼Œå¯èƒ½ç”¨äºé—®é¢˜è¦æ±‚æ¨¡å‹ç»™å‡ºæ•°å­—æ—¶çš„æƒ…å½¢ã€‚

```python
def strict_format_reward_func(completions, **kwargs) -> list[float]:
    """Reward function that checks if the completion has a specific format."""
    pattern = r"^<reasoning>\n.*?\n</reasoning>\n<answer>\n.*?\n</answer>\n$"
    responses = [completion[0]["content"] for completion in completions]
    matches = [re.match(pattern, r) for r in responses]
    return [0.5 if match else 0.0 for match in matches]
```

strict\_format\_reward\_func(completions, \*\*kwargs) -> list\[float]

* ä½œç”¨ï¼šæ£€æŸ¥æ¨¡å‹çš„è¾“å‡ºæ˜¯å¦ç¬¦åˆä¸¥æ ¼çš„æ ¼å¼è¦æ±‚ï¼ŒåŒ…æ‹¬ å’Œ æ ‡ç­¾ã€‚

* å®ç°ï¼š

* pattern = r"^\n.*?\n\n\n.*?\n\n$"ï¼šå®šä¹‰äº†ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼Œç¡®ä¿è¾“å‡ºçš„æ ¼å¼ä¸¥æ ¼ç¬¦åˆè¦æ±‚ã€‚

* responses = \[completion\[0]\["content"] for completion in completions]ï¼šæå–æ¨¡å‹çš„å›ç­”ã€‚

* matches = \[re.match(pattern, r) for r in responses]ï¼šé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æ£€æŸ¥æ¯ä¸ªå›ç­”æ˜¯å¦ç¬¦åˆæ ¼å¼ã€‚

* return \[0.5 if match else 0.0 for match in matches]ï¼šå¦‚æœåŒ¹é…æ ¼å¼ï¼Œè¿”å›å¥–åŠ± 0.5ï¼›å¦åˆ™è¿”å› 0.0ã€‚

* ç”¨é€”ï¼šç”¨äºæ£€æŸ¥è¾“å‡ºæ˜¯å¦ç¬¦åˆä¸¥æ ¼çš„æ ¼å¼è¦æ±‚ï¼Œé€šå¸¸ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºçš„ç»“æ„æ€§å’Œä¸€è‡´æ€§ã€‚

```python
def soft_format_reward_func(completions, **kwargs) -> list[float]:
    """Reward function that checks if the completion has a specific format."""
    pattern = r"<reasoning>.*?</reasoning>\s*<answer>.*?</answer>"
    responses = [completion[0]["content"] for completion in completions]
    matches = [re.match(pattern, r) for r in responses]
    return [0.5 if match else 0.0 for match in matches]
```

soft\_format\_reward\_func(completions, \*\*kwargs) -> list\[float]

* ä½œç”¨ï¼šæ£€æŸ¥æ¨¡å‹çš„è¾“å‡ºæ˜¯å¦ç¬¦åˆç¨å¾®å®½æ¾çš„æ ¼å¼è¦æ±‚ï¼Œ å’Œ æ ‡ç­¾ä¹‹é—´å¯ä»¥æœ‰ç©ºç™½å­—ç¬¦ã€‚

* å®ç°ï¼š

* pattern = r".*?\s*.\*?"ï¼šå®šä¹‰äº†ä¸€ä¸ªç¨å¾®å®½æ¾çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œå…è®¸ å’Œ æ ‡ç­¾ä¹‹é—´æœ‰ç©ºæ ¼æˆ–æ¢è¡Œã€‚

* responses = \[completion\[0]\["content"] for completion in completions]ï¼šæå–æ¨¡å‹çš„å›ç­”ã€‚

* matches = \[re.match(pattern, r) for r in responses]ï¼šæ£€æŸ¥æ¯ä¸ªå›ç­”æ˜¯å¦ç¬¦åˆæ­¤æ ¼å¼ã€‚

* return \[0.5 if match else 0.0 for match in matches]ï¼šå¦‚æœæ ¼å¼åŒ¹é…ï¼Œè¿”å›å¥–åŠ± 0.5ï¼›å¦åˆ™è¿”å› 0.0ã€‚

* ç”¨é€”ï¼šç”¨äºç¨å¾®æ”¾å®½çš„æ ¼å¼è¦æ±‚ï¼Œé€‚ç”¨äºæŸäº›å¯¹æ ¼å¼è¦æ±‚ä¸é‚£ä¹ˆä¸¥æ ¼çš„åœºæ™¯ã€‚

```python
def count_xml(text) -> float:
    count = 0.0
    if text.count("<reasoning>\n") == 1:
        count += 0.125
    if text.count("\n</reasoning>\n") == 1:
        count += 0.125
    if text.count("\n<answer>\n") == 1:
        count += 0.125
        count -= len(text.split("\n</answer>\n")[-1])*0.001
    if text.count("\n</answer>") == 1:
        count += 0.125
        count -= (len(text.split("\n</answer>")[-1]) - 1)*0.001
    return count
```

count\_xml(text) -> float

* ä½œç”¨ï¼šè®¡ç®—æ–‡æœ¬ä¸­ å’Œ æ ‡ç­¾çš„å‡ºç°æ¬¡æ•°ï¼Œå¹¶æ ¹æ®å®ƒä»¬çš„ä½ç½®å’Œé¢‘ç‡åˆ†é…å¥–åŠ±ã€‚

* å®ç°ï¼š

* count = 0.0ï¼šåˆå§‹åŒ–è®¡æ•°å™¨ã€‚

* if text.count("\n") == 1:ï¼šæ£€æŸ¥æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«ä¸€ä¸ª æ ‡ç­¾ï¼Œå¹¶ä¸”åªå‡ºç°ä¸€æ¬¡ã€‚

* count += 0.125ï¼šå¦‚æœæ¡ä»¶æ»¡è¶³ï¼Œå¥–åŠ± 0.125ã€‚

* if text.count("\n\n") == 1:ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ä¸€ä¸ªç»“æŸçš„ æ ‡ç­¾ã€‚

* count += 0.125ï¼šè‹¥æ¡ä»¶æ»¡è¶³ï¼Œå†å¥–åŠ± 0.125ã€‚

* if text.count("\n\n") == 1:ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ä¸€ä¸ª æ ‡ç­¾ã€‚

* count += 0.125ï¼šè‹¥æ»¡è¶³æ¡ä»¶ï¼Œå¥–åŠ± 0.125ã€‚

* count -= len(text.split("\n\n")\[-1])\*0.001ï¼šå¦‚æœå­˜åœ¨å¤šä½™çš„æ–‡æœ¬åœ¨ æ ‡ç­¾ä¹‹åï¼Œæ‰£é™¤ä¸€äº›å¥–åŠ±ã€‚

* return countï¼šè¿”å›æœ€ç»ˆçš„å¥–åŠ±å€¼ã€‚

* ç”¨é€”ï¼šç”¨äºè®¡ç®—æ¨¡å‹è¾“å‡ºçš„ XML æ ¼å¼æ˜¯å¦ç¬¦åˆé¢„æœŸï¼Œå¹¶ç»™å‡ºä¸€ä¸ªåŸºäºç»“æ„çš„å¥–åŠ±åˆ†æ•°ã€‚

```python
def xmlcount_reward_func(completions, **kwargs) -> list[float]:
    contents = [completion[0]["content"] for completion in completions]
    return [count_xml(c) for c in contents]
```

xmlcount\_reward\_func(completions, \*\*kwargs) -> list\[float]

* ä½œç”¨ï¼šè¯¥å‡½æ•°ç”¨äºè®¡ç®—æ¯ä¸ªæ¨¡å‹è¾“å‡ºçš„ XML ç»“æ„ç¬¦åˆåº¦ï¼Œå¹¶è¿”å›å¥–åŠ±åˆ†æ•°ã€‚

* å®ç°ï¼š

* contents = \[completion\[0]\["content"] for completion in completions]ï¼šæå–æ¨¡å‹çš„å›ç­”å†…å®¹ã€‚

* return \[count\_xml(c) for c in contents]ï¼šå¯¹æ¯ä¸ªè¾“å‡ºåº”ç”¨ count\_xml å‡½æ•°ï¼Œè¿”å›å¥–åŠ±åˆ†æ•°åˆ—è¡¨ã€‚

* ç”¨é€”ï¼šç”¨äºæ ¹æ® XML æ ¼å¼çš„ç¬¦åˆåº¦ç»™å‡ºå¥–åŠ±ï¼Œå¸¸ç”¨äºè¦æ±‚æ¨¡å‹è¾“å‡ºç¬¦åˆç‰¹å®šæ ¼å¼çš„ä»»åŠ¡ã€‚

è¿™äº›å¥–åŠ±å‡½æ•°ç”¨äºå¼ºåŒ–å­¦ä¹ ä¸­çš„åé¦ˆæœºåˆ¶ï¼Œå¸®åŠ©æ¨¡å‹ä¼˜åŒ–è¾“å‡ºç»“æœï¼Œå¹¶æ»¡è¶³æ ¼å¼ã€æ­£ç¡®æ€§ç­‰å¤šæ–¹é¢è¦æ±‚ã€‚

#### 4.GRPOè®­ç»ƒæµç¨‹

â€ƒâ€ƒå½“ä¸€åˆ‡å‡†å¤‡å®Œæ¯•åï¼Œæ¥ä¸‹æ¥å³å¯å¼€å¯æ¨¡å‹GRPOè®­ç»ƒã€‚

é¦–å…ˆè¯»å–æ¨¡å‹ï¼Œå¹¶è®¾ç½®æ¨¡å‹ä¿å­˜åœ°å€ï¼š

```python
model_name = "models/Qwen2.5-0.5B-Instruct"

output_dir="outputs/Qwen-0.5B-GRPO"
run_name="Qwen-0.5B-GRPO-gsm8k"
```

```python
training_args = GRPOConfig(
    output_dir=output_dir,
    run_name=run_name,
    learning_rate=5e-6,
    adam_beta1 = 0.9,
    adam_beta2 = 0.99,
    weight_decay = 0.1,
    warmup_ratio = 0.1,
    lr_scheduler_type='cosine',
    logging_steps=1,
    bf16=True,
    per_device_train_batch_size=1,
    gradient_accumulation_steps=4,
    num_generations=16,
    max_prompt_length=256,
    max_completion_length=200,
    num_train_epochs=1,
    save_steps=100,
    max_grad_norm=0.1,
    log_on_each_node=False,
    use_vllm=False,
    vllm_gpu_memory_utilization=.3,
    vllm_device="cuda:0",
    report_to="wandb" 
)
```

ç„¶ååˆ›å»ºè®­ç»ƒå‚æ•°ã€‚GRPOConfig æ˜¯ä¸€ä¸ªç”¨äºå¼ºåŒ–å­¦ä¹ å’Œä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹çš„é…ç½®ç±»ï¼Œå®ƒåŒ…å«äº†è®­ç»ƒçš„å„ç§è®¾ç½®ã€‚è®©æˆ‘ä»¬æ·±å…¥äº†è§£è¿™äº›å‚æ•°ã€‚

å…·ä½“çš„å‚æ•°è®¾ç½®å¦‚ä¸‹ï¼š

* output\_dir=output\_dirï¼šæŒ‡å®šè®­ç»ƒç»“æœä¿å­˜çš„ç›®å½•ï¼ˆä¾‹å¦‚æ¨¡å‹æ£€æŸ¥ç‚¹ã€æ—¥å¿—æ–‡ä»¶ï¼‰ã€‚output\_dir å˜é‡åº”äº‹å…ˆå®šä¹‰ã€‚

* run\_name=run\_nameï¼šè¿è¡Œçš„åç§°ï¼Œç”¨äºæ ‡è¯†è¯¥è®­ç»ƒä»»åŠ¡çš„åç§°ã€‚

* learning\_rate=5e-6ï¼šå­¦ä¹ ç‡ï¼Œå†³å®šäº†æ¯æ¬¡å‚æ•°æ›´æ–°æ—¶æ¨¡å‹æ›´æ–°çš„æ­¥é•¿ã€‚è¾ƒå°çš„å­¦ä¹ ç‡æ„å‘³ç€è®­ç»ƒæ›´åŠ ç¨³å®šï¼Œä½†å¯èƒ½éœ€è¦æ›´é•¿çš„æ—¶é—´ã€‚

* adam\_beta1=0.9 å’Œ adam\_beta2=0.99ï¼šAdam ä¼˜åŒ–å™¨çš„è¶…å‚æ•°ï¼Œåˆ†åˆ«å¯¹åº”ä¸€é˜¶çŸ©å’ŒäºŒé˜¶çŸ©çš„è¡°å‡ç‡ã€‚å®ƒä»¬é€šå¸¸ç”¨äºæ§åˆ¶ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„åŠ¨é‡ã€‚

* weight\_decay=0.1ï¼šæƒé‡è¡°å‡ï¼Œé€šå¸¸ç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæ˜¯ä¸€ç§æ­£åˆ™åŒ–æ–¹æ³•ã€‚

* warmup\_ratio=0.1ï¼šå­¦ä¹ ç‡çš„é¢„çƒ­æ¯”ä¾‹ï¼Œè¡¨ç¤ºåœ¨è®­ç»ƒçš„åˆæœŸé˜¶æ®µé€æ­¥å¢åŠ å­¦ä¹ ç‡ï¼Œé¿å…ç›´æ¥å¼€å§‹æ—¶å­¦ä¹ ç‡è¿‡é«˜ã€‚

* lr\_scheduler\_type='cosine'ï¼šå­¦ä¹ ç‡è°ƒåº¦ç±»å‹ï¼Œcosine è¡¨ç¤ºä½¿ç”¨ä½™å¼¦é€€ç«ï¼ˆCosine Annealingï¼‰æ¥è°ƒæ•´å­¦ä¹ ç‡ï¼Œé€šå¸¸åœ¨è®­ç»ƒçš„åæœŸå°†å­¦ä¹ ç‡é€æ¸å‡å°ã€‚

* logging\_steps=1ï¼šæ¯è®­ç»ƒ 1 æ­¥å°±è®°å½•ä¸€æ¬¡æ—¥å¿—ã€‚è¿™ä¸ªå‚æ•°æ§åˆ¶äº†æ—¥å¿—è®°å½•çš„é¢‘ç‡ã€‚

* bf16=Trueï¼šå¯ç”¨ bfloat16 ç²¾åº¦è®­ç»ƒã€‚bfloat16 æ˜¯ä¸€ç§æ•°å€¼ç²¾åº¦æ ¼å¼ï¼Œé€šå¸¸åœ¨æ”¯æŒè¯¥æ ¼å¼çš„ç¡¬ä»¶ï¼ˆå¦‚ Google TPUï¼‰ä¸Šèƒ½æœ‰æ•ˆåŠ é€Ÿè®­ç»ƒï¼ŒåŒæ—¶å‡å°‘æ˜¾å­˜å ç”¨ã€‚

* per\_device\_train\_batch\_size=1ï¼šæ¯ä¸ªè®¾å¤‡ä¸Šè¿›è¡Œçš„è®­ç»ƒæ‰¹æ¬¡å¤§å°ï¼Œå³æ¯æ¬¡è®¡ç®—æ—¶ä½¿ç”¨çš„æ ·æœ¬æ•°ã€‚æ­¤å¤„è®¾ç½®ä¸º 1ï¼Œè¡¨ç¤ºæ¯ä¸ª GPU æˆ–è®¾å¤‡ä¸Šå¤„ç† 1 ä¸ªæ ·æœ¬ã€‚

* gradient\_accumulation\_steps=4ï¼šæ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œåœ¨è®­ç»ƒæ—¶é€šè¿‡ç´¯è®¡å¤šä¸ªå°æ‰¹æ¬¡çš„æ¢¯åº¦æ¥æ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹æ¬¡å¤§å°ï¼Œä»¥èŠ‚çœæ˜¾å­˜ã€‚

* num\_generations=16ï¼šæ¯ä¸ªè®­ç»ƒæ ·æœ¬ç”Ÿæˆçš„è¾“å‡ºæ•°é‡ï¼Œé€šå¸¸ç”¨äºç”Ÿæˆå¼ä»»åŠ¡ï¼ˆå¦‚æ–‡æœ¬ç”Ÿæˆï¼‰ã€‚

* max\_prompt\_length=256ï¼šæœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆåŒ…æ‹¬é—®é¢˜å’Œä¸Šä¸‹æ–‡ï¼‰ï¼Œè¶…è¿‡æ­¤é•¿åº¦çš„è¾“å…¥ä¼šè¢«æˆªæ–­ã€‚

* max\_completion\_length=200ï¼šæ¨¡å‹ç”Ÿæˆçš„æœ€å¤§è¾“å‡ºé•¿åº¦ã€‚

* num\_train\_epochs=1ï¼šè®­ç»ƒçš„æ€»è½®æ•°ã€‚æ¯ä¸€è½®éƒ½å°†å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œä¸€æ¬¡å®Œæ•´çš„è®­ç»ƒã€‚

* save\_steps=100ï¼šæ¯ 100 æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡å‹çš„æ£€æŸ¥ç‚¹ã€‚

* max\_grad\_norm=0.1ï¼šæ¢¯åº¦è£å‰ªçš„æœ€å¤§èŒƒæ•°ï¼Œè¿™æœ‰åŠ©äºé¿å…æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ·±åº¦ç¥ç»ç½‘ç»œä¸­ã€‚

* log\_on\_each\_node=Falseï¼šåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šæ˜¯å¦è®°å½•æ—¥å¿—ï¼Œé€šå¸¸åœ¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ä½¿ç”¨ã€‚

* use\_vllm=Falseï¼šæ˜¯å¦ä½¿ç”¨ vllm è¿›è¡Œè®­ç»ƒã€‚vllm æ˜¯ä¸€ç§é«˜æ•ˆçš„è®­ç»ƒæ–¹æ³•ï¼Œé€šå¸¸ç”¨äºå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒã€‚

* vllm\_gpu\_memory\_utilization=.3ï¼šå¦‚æœå¯ç”¨äº† vllmï¼Œè¿™æ˜¯æ¯ä¸ª GPU çš„å†…å­˜ä½¿ç”¨æ¯”ä¾‹ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªæµ®åŠ¨å€¼ï¼Œ0 åˆ° 1ï¼‰ã€‚

* vllm\_device="cuda:0"ï¼šæŒ‡å®šè¦åœ¨ç¬¬ä¸€ä¸ª GPU ä¸Šè¿è¡Œ vllmã€‚

* report\_to="none"ï¼šç¦ç”¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŠ¥å‘Šå·¥å…·ï¼ˆå¦‚ WandBï¼‰ã€‚å¦‚æœè®¾ç½®ä¸º "wandb"ï¼Œåˆ™è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè®°å½•æ•°æ®å¹¶ä¸Šä¼ åˆ° WandBã€‚

ç„¶åè¿›è¡Œæ¨¡å‹åŠ è½½ï¼š

```python
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map=None
).to("cuda")
```

å¹¶åŠ è½½åˆ†è¯å™¨

```python
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token
```

ç„¶åå¼€å§‹æ¨¡å‹è®­ç»ƒï¼š

```python
trainer = GRPOTrainer(
    model=model,
    processing_class=tokenizer,
    reward_funcs=[
        xmlcount_reward_func,
        soft_format_reward_func,
        strict_format_reward_func,
        int_reward_func,
        correctness_reward_func],
    args=training_args,
    train_dataset=dataset,
)

trainer.train()

trainer.save_model(output_dir)
```

```plaintext
-------------------- Question:
Ahmed and Emily are having a contest to see who can get the best grade in the class. There have been 9 assignments and Ahmed has a 91 in the class. Emily has a 92. The final assignment is worth the same amount as all the other assignments. Emily got a 90 on the final assignment. What is the minimum grade Ahmed needs to get to beat Emily if all grades are whole numbers? 
Answer:
100 
Response:
To determine the minimum grade Ahmed needs to beat Emily, we'll first calculate the total number of assignments Ahmed has completed and the difference between the total number of assignments and the number of final assignments:

1. **Total number of assignments**: 9
2. **Number of final assignments**: 1
3. **Total number of assignments completed**: \( 9 - 1 = 8 \)
4. **Number of final assignments to be completed**: 1

To beat Emily, Ahmed needs to get a score that is greater than:

\[ \text{Emily's score} + \text{Total number of final assignments} \]

So, we calculate:

\[ 91 + 1 = 92 \]

To beat Emily, Ahmed needs to have:

\[ 92 + 1 = 93 \]

Therefore, Ahmed needs at least a score of 93 on the final assignment to potentially beat Emily. 
Extracted:
To determine the minimum grade Ahmed needs to beat Emily, we'll first calculate the total number of assignments Ahmed has completed and the difference between the total number of assignments and the number of final assignments:

1. **Total number of assignments**: 9
2. **Number of final assignments**: 1
3. **Total number of assignments completed**: \( 9 - 1 = 8 \)
4. **Number of final assignments to be completed**: 1

To beat Emily, Ahmed needs to get a score that is greater than:

\[ \text{Emily's score} + \text{Total number of final assignments} \]

So, we calculate:

\[ 91 + 1 = 92 \]

To beat Emily, Ahmed needs to have:

\[ 92 + 1 = 93 \]

Therefore, Ahmed needs at least a score of 93 on the final assignment to potentially beat Emily.
-------------------- Question:
The gauge on a water tank shows that the tank is 1/3 full of water. To fill the tank, 16 gallons of water are added. How many gallons of water does the tank hold when full? 
Answer:
24 
Response:
Let's denote the full capacity of the tank as \( C \) gallons. From the information given, we know that when the tank is \( \frac{1}{3} \) full, it contains \( \frac{1}{3}C \) gallons of water.

We are told that 16 gallons are added to the tank to fill it up to its full capacity. Therefore, the additional water added can be expressed as:

\[ \frac{1}{3}C + 16 \]

Since the tank is \( \frac{1}{3} \) full, the full capacity \( C \) is:

\[ C = 16 \times 3 \]

\[ C = 48 \] gallons

So, the tank holds 48 gallons of water when full. 
Extracted:
Let's denote the full capacity of the tank as \( C \) gallons. From the information given, we know that when the tank is \( \frac{1}{3} \) full, it contains \( \frac{1}{3}C \) gallons of water.

We are told that 16 gallons are added to the tank to fill it up to its full capacity. Therefore, the additional water added can be expressed as:

\[ \frac{1}{3}C + 16 \]

Since the tank is \( \frac{1}{3} \) full, the full capacity \( C \) is:

\[ C = 16 \times 3 \]

\[ C = 48 \] gallons

So, the tank holds 48 gallons of water when full.
-------------------- Question:
There are 15 tables in the school's cafeteria. Each table can seat 10 people. Usually, only 1/10 of the seats are left unseated. How many seats are usually taken? 
Answer:
135 
Response:
First, let's calculate the total number of seats in the cafeteria:

Total seats = Number of tables Ã— Number of seats per table
Total seats = 15 Ã— 10
Total seats = 150

Now, let's determine how many seats are usually taken:

Seats taken = Total seats Ã— 1/10
Seats taken = 150 Ã— 1/10
Seats taken = 15

Therefore, usually, 15 seats are taken. 
Extracted:
First, let's calculate the total number of seats in the cafeteria:

Total seats = Number of tables Ã— Number of seats per table
Total seats = 15 Ã— 10
Total seats = 150

Now, let's determine how many seats are usually taken:

Seats taken = Total seats Ã— 1/10
Seats taken = 150 Ã— 1/10
Seats taken = 15

Therefore, usually, 15 seats are taken.
-------------------- Question:
Fiona completed 36 math questions in an hour. Shirley was able to complete twice as many math questions within that same time, and Kiana completed half of the sum of Fiona and Shirley's math questions. If they each did the same number of questions the following hour, how many math questions did all three girls complete in 2 hours? 
Answer:
324 
Response:
First, let's determine how many math questions each girl completed in the first hour.

Fiona completed 36 questions.

Shirley completed twice as many questions as Fiona, so:
\[ \text{Shirley's questions} = 2 \times 36 = 72 \]

Kiana completed half of the sum of Fiona and Shirley's questions:
\[ \text{Kiana's questions} = \frac{36 + 72}{2} = \frac{108}{2} = 54 \]

Next, let's calculate the number of math questions each of them completed in the second hour if they each did the same number of questions as in the first hour.

Fiona still completed 36 questions.
Shirley completed 72 questions.
Kiana completed 54 questions.

Since they did the same number of questions each hour, we can find the total number of questions completed in 2 hours by adding the 
Extracted:
First, let's determine how many math questions each girl completed in the first hour.

Fiona completed 36 questions.

Shirley completed twice as many questions as Fiona, so:
\[ \text{Shirley's questions} = 2 \times 36 = 72 \]

Kiana completed half of the sum of Fiona and Shirley's questions:
\[ \text{Kiana's questions} = \frac{36 + 72}{2} = \frac{108}{2} = 54 \]

Next, let's calculate the number of math questions each of them completed in the second hour if they each did the same number of questions as in the first hour.

Fiona still completed 36 questions.
Shirley completed 72 questions.
Kiana completed 54 questions.

Since they did the same number of questions each hour, we can find the total number of questions completed in 2 hours by adding the




<div>

  <progress value='71' max='1868' style='width:300px; height:20px; vertical-align: middle;'></progress>
  [  71/1868 18:44 < 8:07:53, 0.06 it/s, Epoch 0.04/1]
</div>
<table border="1" class="dataframe">
```

Step Training Loss 1 0.000000 2 0.000000 3 0.000000 4 0.000000 5 0.000000 6 -0.000000 7 0.000000 8 0.000000 9 0.000000 10 0.000000 11 0.000000 12 0.000000 13 0.000000 14 0.000000 15 0.000000 16 0.000000 17 0.000000 18 0.000000 19 0.000000 20 0.000000 21 0.000000 22 0.000000 23 0.000000 24 0.000000 25 0.000000 26 0.000000 27 0.000000 28 0.000000 29 0.000000 30 0.000000 31 0.000000 32 0.000000 33 0.000000 34 0.000000 35 0.000000 36 0.000000 37 0.000000 38 0.000000 39 0.000000 40 0.000000 41 0.000000 42 0.000000 43 0.000000 44 0.000000 45 0.000000 46 0.000000 47 0.000000 48 0.000000 49 0.000000 50 0.000000 51 0.000000 52 0.000000 53 0.000000 54 0.000000 55 0.000000 56 0.000000 57 0.000000 58 0.000000 59 0.000000 60 0.000000 61 0.000000 62 0.000000 63 0.000000 64 0.000000 65 0.000000 66 0.000000 67 0.000000 68 0.000000 69 0.000000

